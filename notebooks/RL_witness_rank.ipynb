{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Witness rankについて\n",
    "\n",
    "参考：\n",
    "* [Model-based RL in Contextual Decision Processes: PAC bounds and Exponential Improvements over Model-free Approaches](https://arxiv.org/abs/1811.08540)\n",
    "\n",
    "[Bellman rank](RL_Bellman_rank.ipynb)の続きです．\n",
    "Witness rankはモデルベースRL向けのBellman rankみたいなものです．\n",
    "モデルベースとモデルフリーでは一般に，\n",
    "* モデルベース：環境のダイナミクスをモデル化し，それを解くことで最適方策を見つける　\n",
    "* モデルフリー：最適方策やその価値を直接モデル化する\n",
    "\n",
    "といった違いがあります．\n",
    "モデルベースはモデルフリーよりも一般にサンプル効率が良いことが信じられています（教師ありの情報をたくさん使えるので）．\n",
    "\n",
    "TODO: globalな探索が重要な環境ではモデルフリーでしか解けないことがBellman rankの論文で指摘されているっぽい．要確認．\n",
    "\n",
    "今回は，関数近似が十分リッチであれば，モデルベースな手法がモデルフリーよりもサンプル効率が指数的に良いことを示していきます．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "表記：\n",
    "\n",
    "Contextual decision process (CDP)を考えます．\n",
    "\n",
    "* $\\mathcal{X}$を$\\mathcal{X}_1, \\dots, \\mathcal{X}_{H+1}$に分割可能な文脈の空間とします．\n",
    "* $|\\mathcal{A}|=K$とします．\n",
    "\n",
    "---\n",
    "\n",
    "Contextual MDPの重要な例として，Factored MDPがあります．\n",
    "$d\\in \\mathbb{N}$と$\\mathcal{O}$を小さな有限集合として，文脈空間を\n",
    "$\\mathcal{X} = [H] \\times \\mathcal{O}^d$とします．\n",
    "\n",
    "また，$x \\in \\mathcal{X}$について，$x[i]$を$i \\in [d]$番目の状態における文脈の値とします．\n",
    "このとき，それぞれの状態変数$i \\in [d]$と，そのparent  $\\operatorname{pa}_i \\subseteq [d]$を考えましょう．\n",
    "\n",
    "Factored MDPでは，\n",
    "\n",
    "$$\n",
    "...\n",
    "$$\n",
    "\n",
    "の形式で遷移確率が分解されます．このとき，遷移の作用素は\n",
    "$\\sum^{d}_{i=1} HK \\cdot |\\mathcal{O}^{1+|\\operatorname{pa}_i|}|$個のパラメータで構成されます．\n",
    "一方で，通常のMDPでは$d H K |\\mathcal{O}|^{1+d}$のパラメータがかかることに注意しましょう（TODO: なんで$d$があるの？）．\n",
    "よって，factored MDPの方が遷移に必要なパラメータの数が少ないです．\n",
    "\n",
    "---\n",
    "\n",
    "* モデルベースでは報酬と遷移のモデル$M=(R, P)$を$M \\in \\mathcal{M}$から選択して，最も良いものを見つけるとします．\n",
    "    * $(r, x') \\sim M_{x, a}$は$r\\sim R(x, a)$かつ$x' \\sim P_{x, a}$として表記します\n",
    "    * $\\operatorname{OP}(M)$で，モデル$M$についての最適価値と最適方策を計算するオラクルを表すとします．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルベースとモデルフリーの定義\n",
    "\n",
    "よく使われるモデルフリーの定義は，「メモリのスペースが$o\\left(|\\mathcal{X}|^2|\\mathcal{A}|\\right)$であるアルゴリズム」ですが，\n",
    "これは関数近似がある場合にスケールしづらいです．\n",
    "\n",
    "そこで，次の定義を使いましょう．\n",
    "\n",
    "---\n",
    "\n",
    "（有限な）関数集合$\\mathcal{G}: (\\mathcal{X} \\times \\mathcal{A}) \\to \\mathbb{R}$について，$\\mathcal{G}$-profileを$\\Phi_{\\mathcal{G}}(x):=[g(x, a)]_{g \\in \\mathcal{G}, a \\in \\mathcal{A}}$として定義します．\n",
    "\n",
    "次を満たす時，アルゴリズムは$\\mathcal{G}$を使ったモデルフリーアルゴリズムといいます．\n",
    "\n",
    "全ての$x\\in \\mathcal{X}$に，$\\Phi_{\\mathcal{G}}(x)$を使ってアクセスする．\n",
    "\n",
    "---\n",
    "\n",
    "つまり，モデルフリーでは$x$と$x'$の違いを，$\\Phi_{\\mathcal{G}}(x)$を使ってでしか確認できません．\n",
    "（例えば$x$と$x'$の違いを$Q(x, \\cdot)$と$Q(x', \\cdot)$を使って判別する，など）\n",
    "\n",
    "そのため，一般には何らかの情報理論的な損失が発生します．\n",
    "（ちなみにモデルベースとモデルフリーアルゴリズムは，Tabular MDPにおいては，情報理論的には同じになります（Appendix D）．）\n",
    "\n",
    "関数近似がある場合では，一方で，モデルフリーでは解けない場合が存在します．\n",
    "\n",
    "---\n",
    "\n",
    "**定理**\n",
    "\n",
    "次を満たすCDPの族$\\mathcal{M}$が存在します．\n",
    "\n",
    "* $|\\mathcal{M}|\\leq 2^H$\n",
    "* 確率$1- \\delta$以上で，$\\mathcal{M}$を使ったモデルベースアルゴリズムが$\\epsilon$-最適な方策を$\\operatorname{poly}(H, 1 / \\epsilon, \\log (1 / \\delta))$個の軌跡で吐き出す\n",
    "* $\\mathcal{G}=O P(\\mathcal{M})$として，どんなモデルフリーアルゴリズムも$o(2^H)$の軌跡を使っても$\\epsilon$-最適方策が吐き出せない \n",
    "\n",
    "---\n",
    "\n",
    "実際，factored MDPにおいてモデルふr−アルゴリズムは上手く行かないみたいですね（lower boundはまだ出されてないみたいですが）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Witness model misfit\n",
    "\n",
    "Integral probability metricを使って次を定義します．\n",
    "\n",
    "---\n",
    "\n",
    "**Integral probability metric**\n",
    "\n",
    "Wasserstein距離の一般化みたいなもんです．\n",
    "\n",
    "$P_1, P_2 \\in \\Delta(\\mathcal{Z})$ over $z \\in \\mathcal{Z}$と，Symmetric（つまり$f\\in \\mathcal{F}$なら$-f\\in \\mathcal{F}$）な関数の集合$\\mathcal{F}: \\mathcal{Z} \\rightarrow \\mathbb{R}$について，\n",
    "\n",
    "$$\n",
    "\\sup _{f \\in \\mathcal{F}} \\mathbb{E}_{z \\sim P_1}[f(z)]-\\mathbb{E}_{z \\sim P_2}[f(z)]\n",
    "$$\n",
    "\n",
    "のことを$\\mathcal{F}$のIPMと呼ぶ．\n",
    "\n",
    "---\n",
    "\n",
    "**Witness model misfit**\n",
    "\n",
    "次の\n",
    "\n",
    "* クラス：$\\mathcal{F}: \\mathcal{X} \\times \\mathcal{A} \\times \\mathcal{R} \\times \\mathcal{X} \\rightarrow \\mathbb{R}$：$(x, a, r, x')$を受け取って何か実数を返す関数．例えばベルマン誤差など．\n",
    "* モデル：$M, M^{\\prime} \\in \\mathcal{M}$\n",
    "* タイムステップ：$h\\in [H]$\n",
    "\n",
    "について，$M'$が$M$にwitnessされたときの$h$におけるWitnessed model misfitは\n",
    "\n",
    "$$\n",
    "\\mathcal{W}\\left(M, M^{\\prime}, h ; \\mathcal{F}\\right) \\triangleq \\sup _{f \\in \\mathcal{F}} \\underset{\\substack{x_h \\sim \\pi_M \\\\ a_h \\sim \\pi_{M^{\\prime}}}}{\\mathbb{E}}\\left[\\underset{\\left(r, x^{\\prime}\\right) \\sim M_h^{\\prime}}{\\mathbb{E}}\\left[f\\left(x_h, a_h, r, x^{\\prime}\\right)\\right]-\\underset{\\left(r, x^{\\prime}\\right) \\sim M_h^{\\star}}{\\mathbb{E}}\\left[f\\left(x_h, a_h, r, x^{\\prime}\\right)\\right]\\right],\n",
    "$$\n",
    "\n",
    "で定義されます．ここで，モデル$M=(R, P)$について，$\\left(r, x^{\\prime}\\right) \\sim M_h$ は $r \\sim R_{x_h, a_h}, x^{\\prime} \\sim P_{x_h, a_h}$の略記です．\n",
    "\n",
    "---\n",
    "\n",
    "**直感**\n",
    "\n",
    "* misfitは，$M'$と$M^*$によって生じる２つの分布のIPMを測っています．\n",
    "    * この分布は$\\mathcal{X} \\times \\mathcal{A} \\times \\mathcal{R} \\times \\mathcal{X}$上に定義されます．\n",
    "* もちろん$M_h'=M_h^*$ならmisfitは０になります．\n",
    "* $M$はデータを集めるようのモデルです．[RL_Bellman_rank.ipynb](RL_Bellman_rank.ipynb)と同じノリ？\n",
    "\n",
    "例えば$\\mathcal{F}=\\left\\{f:\\|f\\|_{\\infty} \\leq 1\\right\\}$であれば，misfitは\n",
    "\n",
    "$$\\mathcal{W}\\left(M, M^{\\prime}, h ; \\mathcal{F}\\right)=\\mathbb{E}\\left[\\left\\|R_{x_h, a_h}^{\\prime} \\circ P_{x_h, a_h}^{\\prime}-R_{x_h, a_h}^{\\star} \\circ P_{x_h, a_h}^{\\star}\\right\\|_{T V} \\mid x_h \\sim \\pi_M, a_h \\sim \\pi_{M^{\\prime}}\\right]$$\n",
    "\n",
    "になります（ここで$R_{x, a} \\circ P_{x, a}$は$\\mathcal{R}\\times \\mathcal{X}$上の分布です）．これは単に$R^{\\prime} \\circ P^{\\prime}$ and $R^{\\star} \\circ P^{\\star}$間のTV距離を測ってるだけです．\n",
    "\n",
    "なので，直感的には$\\mathcal{F}$によってIPMの測り方が決まります．\n",
    "\n",
    "---\n",
    "\n",
    "**Average Bellman Errorとの関係**\n",
    "\n",
    "Bellman rankのAverage Bellman Errorを思い出しましょう．Average Bellman Errorは次で定義されます：\n",
    "\n",
    "$$\n",
    "\\mathcal{E}_B\\left(Q, Q^{\\prime}, h\\right) \\triangleq \\mathbb{E}\\left[Q^{\\prime}\\left(x_h, a_h\\right)-r_h-Q^{\\prime}\\left(x_{h+1}, a_{h+1}\\right) \\mid x_h \\sim \\pi_Q, a_{h: h+1} \\sim \\pi_{Q^{\\prime}}\\right]\n",
    "$$\n",
    "\n",
    "ここで，Q関数が$\\mathcal{Q}=\\mathrm{OP}(\\mathcal{M})$の形をしている場合，上の定義を２つのモデル$M, M'$に対する誤差として拡張できます．\n",
    "そのとき，$M, M'$に対するAverage Bellman Errorは関数$f_{M^{\\prime}}\\left(x, a, r, x^{\\prime}\\right)=r+V_{M^{\\prime}}\\left(x^{\\prime}\\right)$によってwitnessされたmisfitと同じです．\n",
    "\n",
    "---\n",
    "\n",
    "$\\mathcal{F}$は何でも良いわけではないです．次を仮定します：\n",
    "（クラス$\\mathcal{F}: \\mathcal{Z}\\to \\mathbb{R}$は$f \\in \\mathcal{F}$なら$-f \\in \\mathcal{F}$のときに対象であるといいます．）\n",
    "\n",
    "$\\mathcal{F}$は対象であり，有限なサイズとします．\n",
    "$\\|f \\|_\\infty \\leq 2$とし，\n",
    "$$\n",
    "\\forall M, M^{\\prime} \\in \\mathcal{M}: \\mathcal{W}\\left(M, M^{\\prime}, h ; \\mathcal{F}\\right) \\geq \\mathcal{E}_B\\left(Q_M, Q_{M^{\\prime}}, h\\right)\n",
    "$$\n",
    "が成立するとします．つまり，\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&\\sup _{f \\in \\mathcal{F}} \\underset{\\substack{x_h \\sim \\pi_M \\\\ a_h \\sim \\pi_{M^{\\prime}}}}{\\mathbb{E}}\\left[\\underset{\\left(r, x^{\\prime}\\right) \\sim M_h^{\\prime}}{\\mathbb{E}}\\left[f\\left(x_h, a_h, r, x^{\\prime}\\right)\\right]-\\underset{\\left(r, x^{\\prime}\\right) \\sim M_h^{\\star}}{\\mathbb{E}}\\left[f\\left(x_h, a_h, r, x^{\\prime}\\right)\\right]\\right]\n",
    "\\\\\\geq & \n",
    "\\mathbb{E}\\left[Q_{M'}\\left(x_h, a_h\\right)-r_h-Q_{M^{\\prime}}\\left(x_{h+1}, a_{h+1}\\right) \\mid x_h \\sim \\pi_Q, a_{h: h+1} \\sim \\pi_{Q_{M'}}\\right]\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "を仮定します．\n",
    "\n",
    "**仮定についての注意**\n",
    "\n",
    "* この仮定は，$r(x, a)+V_M(x') \\in \\mathcal{F}$である場合に常に成立します．実際，この場合はMisfitが平均ベルマン誤差に一致します．ただし，必ずしもこの場合を含む必要はありません．\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Witness rank\n",
    "\n",
    "これまではWitness model misfitを定義し，仮定を一つ導入しました．実はこれだけでは十分ではありません．指数的なサンプルが必要になるMDPが存在してしまいます（論文のProposition 4）．\n",
    "\n",
    "そこで，Witness rankの仮定を導入します．ノリはBellman rankと同じです．\n",
    "\n",
    "---\n",
    "\n",
    "**Witness rank**\n",
    "\n",
    "モデルクラス$\\mathcal{M}$, テスト関数$\\mathcal{F}$，そして$\\kappa \\in (0, 1]$を考えます．\n",
    "それぞれの$h \\in [H]$に対して，行列の集合$\\mathcal{N}_{\\kappa, h}$を次のように定めます．\n",
    "任意の$A \\in \\mathcal{N}_{\\kappa, h}$が次を満たす：\n",
    "\n",
    "$$\n",
    "A \\in \\mathbb{R}^{|\\mathcal{M}| \\times|\\mathcal{M}|}, \\quad \\kappa \\mathcal{E}_B\\left(M, M^{\\prime}, h\\right) \\leq A\\left(M, M^{\\prime}\\right) \\leq \\mathcal{W}\\left(M, M^{\\prime}, h\\right), \\forall M, M^{\\prime} \\in \\mathcal{M},\n",
    "$$\n",
    "\n",
    "これについて，Witness rankを\n",
    "\n",
    "$$\n",
    "\\mathrm{W}(\\kappa, \\beta, \\mathcal{M}, \\mathcal{F}, h) \\triangleq \\min _{A \\in \\mathcal{N}_{\\kappa, h}} \\operatorname{rank}(A, \\beta)\n",
    "$$\n",
    "\n",
    "として定義します．\n",
    "\n",
    "**解釈**\n",
    "\n",
    "* $A(M, M')={W}\\left(M, M^{\\prime}, h\\right)$である場合を考えましょう．\n",
    "この時，$0$でないwitnessed model misfitをチェックするためにかかる文脈の分布の数はWitness rankで抑えられます．よって，$M^\\star$を見つけるためにかかる時間はwitness rankで抑えられます．\n",
    "* 一方で，$A\\left(M, M^{\\prime}\\right)=\\kappa \\mathcal{E}_B\\left(M, M^{\\prime}, h\\right)$の場合はこれはBellman rankと同じです．よって，上のWitness rankの定義はBellman rankを一般化してることがわかります．\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## アルゴリズム\n",
    "\n",
    "Model misfitを推定して最適方策を出すアルゴリズムを見てみましょう．\n",
    "\n",
    "データセット$\\mathcal{D}=\\{(x_h^{(n)}, a_h^{(n)}, r_h^{(n)}, x_{h+1}^{(n)})\\}_{n=1}^N$が与えられたときを考えます．ここで，\n",
    "\n",
    "$$\n",
    "x_h^{(n)} \\sim \\pi_M, a_h^{(n)} \\sim U(\\mathcal{A}), (r_h^{(n)}, x_{h+1}^{(n)}) \\sim M_h^\\star\n",
    "$$\n",
    "\n",
    "です．また，importance weightを$\\rho^{(n)} = K\\pi_{M'}(a_h^{(n)} \\mid x_h^{(n)})$とします．\n",
    "\n",
    "つまり，\n",
    "* 各ステップ$h$までは$\\pi_M$で動き，$x_h^{(n)}$を出す\n",
    "* その次に行動$a_h^{(n)}$を$U(\\mathcal{A})$から出す\n",
    "* 報酬と次状態は真のMDPからサンプルする\n",
    "\n",
    "状況です．これを使ってmisfitを推定してみましょう．\n",
    "\n",
    "$$\n",
    "\\widehat{\\mathcal{W}}(M, M', h) = \\max_{f \\in \\mathcal{F}}\n",
    "\\sum^{N}_{n=1}\\frac{\\rho^{(n)}}{N}\n",
    "\\mathbb{E}_{(r, x')\\sim M'_h}\n",
    "\\left[f(x_h^{(n)}, a_h^{(n)}, r, x') - f(x_h^{(n)}, a_h^{(n)}, r^{(n)}_h, x^{(n)}_{h+1})\\right]\n",
    "$$\n",
    "\n",
    "ここで，行動は$U(\\mathcal{A})$からサンプルしてるので，重み$\\rho^{n}$で修正しています．\n",
    "\n",
    "これは通常の一様収束の話を使えば$\\mathcal{W}(M, M', h)$に収束することが言えます．\n",
    "\n",
    "また，平均ベルマン誤差$\\mathcal{E}_B(M, M, h)$も推定します．\n",
    "データセット\n",
    "$\\{(x_h^{(n)}, a_h^{(n)}, r_h^{(n)}, x_{h+1}^{(n)})\\}_{n=1}^N$\n",
    "を考えます．ここで，\n",
    "$$\n",
    "x_h^{(n)} \\sim \\pi_M, a_h^{(n)} \\sim \\pi_M, (r_h^{(n)}, x_{h+1}^{(n)}) \\sim M_h^\\star\n",
    "$$\n",
    "を使って，unbiasedな推定\n",
    "$$\n",
    "\\widehat{\\mathcal{E}}_B(M, M, h) = \\frac{1}{N} \\sum^N_{n=1} \n",
    "\\left[Q_M(x^{(n)}_h, a^{(n)}_h) - \\left[r_h^{(n)} + V_M(x_{h+1}^{(n)})\\right]\\right]\n",
    "$$\n",
    "をします．\n",
    "\n",
    "以上を踏まえて，次のアルゴリズムを考えます：\n",
    "\n",
    "![witness-rank](figs/Witness-rank.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このアルゴリズムでは，ループ毎に$\\mathcal{M}_t$から最適なモデル以外が除去されていきます．\n",
    "\n",
    "* ３行目ではOptimisticなモデルを選択し，４行目でその価値をサンプルから推定してます．\n",
    "* ４，５行目で，その推定値がOptimisticなモデルの価値とあまり変わらない場合，その方策をそのまま返します．\n",
    "* ６行目で，平均ベルマン誤差が高いステップを探します．\n",
    "* ７行目で，このステップの精度を上げます\n",
    "* 最後にWitness misfitが一定以上のモデルを排除します．$M^\\star$のmisfitは０なので"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
