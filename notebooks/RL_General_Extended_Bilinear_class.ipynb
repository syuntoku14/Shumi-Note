{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extended Bilinear Class\n",
    "\n",
    "\n",
    "参考\n",
    "* [Bilinear Classes: A Structural Framework for Provable Generalization in RL](https://arxiv.org/abs/2103.10897)の６章\n",
    "\n",
    "Bilinear Classは色々なMDPの仮定を一般化しますが，Witness rankなどを一般化するためにはもうひと工夫必要です．ここではより一般的なBilinear Classについて見てみます．\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "**Generalized Bilinear Class**\n",
    "\n",
    "* MDP$\\mathcal{M}$\n",
    "* 仮説クラス$\\mathcal{H}$\n",
    "* discrepancy関数$\\ell_f: \\mathbb{R} \\times \\mathcal{S} \\times \\mathcal{A} \\times \\mathcal{S} \\times \\mathcal{H} \\times \\mathcal{F} \\rightarrow \\mathbb{R}$\n",
    "* 推定用の方策を$\\Pi_{\\text {est }}=\\left\\{\\pi_{e s t}(f): f \\in \\mathcal{H}\\right\\}$\n",
    "* 非減少な関数：$\\xi, \\zeta: \\mathbb{R} \\mapsto \\mathbb{R}$ with $\\xi(0)=0, \\zeta(0)=0$\n",
    "* discriminator クラス：$\\left\\{\\mathcal{F}_h\\right\\}_{h=0}^{H-1}$.\n",
    "\n",
    "このとき，\n",
    "$\\left(\\mathcal{H}, \\ell_f, \\Pi, \\mathcal{M}\\right)$\n",
    "は次を満たすときにGeneralized Bilinear Classと言います．\n",
    "\n",
    "1. $\\mathcal{H}$が実現可能\n",
    "2. 次を満たす関数$W_h: \\mathcal{H} \\times \\mathcal{H} \\rightarrow \\mathcal{V}$ and $X_h: \\mathcal{H} \\rightarrow \\mathcal{V}$がヒルベルト空間$\\mathcal{V}$について存在する：\n",
    "\n",
    "$$\n",
    "\\left|\\mathbb{E}_{a_{0: h} \\sim \\pi_f}\\left[Q_{h, f}\\left(s_h, a_h\\right)-r\\left(s_h, a_h\\right)-V_{h+1, f}\\left(s_{h+1}\\right)\\right]\\right| \\leq \\xi\\left(\\left|\\left\\langle W_h(f)-W_h\\left(f^{\\star}\\right), X_h(f)\\right\\rangle\\right|\\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\left|\\max _{\\nu \\in \\mathcal{F}_h} \\mathbb{E}_{a_{0: h-1} \\sim \\pi_f} \\mathbb{E}_{a_h \\sim \\pi_{e s t}}\\left[\\ell_f\\left(s_h, a_h, r_h, s_{h+1}, g, \\nu\\right)\\right]\\right| \\geq \\zeta\\left(\\left|\\left\\langle W_h(g)-W_h\\left(f^{\\star}\\right), X_h(f)\\right\\rangle\\right|\\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbb{E}_{a_{0: h-1} \\sim \\pi_f} \\mathbb{E}_{a_h \\sim \\pi_{e s t}}\\left[\\ell_f\\left(s_h, a_h, r_h, s_{h+1}, f^{\\star}, \\nu\\right)\\right]=0, \\forall \\nu \\in \\mathcal{F}_h\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "これはBilinear Classを一般化してることに注意しましょう．\n",
    "実際，$\\xi$と$\\zeta$をidentity関数として，$\\mathcal{F}_h=\\emptyset$とすれば良いです（つまり，discrepancy関数内の$\\nu$を無視します）．\n",
    "\n",
    "また，$\\zeta$に以下の仮定を置きます（TODO）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "**Witness rankとの関係**\n",
    "\n",
    "次を満たすときにWitness rankが$d$であるといいます．\n",
    "２つのモデル$f, g \\in \\mathcal{M}$に対して，次を満たす\n",
    "$X_h: \\mathcal{H} \\mapsto \\mathbb{R}^d$ と$W_h: \\mathcal{H} \\mapsto \\mathbb{R}^d$\n",
    "が存在する：\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "& \\max _{v \\in \\mathcal{F}_h} \\mathbb{E}_{a_{0: h-1} \\sim \\pi_f} \\mathbb{E}_{a_h \\sim \\pi_g}\\left[\\mathbb{E}_{s^{\\prime} \\sim g_h\\left(\\cdot \\mid s_h, a_h\\right)} v\\left(s_h, a_h, s^{\\prime}\\right)-\\mathbb{E}_{s^{\\prime} \\sim P_h\\left(\\cdot \\mid s_h, a_h\\right)} v\\left(s_h, a_h, s^{\\prime}\\right)\\right] \\geq\\left\\langle W_h(g), X_h(f)\\right\\rangle, \\\\\n",
    "& \\kappa \\cdot \\mathbb{E}_{a_{0: h-1} \\sim \\pi_f} \\mathbb{E}_{a_h \\sim \\pi_g}\\left[\\mathbb{E}_{s^{\\prime} \\sim g_h\\left(\\cdot \\mid s_h, a_h\\right)} V_{h+1, g}\\left(s^{\\prime}\\right)-\\mathbb{E}_{s^{\\prime} \\sim P_h\\left(\\cdot \\mid s_h, a_h\\right)} V_{h+1, g}\\left(s^{\\prime}\\right)\\right] \\leq\\left\\langle W_h(g), X_h(f)\\right\\rangle,\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "これがBilinear Classに含まれることを示します．報酬関数は既知であるとしましょう．$f^\\star$はモデルベースなので，真の$P$を表します．つまり，$\\left\\langle W_h\\left(f^{\\star}\\right), X_h(f)\\right\\rangle=0$が任意の$f \\in \\mathcal{H}$で成立します．\n",
    "これをWitness rankの定義と合わせると，\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "& \\max _{v \\in \\mathcal{F}_h} \\mathbb{E}_{a_{0: h-1} \\sim \\pi_f} \\mathbb{E}_{a_h \\sim \\pi_g}\\left[\\mathbb{E}_{s^{\\prime} \\sim g_h\\left(\\cdot \\mid s_h, a_h\\right)} v\\left(s_h, a_h, s^{\\prime}\\right)-\\mathbb{E}_{s^{\\prime} \\sim P_h\\left(\\cdot \\mid s_h, a_h\\right)} v\\left(s_h, a_h, s^{\\prime}\\right)\\right] \\\\\n",
    "& \\quad \\geq\\left\\langle W_h(g)-W_h\\left(f^{\\star}\\right), X_h(f)\\right\\rangle .\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "が言えます（元論文は不等号の向きが逆？）．\n",
    "\n",
    "Discrepancy関数を\n",
    "\n",
    "$$\n",
    "\\ell_f(o, g, v)=\\frac{\\mathbf{1}\\left\\{a=\\pi_g(s)\\right\\}}{1 / A}\\left[\\mathbb{E}_{\\tilde{s} \\sim g_h(\\cdot \\mid s, a)} v(s, a, \\tilde{s})-v\\left(s, a, s^{\\prime}\\right)\\right]\n",
    "$$\n",
    "\n",
    "とすれば，これはGeneralized Bilinear classの定義の２つめと同じです．\n",
    "\n",
    "続いて１つ目を示しましょう．Witness rankではモデルベースを考えるので，\n",
    "$Q_{h, f}\\left(s_h, a_h\\right)=r\\left(s_h, a_h\\right)+\\mathbb{E}_{s^{\\prime} \\sim g_h\\left(s_h, a_h\\right)} V_{h+1, f}\\left(s^{\\prime}\\right)$を考えます．これを使うと，\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "& \\left|\\mathbb{E}_{a_{0: h} \\sim \\pi_f}\\left[Q_{h, f}\\left(s_h, a_h\\right)-r_h-V_{h+1, f}\\left(s_{h+1}\\right)\\right]\\right| \\\\\n",
    "& =\\left|\\mathbb{E}_{a_{0: h} \\sim \\pi_f}\\left[\\mathbb{E}_{s^{\\prime} \\sim g_h\\left(s_h, a_h\\right)} V_{h+1, f}\\left(s^{\\prime}\\right)-\\mathbb{E}_{s^{\\prime} \\sim P_h\\left(s_h, a_h\\right)} V_{h+1, f}\\left(s^{\\prime}\\right)\\right]\\right|\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "が成り立ちます．よって，$\\zeta$をidentity関数として，$\\xi(x)=x / \\kappa$とすれば，Witness rankは generalized Bilinear Classに含まれることがわかります．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
