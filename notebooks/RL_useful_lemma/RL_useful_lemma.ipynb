{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Good Set\n",
    "\n",
    "表記\n",
    "* $w_{tj}(s, a)$：エピソード$j$のステップ$t \\in [H]$で$(s, a)$を訪れる確率\n",
    "* $w_j(s, a):= \\sum_{t=1}^H w_{tj}(s, a)$\n",
    "* $n_j(s, a)$：エピソード$j$までに$(s, a)$を訪れる回数\n",
    "\n",
    "直感的には，次の$L_k$は状態行動空間を「十分訪れたことがある集合」と「そんなに訪れたことがない集合」に分割します．\n",
    "$L_k$の中身の状態行動の訪問回数は，そのoccupancy measureで下から抑えることができます．\n",
    "これはリグレットのバウンドに便利です．\n",
    "\n",
    "---\n",
    "\n",
    "**定義: Good Set**\n",
    "\n",
    "参考：\n",
    "* [Tight Regret Bounds for Model-Based Reinforcement Learning with Greedy Policies](https://arxiv.org/abs/1905.11527)のAppendix F.1\n",
    "* [Tighter Problem-Dependent Regret Bounds in Reinforcement Learning without Domain Knowledge using Value Function Bounds](https://arxiv.org/abs/1901.00210)のAppendix G．こっちのほうがわかりやすいかも．\n",
    "\n",
    "次の集合$L_k$を定義します：\n",
    "\n",
    "$$\n",
    "L_k:= \\left\\{\n",
    "(s, a) \\in \\mathcal{S}\\times \\mathcal{A}: \n",
    "\\frac{1}{4}\n",
    "\\sum_{j<k} w_j(s, a) \\geq H \\ln \\frac{SAH}{\\delta'} + H\n",
    "\\right\\}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "**補題: Failure event**\n",
    "\n",
    "参考：\n",
    "* [Policy Certificates: Towards Accountable Reinforcement Learning](https://arxiv.org/abs/1811.03056)のLemma 6\n",
    "\n",
    "次のFailure Eventを考えます．\n",
    "\n",
    "$$\n",
    "F^N = \\left\\{\\exist k, s, a : n_k(s, a) < \\frac{1}{2}\\sum_{i < k} w_i(s, a) - H \\ln \\frac{SAH}{\\delta'}\\right\\}\n",
    "$$\n",
    "\n",
    "このとき，\n",
    "$$\n",
    "\\mathbb{P}\\left(F^N\\right) \\leq S A H \\delta^{\\prime}\n",
    "$$\n",
    "\n",
    "が成り立ちます．\n",
    "\n",
    "**証明**\n",
    "\n",
    "* $s \\in \\mathcal{S}, a \\in \\mathcal{A}, t \\in [H]$を固定します．\n",
    "* $\\mathcal{F}_k$を，$k$エピソード目の初期状態$s_{k, 1}$と，$k-1$エピソードまでから誘導される$\\sigma$代数とします．\n",
    "* $X_k$を，$s, a$がエピソード$k$の$t$ステップ目に訪問される指示関数とします．\n",
    "\n",
    "このとき，$X_k=1$である確率，つまり\n",
    "\n",
    "$$\n",
    "\\mathbb{P}\\left(s=s_{k, t}, a=a_{k, t} \\mid s_{k, 1}, \\pi_k\\right)\n",
    "$$\n",
    "\n",
    "は，$\\mathcal{F}_k$-measurableです．あとは次の補題に$W=\\ln \\frac{SAH}{\\delta'}$を当てはめて，Union boundを取れば成立します．\n",
    "\n",
    "**補題**\n",
    "\n",
    "* $i=1 \\ldots$について，$\\mathcal{F}_i$をフィルトレーションとする\n",
    "* $X_1, \\dots, X_n$をベルヌーイ確率変数とする\n",
    "    * ここで，$\\mathbb{P}\\left(X_i=1 \\mid \\mathcal{F}_{i-1}\\right)=P_i$であり，$P_i$は$\\mathcal{F}_{i-1}$-measurableかつ$X_i$は$\\mathcal{F}_i$-measurableである．\n",
    "  \n",
    "このとき，\n",
    "\n",
    "$$\n",
    "\\mathbb{P}\\left(\\exists n: \\sum_{t=1}^n X_t<\\sum_{t=1}^n P_t / 2-W\\right) \\leq e^{-W}\n",
    "$$\n",
    "\n",
    "が成り立つ．\n",
    "\n",
    "証明は[Unifying PAC and Regret: Uniform PAC Bounds for Episodic Reinforcement Learning](https://arxiv.org/abs/1703.07710)のLemma F.4参照．\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "**補題: Visitation Ratio**\n",
    "\n",
    "参考：\n",
    "* [Tighter Problem-Dependent Regret Bounds in Reinforcement Learning without Domain Knowledge using Value Function Bounds](https://arxiv.org/abs/1901.00210)のLemma 6\n",
    "\n",
    "$(F^N)^c$が成り立っているとき，$(s, a) \\in L_k$については，\n",
    "\n",
    "$$\n",
    "n_k(s, a) \\geq \\frac{1}{4} \\sum_{j \\leq k} w_j(s, a)\n",
    "$$\n",
    "\n",
    "が成り立つ．\n",
    "\n",
    "**証明**\n",
    "\n",
    "$(F^N)^c$が成り立っているので，次が成立します．\n",
    "$$\n",
    "\\begin{aligned}\n",
    "n_k(s, a) \\geq \\frac{1}{2} \\sum_{j<k} w_j(s, a)-H \\ln \\frac{S A H}{\\delta^{\\prime}}\n",
    "&=\\frac{1}{4} \\sum_{j<k} w_j(s, a)+\\frac{1}{4} \\sum_{j<k} w_j(s, a)-H \\ln \\frac{S A H}{\\delta^{\\prime}} \\\\\n",
    "&\\geq \\frac{1}{4} \\sum_{j<k} w_j(s, a)+H \\\\\n",
    "&\\geq \\frac{1}{4} \\sum_{j<k} w_j(s, a)+w_k(s, a) \\\\\n",
    "&\\geq \\frac{1}{4} \\sum_{j \\leq k} w_j(s, a)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "ここで2つ目の不等式は$(s, a) \\in L_k$を使ってます．\n",
    "\n",
    "---\n",
    "\n",
    "次の補題は，$(s, a) \\notin L_k$であれば，リグレットにはほぼ寄与しないことを示しています．\n",
    "\n",
    "**補題（Minimal Contribution）**\n",
    "\n",
    "参考：\n",
    "* [Tighter Problem-Dependent Regret Bounds in Reinforcement Learning without Domain Knowledge using Value Function Bounds](https://arxiv.org/abs/1901.00210)のLemma 7\n",
    "\n",
    "次が成立します．\n",
    "\n",
    "$$\n",
    "\\sum_{k=1}^K \\sum_{t=1}^H \\sum_{(s, a) \\notin L_k} w_{t k}(s, a) \\leq \\tilde{\\mathcal{O}}(SAH)\n",
    "$$\n",
    "\n",
    "**証明**\n",
    "\n",
    "定義より，$(s, a) \\notin L_k$であれば，\n",
    "\n",
    "$$\n",
    "\\frac{1}{4} \\sum_{j \\leq k} w_j(s, a)<H \\ln \\frac{S A H}{\\delta^{\\prime}}+H\n",
    "$$\n",
    "\n",
    "が成立します．よって，\n",
    "\n",
    "$$\n",
    "\\sum_{k=1}^K \\sum_{t=1}^H \\sum_{(s, a) \\notin L_k} w_{t k}(s, a)=\\sum_{s, a} \\sum_{k=1}^K w_k(s, a) 1\\left\\{(s, a) \\notin L_k\\right\\} \\leq \\sum_{s, a}\\left(4 H \\ln \\frac{S A H}{\\delta^{\\prime}}+4 H\\right) \\leq \\tilde{\\mathcal{O}}(SAH)\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "**補題（Visitation Ratio）**\n",
    "\n",
    "\n",
    "参考：\n",
    "* [Tighter Problem-Dependent Regret Bounds in Reinforcement Learning without Domain Knowledge using Value Function Bounds](https://arxiv.org/abs/1901.00210)のLemma 13\n",
    "\n",
    "$(F^N)^c$が成り立っているとき，次が成立します：\n",
    "\n",
    "$$\n",
    "{\\sum_{k=1}^K \\sum_{t=1}^H \\sum_{(s, a) \\in L_k} \\frac{w_{t k}(s, a)}{n_k(s, a)}} \\leq \\tilde{\\mathcal{O}}(\\sqrt{S A })\n",
    "$$\n",
    "\n",
    "証明は省略\n",
    "\n",
    "---\n",
    "\n",
    "**補題**\n",
    "\n",
    "参考\n",
    "* [Tight Regret Bounds for Model-Based Reinforcement Learning with Greedy Policies](https://arxiv.org/abs/1905.11527)のLemma 38\n",
    "* [Exploration Exploitation in Constrained MDPs](https://arxiv.org/abs/2003.02189)のLemma 36では$H$が$H^2$になってる．なぜ？\n",
    "* 結果自体は$\\frac{1}{\\sqrt{n}}$のバウンドであり，これは[RL_UCB_VI_regret_proof.ipynb](RL_UCB_VI_regret_proof.ipynb)では$H\\sqrt{SAK}$でバウンドされてます．もしかしたら下のやつ間違ってるかも．$H^2$のほうが正しいかもですね．\n",
    "\n",
    "$(F^N)^c$が成り立っているとき，次が成立します：\n",
    "\n",
    "$$\n",
    "\\sum_{k=1}^K \\sum_{t=1}^H \\mathbb{E}\\left[\\sqrt{\\frac{1}{n_{k-1}\\left(s_t^k, \\pi_k\\left(s_t^k\\right)\\right) \\vee 1}} \\mid \\mathcal{F}_{k-1}\\right] \\leq \\tilde{\\mathcal{O}}(\\sqrt{S A KH}+S A H)\n",
    "$$\n",
    "\n",
    "**証明**\n",
    "\n",
    "次が成立します．\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "& \\sum_{k=1}^K \\sum_{t=1}^H \\mathbb{E}\\left[\\sqrt{\\frac{1}{n_{k-1}\\left(s_t^k, \\pi_k\\left(s_t^k\\right)\\right) \\vee 1}} \\mid \\mathcal{F}_{k-1}\\right] \\\\\n",
    "& =\\sum_{k=1}^K \\sum_{t=1}^H \\sum_{s, a} w_{t k}(s, a) \\sqrt{\\frac{1}{n_{k-1}(s, a) \\vee 1}} \\\\\n",
    "& \\leq \\sum_{k=1}^K \\sum_{t=1}^H \\sum_{s, a \\in L_k} w_{t k}(s, a) \\sqrt{\\frac{1}{n_{k-1}(s, a)}}+\\sum_{k=1}^K \\sum_{t=1}^H \\sum_{s, a \\notin \\in L_k} w_{t k}(s, a) \\\\\n",
    "& \\leq \\sum_{k=1}^K \\sum_{t=1}^H \\sum_{s, a \\in L_k} w_{t k}(s, a) \\sqrt{\\frac{1}{n_{k-1}(s, a)}}+S A H .\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "また，\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "& \\sum_{k=1}^K \\sum_{t=1}^H \\sum_{s, a \\in L_k} w_{t k}(s, a) \\sqrt{\\frac{1}{n_{k-1}(s, a)}} \\\\\n",
    "& \\leq \\sqrt{\\sum_{k=1}^K \\sum_{t=1}^H \\sum_{s, a \\in L_k} w_{t k}(s, a)} \\sqrt{\\sum_{k=1}^K \\sum_{t=1}^H \\sum_{s, a \\in L_k} \\frac{w_{t k}(s, a)}{n_{k-1}(s, a)}} \\\\\n",
    "& \\leq \\sqrt{\\sum_{k=1}^K \\sum_{t=1}^H \\sum_{s, a} w_{t k}(s, a)} \\sqrt{\\sum_{k=1}^K \\sum_{t=1}^H \\sum_{s, a \\in L_k} \\frac{w_{t k}(s, a)}{n_{k-1}(s, a)}} \\\\\n",
    "& =\\sqrt{KH} \\sqrt{\\sum_{k=1}^K \\sum_{t=1}^H \\sum_{s, a} \\frac{w_{t k}(s, a)}{n_{k-1}(s, a)}} \\lesssim \\tilde{\\mathcal{O}}(\\sqrt{S A KH}) .\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "が成立します．ここで，$\\sum_{t=1}^H \\sum_{s, a} w_{t k}(s, a)=H$を使いました．\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regret Bound\n",
    "\n",
    "---\n",
    "\n",
    "**補題：On Policy Errors for Optimistic Model**\n",
    "\n",
    "参考：\n",
    "* [Exploration-Exploitation in Constrained MDPs](https://arxiv.org/abs/2003.02189)の補題29\n",
    "\n",
    "次が成立するとします：\n",
    "\n",
    "$$\n",
    "\\left|\\widetilde{p}_h^k\\left(s^{\\prime} \\mid s, a\\right)-p_h\\left(s^{\\prime} \\mid s, a\\right)\\right| \\lesssim \\sqrt{\\frac{p_h\\left(s^{\\prime} \\mid s, a\\right)}{n_h^{k-1}(s, a) \\vee 1}}+\\frac{1}{n_h^{k-1}(s, a) \\vee 1} .\n",
    "$$\n",
    "\n",
    "および\n",
    "\n",
    "$$\n",
    "n_h^{k-1}(s, a) \\leq \\frac{1}{2} \\sum_{j<k} q_h^{\\pi_k}(s, a \\mid p)-H \\ln \\frac{S A H}{\\delta^{\\prime}}\n",
    "$$\n",
    "\n",
    "また，$\\pi_k$を$k$エピソード目の方策とします．このとき，任意の$K'\\in [K]$について，\n",
    "\n",
    "$$\n",
    "\\sum_{k=1}^{K^{\\prime}}\\left|V_1^{\\pi_k}\\left(s_1 ; l, p\\right)-V_1^{\\pi_k}\\left(s_1 ; \\widetilde{l}_k, \\widetilde{p}_k\\right)\\right| \\leq \\widetilde{\\mathcal{O}}\\left(\\sqrt{S \\mathcal{N} H^4 K}+(\\sqrt{\\mathcal{N}}+H) H^2 S A\\right)\n",
    "$$\n",
    "\n",
    "が成立します．ここで，$\\mathcal{N}:=\\max _{s, a, h}\\left|\\left\\{s^{\\prime}: p_h\\left(s^{\\prime} \\mid s, a\\right)>0\\right\\}\\right|$は次状態への遷移確率が非ゼロになる最大個数です．\n",
    "\n",
    "**証明**\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "& \\sum_{k=1}^{K^{\\prime}}\\left|V_1^{\\pi_k}\\left(s_1 ; p\\right)-V_1^{\\pi_k}\\left(s_1 ; \\widetilde{p}_k\\right)\\right| \\\\\n",
    "& =\\sum_{k=1}^{K^{\\prime}}\\left|\\mathbb{E}\\left[\\sum_{h=1}^H\\left(p_h-\\widetilde{p}_h^k\\right)\\left(\\cdot \\mid s_h, a_h\\right) {V}_{h+1}^{\\pi_k}(\\cdot; \\widetilde{p}_k) \\mid s_1, p, \\pi_k\\right]\\right| \\\\\n",
    "&\\leq \\underbrace{\\sum_{k=1}^{K^{\\prime}} \\mathbb{E}\\left[\\sum_{h=1}^H \\sum_{s^{\\prime}}\\left|\\left(p_h-\\widetilde{p}_h^k\\right)\\left(s^{\\prime} \\mid s_h, a_h\\right)\\right|\\left|{V}_{h+1}^{\\pi_k}\\left(s^{\\prime} ; \\widetilde{p}_k\\right)\\right| \\mid s_1, p, \\pi_k\\right]}_{(i)}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "最後の(i)をバウンドしましょう．\n",
    "$V^\\pi$の部分は$H$以下なので外に出し，仮定を代入すると，\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "(i) & \\lesssim H \\sum_{k=1}^{K^{\\prime}} \\sum_{h=1}^H \\mathbb{E}\\left[\\sqrt{\\frac{1}{n_h^k\\left(s_h, a_h\\right) \\vee 1}} \\sum_{s^{\\prime}} \\sqrt{p_h\\left(s^{\\prime} \\mid s_h, a_h\\right)}+\\frac{S}{n_h^k\\left(s_h, a_h\\right) \\vee 1} \\mid s_1, p, \\pi_k\\right] \\\\\n",
    "& \\leq H \\sum_{k=1}^{K^{\\prime}} \\sum_{h=1}^H \\mathbb{E}\\left[\\sqrt{\\frac{1}{n_h^k\\left(s_h, a_h\\right) \\vee 1}} \\sqrt{\\mathcal{N}}\\sqrt{\\sum_{s^{\\prime}} p_h\\left(s^{\\prime} \\mid s_h, a_h\\right)}+\\frac{S}{n_h^k\\left(s_h, a_h\\right) \\vee 1} \\mid s_1, p, \\pi_k\\right] \\\\\n",
    "& =H \\sum_{k=1}^{K^{\\prime}} \\sum_{h=1}^H \\mathbb{E}\\left[\\sqrt{\\frac{1}{n_h^k\\left(s_h, a_h\\right) \\vee 1}} \\sqrt{\\mathcal{N}}+\\frac{S}{n_h^k\\left(s_h, a_h\\right) \\vee 1} \\mid s_1, p, \\pi_k\\right] \\\\\n",
    "& =H \\sum_{k=1}^{K^{\\prime}} \\sum_{h=1}^H \\mathbb{E}\\left[\\sqrt{\\frac{1}{n_h^k\\left(s_h^k, a_h^k\\right) \\vee 1}} \\sqrt{\\mathcal{N}}+\\frac{S}{n_h^k\\left(s_h^k, a_h^k\\right) \\vee 1} \\mid \\mathcal{F}_{k-1}\\right] \\\\\n",
    "& \\lesssim \\sqrt{S \\mathcal{N} H^4 K}+\\sqrt{\\mathcal{N}} H^2 S A+S H^3 A \\leq \\widetilde{\\mathcal{O}}\\left(\\sqrt{S \\mathcal{N} H^4 K}+(\\sqrt{\\mathcal{N}}+H) H^2 S A\\right) .\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "* １行目は$p$についての仮定を代入してます．\n",
    "* ２行目はJensenの不等式です．\n",
    "* ５行目はGood setの節でやった補題を使っています．\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 連続MDP\n",
    "\n",
    "---\n",
    "\n",
    "**補題: Lipschitz MDPでは価値関数もLipschitz**\n",
    "\n",
    "参考：\n",
    "* [Kernel-Based Reinforcement Learning: A Finite-Time Analysis](https://arxiv.org/abs/2004.05599)\n",
    "\n",
    "状態空間$\\mathcal{X}$と行動空間$\\mathcal{A}$について，$\\rho$を$\\rho\\left[(x, a),\\left(x^{\\prime}, a^{\\prime}\\right)\\right]=\\rho_{\\mathcal{X}}\\left(x, x^{\\prime}\\right)+\\rho_{\\mathcal{A}}(a, a')$であるような測度とします．\n",
    "次を仮定します：\n",
    "* 報酬関数が$\\lambda_r$-Lipshitzです．つまり，$\\left|r_h(x, a)-r_h\\left(x^{\\prime}, a^{\\prime}\\right)\\right| \\leq \\lambda_r \\rho\\left[(x, a),\\left(x^{\\prime}, a^{\\prime}\\right)\\right]$です．\n",
    "* 遷移確率は1-WassersteinについてLipschitzです．つまり，$W_1\\left(P_h(\\cdot \\mid x, a), P_h\\left(\\cdot \\mid x^{\\prime}, a^{\\prime}\\right)\\right) \\leq \\lambda_p \\rho\\left[(x, a),\\left(x^{\\prime}, a^{\\prime}\\right)\\right]$です．\n",
    "\n",
    "このとき，次が成立します．\n",
    "\n",
    "$$\\forall\\left(x, a, x^{\\prime}, a^{\\prime}\\right), \\forall h \\in[H], \\quad\\left|Q_h^*(x, a)-Q_h^*\\left(x^{\\prime}, a^{\\prime}\\right)\\right| \\leq L_h \\rho\\left[(x, a),\\left(x^{\\prime}, a^{\\prime}\\right)\\right]$$\n",
    "\n",
    "ここで，$L_h \\stackrel{\\text { def }}{=} \\sum_{h^{\\prime}=h}^H \\lambda_r \\lambda_p^{H-h^{\\prime}}$としました．\n",
    "\n",
    "**証明**\n",
    "\n",
    "帰納法で示します．$h=H$なら明らかに成立します．\n",
    "続いて，$h+1$のときに成立するか考えましょう．\n",
    "\n",
    "まず，$V_{h+1}^*(x)$はLipschitzになります．\n",
    "$$\n",
    "\\begin{aligned}\n",
    "V_{h+1}^*(x)-V_{h+1}^*\\left(x^{\\prime}\\right) & =\\max _a Q_{h+1}^*(x, a)-\\max _a Q_{h+1}^*\\left(x^{\\prime}, a\\right) \\leq \\max _a\\left(Q_{h+1}^*(x, a)-Q_{h+1}^*\\left(x^{\\prime}, a\\right)\\right) \\\\\n",
    "& \\leq \\max _a \\sum_{h^{\\prime}=h+1}^H \\lambda_r \\lambda_p^{H-h^{\\prime}} \\rho\\left[(x, a),\\left(x^{\\prime}, a\\right)\\right]=\\sum_{h^{\\prime}=h+1}^H \\lambda_r \\lambda_p^{H-h^{\\prime}} \\rho_{\\mathcal{X}}\\left(x, x^{\\prime}\\right),\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "最後の部分では$\\rho\\left[(x, a),\\left(x^{\\prime}, a^{\\prime}\\right)\\right]=\\rho_{\\mathcal{X}}\\left(x, x^{\\prime}\\right)+\\rho_{\\mathcal{A}}\\left(a, a^{\\prime}\\right)$であることを使っています．\n",
    "$x$と$x'$を逆にして同じことを示せば，\n",
    "\n",
    "$$\n",
    "\\left|V_{h+1}^*(x)-V_{h+1}^*\\left(x^{\\prime}\\right)\\right| \\leq \\sum_{h^{\\prime}=h+1}^H \\lambda_r \\lambda_p^{H-h^{\\prime}} \\rho_{\\mathcal{X}}\\left(x, x^{\\prime}\\right) .\n",
    "$$\n",
    "\n",
    "であることがわかります．\n",
    "最後に，\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "Q_h^*(x, a)-Q_h^*\\left(x^{\\prime}, a^{\\prime}\\right) & \\leq \\lambda_r \\rho\\left[(x, a),\\left(x^{\\prime}, a^{\\prime}\\right)\\right]+\\int_{\\mathcal{X}} V_{h+1}^*(y)\\left(P_h(\\mathrm{~d} y \\mid x, a)-P_h\\left(\\mathrm{~d} y \\mid x^{\\prime}, a^{\\prime}\\right)\\right) \\\\\n",
    "& \\leq \\lambda_r \\rho\\left[(x, a),\\left(x^{\\prime}, a^{\\prime}\\right)\\right]+L_{h+1} \\int_{\\mathcal{X}} \\frac{V_{h+1}^*(y)}{L_{h+1}}\\left(P_h(\\mathrm{~d} y \\mid x, a)-P_h\\left(\\mathrm{~d} y \\mid x^{\\prime}, a^{\\prime}\\right)\\right) \\\\\n",
    "& \\leq\\left[\\lambda_r+\\lambda_p \\sum_{h^{\\prime}=h+1}^H \\lambda_r \\lambda_p^{H-h^{\\prime}}\\right] \\rho\\left[(x, a),\\left(x^{\\prime}, a^{\\prime}\\right)\\right]=\\sum_{h^{\\prime}=h}^H \\lambda_r \\lambda_p^{H-h^{\\prime}} \\rho\\left[(x, a),\\left(x^{\\prime}, a^{\\prime}\\right)\\right]\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "が成立します．ここで，$V_{h+1}^* / L_{h+1}$が$1$-Lipschitzであることと，Wasserstein距離の定義を使いました．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "**補題：Covering Numberを使った２つの関数の大小の確率バウンド**\n",
    "\n",
    "参考：\n",
    "* [Kernel-Based Reinforcement Learning: A Finite-Time Analysis](https://arxiv.org/abs/2004.05599)のLemma 6\n",
    "\n",
    "$\\mathcal{N}(\\epsilon, \\mathcal{X} \\times \\mathcal{A}, \\rho)$を測度空間$(\\mathcal{X}\\times \\mathcal{A}, \\rho)$についての$\\epsilon$-covering numberとします．\n",
    "\n",
    "$(\\Omega, \\mathcal{T}, \\mathbb{P})$の確率空間を考えます．\n",
    "$F$, $G$を$\\mathcal{X} \\times \\mathcal{A} \\times \\Omega$ to $\\mathbb{R}$なる関数とし，\n",
    "$\\omega \\rightarrow F(x, a, \\omega)$ and $\\omega \\rightarrow G(x, a, \\omega)$を確率変数とします．\n",
    "\n",
    "また，関数$(x, a) \\rightarrow F(x, a, \\omega)$と$(x, a) \\rightarrow G(x, a, \\omega)$は，任意の$\\omega \\in \\Omega$について，それぞれ$L_F$と$L_G$-Lipschitzとします．\n",
    "\n",
    "このとき，\n",
    "\n",
    "$$\n",
    "\\forall(x, a), \\quad \\mathbb{P}[\\omega \\in \\Omega: G(x, a, \\omega) \\geq F(x, a, \\omega)] \\leq \\delta\n",
    "$$\n",
    "\n",
    "であれば，\n",
    "\n",
    "$$\n",
    "\\mathbb{P}\\left[\\omega \\in \\Omega: \\exists(x, a), G(x, a, \\omega) \\geq F(x, a, \\omega)+\\left(L_G+L_f\\right) \\epsilon\\right] \\leq \\delta \\mathcal{N}(\\epsilon, \\mathcal{X} \\times \\mathcal{A}, \\rho)\n",
    "$$\n",
    "\n",
    "が成り立ちます．\n",
    "\n",
    "証明は省略"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "**補題：Kernelを使った$\\frac{1}{n}$のバウンド**\n",
    "\n",
    "参考：\n",
    "* [Kernel-Based Reinforcement Learning: A Finite-Time Analysis](https://arxiv.org/abs/2004.05599)のLemma 6\n",
    "\n",
    "\n",
    "$u, v \\in \\mathcal{X} \\times \\mathcal{A}$とします．関数$g: \\mathbb{R}_{\\geq 0} \\rightarrow[0,1]$について，カーネル関数を\n",
    "\n",
    "$$\\psi_\\sigma(u, v) \\stackrel{\\text { def }}{=} g(\\rho[u, v] / \\sigma)$$\n",
    "とします．\n",
    "\n",
    "$(x, a)$ and $(s, h) \\in[K] \\times[H]$に対して，重み関数を\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "& w_h^s(x, a) \\stackrel{\\text { def }}{=} \\psi_\\sigma\\left((x, a),\\left(x_h^s, a_h^s\\right)\\right) \\quad \\text { and } \\\\\n",
    "& \\widetilde{w}_h^s(x, a) \\stackrel{\\text { def }}{=} \\frac{w_h^s(x, a)}{\\beta+\\sum_{l=1}^{k-1} w_h^l(x, a)},\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "として，疑似訪問頻度を\n",
    "\n",
    "$$\n",
    "\\mathbf{C}_h^k(x, a) \\stackrel{\\text { def }}{=} \\beta+\\sum_{s=1}^{k-1} w_h^s(x, a)\n",
    "$$\n",
    "\n",
    "とします．このとき，\n",
    "\n",
    "$$\n",
    "\\sum_{k=1}^K \\sum_{h=1}^H \\frac{1}{\\mathbf{C}_h^k\\left(\\tilde{x}_h^k, \\tilde{a}_h^k\\right)} \\mathbb{I}\\left\\{\\rho\\left[\\left(\\tilde{x}_h^k, \\tilde{a}_h^k\\right),\\left(x_h^k, a_h^k\\right)\\right] \\leq 2 \\sigma\\right\\} \\lesssim H\\left|\\mathcal{C}_\\sigma\\right|\n",
    "$$\n",
    "\n",
    "および\n",
    "\n",
    "$$\n",
    "\\sum_{k=1}^K \\sum_{h=1}^H \\frac{1}{\\sqrt{\\mathbf{C}_h^k\\left(\\tilde{x}_h^k, \\tilde{a}_h^k\\right)}} \\mathbb{I}\\left\\{\\rho\\left[\\left(\\tilde{x}_h^k, \\tilde{a}_h^k\\right),\\left(x_h^k, a_h^k\\right)\\right] \\leq 2 \\sigma\\right\\} \\lesssim H\\left|\\mathcal{C}_\\sigma\\right|+H \\sqrt{\\left|\\mathcal{C}_\\sigma\\right| K}\n",
    "$$\n",
    "\n",
    "が成立します．\n",
    "\n",
    "証明は省略"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 集中不等式\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "**補題：重み付きのHoeffdingに便利**\n",
    "\n",
    "参考：\n",
    "* [Kernel-Based Reinforcement Learning: A Finite-Time Analysis](https://arxiv.org/abs/2004.05599)のLemma 7\n",
    "\n",
    "非負の実数列$\\left\\{z_s\\right\\}_{s=1}^t$と，関数$g: \\mathbb{R}_{+} \\rightarrow[0,1]$を考えます．ここで，$g$は次を満たすとします．\n",
    "\n",
    "====\n",
    "\n",
    "関数$g: \\mathbb{R}_{\\geq 0} \\rightarrow[0,1]$は微分可能，non-increasing，$g(4) > 0$を満たし，また，次を満たす定数$C^g_1, C^g_2$が存在します：\n",
    "\n",
    "$$\n",
    "g(z) \\leq C_1^g \\exp \\left(-z^2 / 2\\right) \\text { and } \\sup _z\\left|g^{\\prime}(z)\\right| \\leq C_2^g\n",
    "$$\n",
    "\n",
    "例えば$g(z)=\\exp \\left(-z^2 / 2\\right)$のようなガウスカーネルが仮定を満たしています．\n",
    "\n",
    "====\n",
    "\n",
    "$\\beta > 0$について，\n",
    "\n",
    "$$\n",
    "w_s \\stackrel{\\text { def }}{=} g\\left(\\frac{z_s}{\\sigma}\\right) \\text { and } \\widetilde{w}_s \\stackrel{\\text { def }}{=} \\frac{w_s}{\\beta+\\sum_{s^{\\prime}=1}^t w_{s^{\\prime}}} \\text {. }\n",
    "$$\n",
    "\n",
    "のとき，$t\\geq 1$について，\n",
    "\n",
    "$$\n",
    "\\sum_{s=1}^t \\widetilde{w}_s z_s \\leq 2 \\sigma\\left(1+\\sqrt{\\log \\left(C_1^g t / \\beta+e\\right)}\\right)\n",
    "$$\n",
    "\n",
    "が成立します．\n",
    "\n",
    "証明は省略．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "**一様な集中不等式（無限のエピソードについてのUnion boundを取るときに便利です）**\n",
    "\n",
    "参考：\n",
    "* [Unifying PAC and Regret: Uniform PAC Bounds for Episodic Reinforcement Learning](https://arxiv.org/abs/1703.07710)のLemma F.1\n",
    "\n",
    "準備：\n",
    "\n",
    "* $\\operatorname{lnp}(x) =\\ln (\\ln (\\max \\{x, e\\}))$とします．\n",
    "\n",
    "$X_1, X_2, \\dots$をフィルトレーション$\\{\\mathcal{F}_t\\}_{t=1}^\\infty$についての\n",
    "$\\sigma^2$-subgaussianなマルチンゲール差分列とします．つまり，\n",
    "\n",
    "$$\n",
    "\\mathbb{E}\\left[\\exp \\left(\\lambda\\left(X_t-\\mu\\right)\\right) \\mid \\mathcal{F}_{t-1}\\right] \\leq \\exp \\left(\\lambda^2 \\sigma^2 / 2\\right)\n",
    "$$\n",
    "\n",
    "が全ての$\\lambda$についてa.s.で成立するとします．このとき，$\\hat{\\mu}_t=\\frac{1}{t} \\sum_{i=1}^t X_i$について，\n",
    "$$\n",
    "\\mathbb{P}\\left(\\exists t:\\left|\\hat{\\mu}_t-\\mu\\right| \\geq \\sqrt{\\frac{4 \\sigma^2}{t}\\left(2 \\operatorname{lnp}(t)+\\ln \\frac{3}{\\delta}\\right)}\\right) \\leq 2 \\delta\n",
    "$$\n",
    "が成り立ちます．\n",
    "\n",
    "**証明**\n",
    "\n",
    "$S_t=\\sum_{s=1}^t\\left(X_s-\\mu\\right)$とします．このとき，\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "& \\mathbb{P}\\left(\\exists t: \\hat{\\mu}_t-\\mu \\geq \\sqrt{\\frac{4 \\sigma^2}{t}\\left(2 \\operatorname{lnp}(t)+\\ln \\frac{3}{\\delta}\\right)}\\right) \\\\\n",
    "= & \\mathbb{P}\\left(\\exists t: S_t \\geq \\sqrt{4 \\sigma^2 t\\left(2 \\operatorname{lnp}(t)+\\ln \\frac{3}{\\delta}\\right)}\\right) \\\\\n",
    "\\leq & \\sum_{k=0}^{\\infty} \\mathbb{P}\\left(\\exists t \\in\\left[2^k, 2^{k+1}\\right]: S_t \\geq \\sqrt{4 \\sigma^2 t\\left(2 \\operatorname{lnp}(t)+\\ln \\frac{3}{\\delta}\\right)}\\right) \\\\\n",
    "\\leq & \\sum_{k=0}^{\\infty} \\mathbb{P}\\left(\\exists t \\leq 2^{k+1}: S_t \\geq \\sqrt{2 \\sigma^2 2^{k+1}\\left(2 \\operatorname{lnp}\\left(2^k\\right)+\\ln \\frac{3}{\\delta}\\right)}\\right)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "最初の不等式はpeeling deviceってやつです（バンディット本のLemma 9.3あたりでも使ってます）．\n",
    "$t \\geq 0$について証明するときに便利ですね．\n",
    "\n",
    "続いて，$\\lambda > 0$について$M_t=\\exp(\\lambda S_t)$とします．\n",
    "これは非負のsubmartingaleです．\n",
    "また，\n",
    "\n",
    "$$\n",
    "f=\\sqrt{2 \\sigma^2 2^{k+1}\\left(2 \\ln p\\left(2^k\\right)+\\ln \\frac{3}{\\delta}\\right)}\n",
    "$$\n",
    "\n",
    "とします．\n",
    "まず\n",
    "$$\n",
    "\\mathbb{P}\\left(\\exists t \\leq 2^{k+1}: S_t \\geq f\\right)=\\mathbb{P}\\left(\\max _{t \\leq 2^{k+1}} M_t \\geq \\exp (\\lambda f)\\right) $$\n",
    "として変形できます．さらに，DoobのMaximal inequality（バンディット本のTheorem 3.9）より，\n",
    "$$\n",
    "\\mathbb{P}\\left(\\max _{t \\leq 2^{k+1}} M_t \\geq \\exp (\\lambda f)\\right)\n",
    "\\leq \\frac{\\mathbb{E}\\left[M_{2^{k+1}}\\right]}{\\exp (\\lambda f)} \\leq \\exp \\left(2^{k+1} \\frac{\\lambda^2 \\sigma^2}{2}-\\lambda f\\right)\n",
    "$$\n",
    "\n",
    "が成り立ちます．ここで，$\\lambda=\\frac{f}{\\sigma^2 2^{k+1}}$とおけば，\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathbb{P}\\left(\\exists t \\leq 2^{k+1}: S_t \\geq f\\right) & \\leq \\exp \\left(-\\frac{f^2}{2^{k+2} \\sigma^2}\\right)\\\\\n",
    "&=\\exp \\left(-2 \\operatorname{lnp}\\left(2^k\\right)-\\ln \\frac{3}{\\delta}\\right)\\\\\n",
    "&=\\frac{\\delta}{3} \\exp \\left(-2 \\operatorname{lnp}\\left(2^k\\right)\\right) \\\\\n",
    "& =\\frac{\\delta}{3} \\exp \\left(-\\max \\left\\{0,2 \\ln \\max \\left\\{0, \\ln 2^k\\right\\}\\right\\}\\right)\\\\\n",
    "&=\\frac{\\delta}{3} \\min \\left\\{1,(k \\ln 2)^{-2}\\right\\} \\\\\n",
    "& \\leq \\frac{\\delta}{3} \\min \\left\\{1, \\frac{1}{k^2 \\ln 2}\\right\\}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "この結果を最初のPeeling deviceの不等式に代入して，\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathbb{P}\\left(\\exists t: \\hat{\\mu}_t-\\mu \\geq \\sqrt{\\frac{4 \\sigma^2}{t}\\left(2 \\ln \\mathrm{p}(t)+\\ln \\frac{3}{\\delta}\\right)}\\right) & \\leq \\frac{\\delta}{3} \\sum_{k=0}^{\\infty} \\min \\left\\{1, \\frac{1}{k^2 \\ln (2)}\\right\\} \\\\\n",
    "& =\\delta \\frac{1}{3}\\left(\\frac{\\pi^2}{6 \\ln 2}+2-1 / \\ln (2)\\right) \\leq \\delta\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "が得られます．\n",
    "これは片側のバウンドですが，逆側も同様にして出すことができます．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
