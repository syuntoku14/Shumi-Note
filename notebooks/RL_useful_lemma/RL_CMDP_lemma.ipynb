{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 制約付きMDP系の便利な補題\n",
    "\n",
    "### 制約付き凸最適化\n",
    "\n",
    "参考：\n",
    "* [Exploration-Exploitation in Constrained MDPs](https://arxiv.org/abs/2003.02189)のAppendix G\n",
    "\n",
    "準備：\n",
    "\n",
    "次の制約付き最適化を考えましょう．\n",
    "\n",
    "$$\n",
    "f_{\\mathrm{opt}}=\\min _{\\mathbf{x} \\in X}\\{f(\\mathbf{x}): \\mathbf{g}(\\mathbf{x}) \\leq \\mathbf{0}, \\mathbf{A} \\mathbf{x}+\\mathbf{b}=\\mathbf{0}\\}\n",
    "$$\n",
    "\n",
    "ここで，$\\mathbf{g}(\\mathbf{x}):=\\left(g_1(\\mathbf{x}), . ., g_I(\\mathbf{x})\\right)^T$と$f, g_1, . ., g_m: \\mathbb{E} \\rightarrow(-\\infty, \\infty)$は凸な実数関数です．また，$\\mathbf{A} \\in \\mathbb{R}^{p \\times n}, \\mathbf{b} \\in \\mathbb{R}^p$とします．\n",
    "\n",
    "これに対して，感度関数を\n",
    "\n",
    "$$\n",
    "v(\\mathbf{u}, \\mathbf{t})=\\min _{\\mathbf{x} \\in X}\\{f(\\mathbf{x}): \\mathbf{g}(\\mathbf{x}) \\leq \\mathbf{u}, \\mathbf{A} \\mathbf{x}+\\mathbf{b}=\\mathbf{t}\\}\n",
    "$$\n",
    "\n",
    "とします．\n",
    "また，双対関数を\n",
    "\n",
    "$$\n",
    "q(\\lambda, \\mu)=\\min _{x \\in X}\\left\\{L(\\mathbf{x}, \\lambda, \\mu)=f(\\mathbf{x})+\\lambda^T \\mathbf{g}(\\mathbf{x})+\\mu^T(\\mathbf{A} \\mathbf{x}+\\mathbf{b})\\right\\}\n",
    "$$\n",
    "\n",
    "として（$\\lambda \\in \\mathbb{R}_{+}^m, \\mu \\in \\mathbb{R}^p$です．），双対問題を\n",
    "\n",
    "$$\n",
    "q_{\\mathrm{opt}}=\\max _{\\lambda \\in \\mathbb{R}_{+}^m, \\mu \\in \\mathbb{R}^p}\\{q(\\lambda, \\mu):(\\lambda, \\mu) \\in \\operatorname{dom}(-q)\\}\n",
    "$$\n",
    "\n",
    "とします．ここで，$\\operatorname{dom}(-q)=\\left\\{(\\lambda, \\mu) \\in \\mathbb{R}_{+}^m, \\mu \\in \\mathbb{R}^p: q(\\lambda, \\mu)>-\\infty\\right\\}$です．\n",
    "\n",
    "---\n",
    "\n",
    "仮定：\n",
    "\n",
    "最適値は有限であり，$g(\\overline{\\mathbf{x}})<0$および$\\mathbf{A} \\widehat{\\mathbf{x}}+\\mathbf{b}=0$であるような$\\bar{x}$と$\\widehat{\\mathbf{x}} \\in \\operatorname{ri}(X)$が存在するとします．\n",
    "ここで，$\\operatorname{ri}(X)$は$X$の相対的内部です．\n",
    "\n",
    "---\n",
    "\n",
    "**定理**\n",
    "\n",
    "$(\\lambda^*, \\mu^*)$は次を満たし，またそのときに限り最適解です．\n",
    "\n",
    "$$\n",
    "-\\left(\\lambda^*, \\mu^*\\right) \\in \\partial v(\\mathbf{0}, \\mathbf{0})\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "**定理**\n",
    "\n",
    "$2\\left\\|\\lambda^*\\right\\|_1 \\leq \\rho$とします．\n",
    "$\\widetilde{\\mathbf{x}}$ は$\\mathbf{A} \\widetilde{\\mathbf{x}}+\\mathbf{b}=0$\n",
    "および\n",
    "$$\n",
    "f(\\widetilde{\\mathbf{x}})-f_{o p t}+\\rho\\left\\|[g(\\widetilde{\\mathbf{x}})]_{+}\\right\\|_{\\infty} \\leq \\delta,\n",
    "$$\n",
    "とします．このとき，\n",
    "\n",
    "$$\n",
    "\\left\\|[g(\\widetilde{\\mathbf{x}})]_{+}\\right\\|_{\\infty} \\leq \\frac{\\delta}{\\rho}\n",
    "$$\n",
    "\n",
    "が成立します．\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 制約付きMDP\n",
    "\n",
    "表記（[Last-Iterate Convergent Policy Gradient Primal-Dual Methods for Constrained MDPs](https://arxiv.org/abs/2306.11700)参照）：\n",
    "\n",
    "* 制約付きMDP：$\\underset{\\pi \\in \\Pi}{\\operatorname{maximize}} V_r^\\pi(\\rho) \\quad \\text { subject to } V_u^\\pi(\\rho) \\geq b$：\n",
    "* $g:=u-(1-\\gamma) b$とする\n",
    "* $L(\\pi, \\lambda):=V_r^\\pi(\\rho)+\\lambda V_g^\\pi(\\rho)$\n",
    "* ラグランジュ形式：$\\underset{\\pi \\in \\Pi}{\\operatorname{maximize}} \\underset{\\lambda \\in[0, \\infty]}{\\operatorname{minimize}} V_{r+\\lambda g}^\\pi(\\rho)$\n",
    "    * 鞍点$(\\pi', \\lambda')$：$V_{r+\\lambda^{\\prime} g}^\\pi(\\rho) \\leq V_{r+\\lambda^{\\prime} g}^{\\pi^{\\prime}}(\\rho) \\leq V_{r+\\lambda g}^{\\pi^{\\prime}}(\\rho)$\n",
    "* 主問題：$V_P^\\pi(\\rho):=\\inf _{\\lambda \\in[0, \\infty]} V_{r+\\lambda g}^\\pi(\\rho)$\n",
    "* 双対問題：$V_D^\\lambda(\\rho):=\\max _{\\pi \\in \\Pi} V_{r+\\lambda g}^\\pi(\\rho)$\n",
    "\n",
    "---\n",
    "\n",
    "**補題：強双対性**\n",
    "\n",
    "参考：\n",
    "* [Safe Policies for Reinforcement Learning via Primal-Dual Methods](https://arxiv.org/abs/1911.09101)のTheorem 3\n",
    "\n",
    "$$\n",
    "V_P^{\\pi^{\\star}}(\\rho)=V_D^{\\lambda^{\\star}}(\\rho)\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "**補題：未定乗数の範囲**\n",
    "\n",
    "参考：\n",
    "* [Natural Policy Gradient Primal-Dual Method for Constrained Markov Decision Processes](https://proceedings.neurips.cc/paper/2020/hash/5f7695debd8cde8db5abcb9f161b49ea-Abstract.html)のLemma 1\n",
    "\n",
    "次のFeasibilityが成立するとする：$\\bar{\\pi} \\in \\Pi$ and $\\xi>0$ such that $V_g^{\\bar{\\pi}}(\\rho) \\geq \\xi$．\n",
    "このとき，\n",
    "\n",
    "$$\n",
    "\\lambda^{\\star} \\in\\left[0,\\left(V_r^{\\bar{\\pi}}-V_r^{\\pi^{\\star}}\\right) / \\xi\\right]\n",
    "$$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
