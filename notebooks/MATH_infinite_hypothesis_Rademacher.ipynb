{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 仮説集合が無限のとき\n",
    "\n",
    "[MATH_finite_hypothesis_bound.ipynb](MATH_finite_hypothesis_bound.ipynb)の続きです．\n",
    "ちょっとおさらいしてみましょう．\n",
    "\n",
    "* 実現可能なとき：$\\hat{R}(h)=0$を満たす任意の$h$について，\n",
    "$$\n",
    "\\mathbb{P}[R(\\hat{h})>\\epsilon] =\\mathbb{P}\\left[{h} \\in \\mathcal{H}_{>\\epsilon}\\right] \n",
    "\\leq \\sum_{h \\in \\mathcal{H}_{>\\epsilon}} \\mathbb{P}\\left[\\widehat{R}(h)=0\\right]\n",
    "\\leq \\left|\\mathcal{H}\\right| \\exp (-\\epsilon n)\n",
    "$$\n",
    "* 実現不可能なとき：\n",
    "$R(h_S) - R(h_0) \\leq {R(h_S) - \\hat{R}(h_S)}  + {\\hat{R}(h_\\mathcal{H}) - R(h_\\mathcal{H})} + {R(h_\\mathcal{H}) - R(h_0)}$を使い，最初の２項をUnion boundで$|\\mathcal{H}|$についてバウンド．\n",
    "\n",
    "さて，無限のときは$\\mathcal{H}$のサイズに対してUnion boundを取ってバウンドするやり方が通用しません．\n",
    "\n",
    "無限の場合は次の\n",
    "1. McDiarmidの不等式を使ってtail boundを期待値計算へ変換し，\n",
    "2. その後ラデマッハ複雑度で無限集合のサイズを抑えます．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## McDiarmidの不等式\n",
    "\n",
    "関数$f$が，任意の$x_1, \\dots, x_n, x_i'$において以下を満たすとします．\n",
    "\n",
    "$$\n",
    "\\left|f\\left(x_1, \\ldots, x_i, \\ldots, x_n\\right)-f\\left(x_1, \\ldots, x_i^{\\prime}, \\ldots, x_n\\right)\\right| \\leq c_i\n",
    "$$\n",
    "\n",
    "また，$X_1, \\dots, X_n$を独立な確率変数とします．このとき，\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&\\mathbb{P}\\left[f\\left(X_1, \\ldots, X_n\\right)-\\mathbb{E}\\left[f\\left(X_1, \\ldots, X_n\\right)\\right]>\\epsilon\\right] \\leq \\exp \\left(-\\frac{2 \\epsilon^2}{\\sum_{i=1}^n c_i^2}\\right)\\\\\n",
    "&\\mathbb{P}\\left[f\\left(X_1, \\ldots, X_n\\right)-\\mathbb{E}\\left[f\\left(X_1, \\ldots, X_n\\right)\\right]\\leq-\\epsilon\\right] \\leq \\exp \\left(-\\frac{2 \\epsilon^2}{\\sum_{i=1}^n c_i^2}\\right) .\n",
    "\\end{aligned}\n",
    "$$\n",
    "が成立します．\n",
    "\n",
    "これはつまり$X_1, \\dots, X_n$の**関数**についての確率不等式です．\n",
    "Hoeffdingはこの「関数」が「期待値」だっただけですね．\n",
    "$f(X_1,\\dots, X_n)=\\frac{1}{n}\\sum_i X_i$としましょう．$|X|\\leq A$なら，\n",
    "\n",
    "$$\n",
    "\\left|f\\left(x_1, \\ldots, x_i, \\ldots, x_n\\right)-f\\left(x_1, \\ldots, x_i^{\\prime}, \\ldots, x_n\\right)\\right| \n",
    "=\\left|\\frac{x_i - x_i'}{n}\\right| \\leq \\frac{2A}{n}\n",
    "$$\n",
    "\n",
    "が成り立ちます．あとは$c_i$に上の式を代入すると，McDiarmidはHoeffdingを一般化していることがわかります．\n",
    "\n",
    "また，$f$の取る値を$[a, b]$とすると，少なくとも$1-\\delta$の確率で\n",
    "$$\n",
    "\\left|f\\left(X_1, \\ldots, X_n\\right)-\\mathbb{E}\\left[f\\left(X_1, \\ldots, X_n\\right)\\right]\\right| \\leq(b-a) \\sqrt{\\frac{n \\log \\frac{2}{\\delta}}{2}}\n",
    "$$\n",
    "が成り立ちます．これは後で使います．\n",
    "\n",
    "**証明**\n",
    "\n",
    "McDiarmidの不等式を示すため，先に次のAzumaの不等式を示します．\n",
    "\n",
    "---\n",
    "\n",
    "**Azumaの不等式**\n",
    "\n",
    "確率変数$X_i$, $Z_i$, $V_i$，$i=1, \\dots, n$に対して，$V_i$は$X_1, \\dots, X_i$の関数として表すことができ，$\\mathbb{E}[V_i \\mid X_1, \\dots, X_{i-1}]=0$が成り立つとします．\n",
    "また$Z_i$は$X_1, \\dots, X_{i-1}$の関数として表すことができ，定数$c_1, \\dots, c_n$が存在して$Z_i \\leq V_i \\leq Z_i + c_i$が成り立つとします．このとき，任意の$\\varepsilon > 0$に対して\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\operatorname{Pr}\\left(S_n \\geq \\varepsilon\\right) &\\leq \\exp \\left\\{-\\frac{2\\varepsilon^2}{\\sum^{n}_{i=1}c_i^2}\\right\\}\\\\\n",
    "\\operatorname{Pr}\\left(S_n \\leq -\\varepsilon\\right) &\\leq \\exp \\left\\{-\\frac{2\\varepsilon^2}{\\sum^{n}_{i=1}c_i^2}\\right\\}\\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "ここで部分和$\\sum^k_{i=1} V_i$を$S_k$とおきました．\n",
    "\n",
    "**証明**\n",
    "\n",
    "$t=4\\varepsilon / \\sum^n_{i=1} c_i^2 > 0$とおくと，\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\operatorname{Pr}(S_n \\geq \\varepsilon)\n",
    "&\\leq e^{-t\\varepsilon} \\mathbb{E}[e^{tS_n}]\\\\\n",
    "&= e^{-t\\varepsilon} \\mathbb{E}_{X_1, \\dots, X_{n-1}}[e^{tS_{n-1}}\\mathbb{E}_{X_n}[e^{tV_n}\\mid X_{1}, \\dots, X_{n-1}]]\\\\\n",
    "&\\leq e^{-t\\varepsilon} \\mathbb{E}_{X_1, \\dots, X_{n-1}}[e^{tS_{n-1}}]e^{t^2c_n^2/8}\\\\\n",
    "&\\leq e^{-t\\varepsilon} e^{t^2\\sum_{i=1}^n c_i^2/8}\\\\\n",
    "&= e^{-2\\varepsilon^2 / \\sum_{i=1}^n c_i^2}\\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "ここで１行目はマルコフの不等式，２行目はタワールール，３行目は$X_1, \\dots, X_{n-1}$で条件づけたおかげでHoeffdingが使えて，４行目はそれを繰り返し適用しています．\n",
    "\n",
    "---\n",
    "\n",
    "さて，McDiarmidの不等式を示しましょう．\n",
    "\n",
    "$f(X_1, \\dots, X_n)$を$f(S)$で略記します．また，$V_1, \\dots, V_n$を\n",
    "$$\n",
    "V_k = \n",
    "\\mathbb{E}[f(S) \\mid X_1, \\dots, X_k] - \\mathbb{E}[f(S) \\mid X_1, \\dots, X_{k-1}] \n",
    "$$\n",
    "とします．ここで$V_1$は$\\mathbb{E}[f(S) \\mid X_1] - \\mathbb{E}[f(S)]$とします．\n",
    "この$V_k$はAzumaの不等式の満たします（TODO:証明書く）．\n",
    "これより，$\\sum^n_{i=1} V_i = f(S) - \\mathbb{E}[f(S)]$とすると，Azumaの不等式からMcdirmidの不等式も成り立ちます．\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ラデマッハ複雑度\n",
    "\n",
    "ラデマッハ複雑度は次で定義されます：\n",
    "\n",
    "---\n",
    "\n",
    "**経験ラデマッハ複雑度**\n",
    "\n",
    "実数値関数の集合$\\mathcal{F}\\subset\\{f: \\mathcal{X}\\to \\mathbb{R}\\}$を考えます。\n",
    "入力点の集合$S=\\{x_1, x_2, \\dots, x_n\\}\\subset \\mathcal{X}$を考えます。\n",
    "また、$+1$と$-1$を等確率で取る独立な確率変数を$\\sigma_1, \\dots, \\sigma_n$とします。\n",
    "このとき、$\\mathcal{F}$の経験ラデマッハ複雑度は\n",
    "\n",
    "$$\n",
    "\\widehat{\\mathcal{R}}_S(\\mathcal{F}) = \\mathbb{E}_\\sigma \\left[\\sup_{f\\in \\mathcal{F}} \\frac{1}{n} \\sum^n_{i=1}\\sigma_i f(x_i)\\right]\n",
    "$$\n",
    "で定義されます。\n",
    "\n",
    "経験ラデマッハ複雑度は、$S$上のランダムなラベル付けに対して関数集合$\\mathcal{G}$のデータへの適合度を平均的に図っていることになります。\n",
    "つまり，$\\mathcal{F}$が複雑な関数を表現できるほど$\\widehat{R}_S(\\mathcal{F})$の値は大きくなります．\n",
    "\n",
    "**ラデマッハ複雑度**\n",
    "\n",
    "経験ラデマッハ複雑度をデータについて期待値を取ったものをラデマッハ複雑度と呼びます．\n",
    "\n",
    "$$\\mathcal{R}_n(\\mathcal{F})=\\mathbb{E}_{S\\sim \\mathcal{D}}[\\widehat{\\mathcal{R}}_S(\\mathcal{F})]$$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ラデマッハ複雑度による汎化誤差バウンド\n",
    "\n",
    "**補足：ここでのバウンドのやり方は[MATH_finite_hypothesis_bound.ipynb](MATH_finite_hypothesis_bound.ipynb)とはちょっと違うので面食らうかもしれない．後で似たようなバウンドの出し方について触れておく**\n",
    "\n",
    "さて，汎化誤差のバウンドに戻りましょう．\n",
    "少し一般化した話を考えます．損失関数$\\ell((x, y), h)$は$[a, b]$上の値を取る関数とします．また，\n",
    "$\\mathcal{H}$上の関数で計算される$\\ell((\\cdot, \\cdot), h)$の集合を$\\mathcal{L}$とします．つまり，$\\mathcal{L}=\\{((x, y), h) \\mapsto \\ell((x, y), h) \\mid(x, y) \\in \\mathcal{X} \\times \\mathcal{Y}, h \\in \\mathcal{H}\\}$とします．\n",
    "\n",
    "### 1. $\\sup_{h \\in \\mathcal{H}} R(h) - \\hat{R}(h)$とゴールの関係を考えよう\n",
    "\n",
    "データに依存した確率変数：\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\hat{G}&=\\sup_{h \\in \\mathcal{H}} R(h) - \\hat{R}(h)\\\\\n",
    "\\hat{G}^-&=\\sup_{h \\in \\mathcal{H}} -(R(h) - \\hat{R}(h))\\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "とします．\n",
    "\n",
    "次の状況を考えましょう（つまり，経験誤差と期待誤差が最もデカくなる仮説でも，その差は$\\epsilon/ 2$で抑えられる状況です）\n",
    "$$\\mathbb{P}\\left[\\widehat{G}>\\frac{\\epsilon}{2}\\right] \\leq \\frac{\\delta}{2},\\; \\mathbb{P}\\left[\\widehat{G}^{-}>\\frac{\\epsilon}{2}\\right] \\leq \\frac{\\delta}{2}$$\n",
    "ならば次が成立します．\n",
    "\n",
    "$$\\mathbb{P}\\left[\\sup_{h \\in \\mathcal{H}}|\\hat{R}(h) - R(h)| > \\epsilon / 2\\right] \\leq \n",
    "\\mathbb{P}\\left[\\widehat{G}>\\frac{\\epsilon}{2}\\right] + \\mathbb{P}\\left[\\widehat{G}^- >\\frac{\\epsilon}{2}\\right] \\leq \\delta$$\n",
    "\n",
    "なので，\n",
    "$\\mathbb{P}\\left[\\widehat{G}>\\frac{\\epsilon}{2}\\right] \\leq \\frac{\\delta}{2},\\; \\mathbb{P}\\left[\\widehat{G}^{-}>\\frac{\\epsilon}{2}\\right] \\leq \\frac{\\delta}{2}$を示していきましょう．\n",
    "\n",
    "\n",
    "## 2. $\\hat{G}$をMcdirmidで使える形にしよう\n",
    "\n",
    "$\\hat{G}'$をデータの一つを変化させたものとします．このとき，\n",
    "$$\n",
    "\\hat{G}'=\\sup_{h \\in \\mathcal{H}} R(h) - \\hat{R}(h) + \\frac{1}{n} (\\ell - \\ell')\n",
    "$$\n",
    "なので，$\\hat{G} - \\hat{G}' \\leq \\frac{b-a}{n}$が成り立つのはすぐにわかります．\n",
    "すると，McDiarmidの不等式から，少なくとも$1-\\delta / 2$の確率で\n",
    "\n",
    "$$\\widehat{G} \\leq \\mathbb{E}\\left[\\widehat{G}\\right]+(b-a) \\sqrt{\\frac{\\log \\frac{2}{\\delta}}{2 n}}$$\n",
    "\n",
    "が成り立ちます．Hoeffdingでは固定された$h$に対して$R(h) - \\hat{R}(h)$をバウンドしていきましたが，今回は$\\sup_h R(h) - \\hat{R}(h)$を直接バウンドしたいわけですね．$\\sup$のせいで平均の形になっていないので，ここではMcdirmidで抑えています．\n",
    "\n",
    "## 3. $\\mathbb{E}[\\hat{G}]$をラデマッハ複雑度で上から抑えよう\n",
    "\n",
    "\n",
    "最後に\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathbb{E}[\\hat{G}]\n",
    "&=\\mathbb{E}_{S \\sim \\mathcal{D}}\\left[\\sup_{h\\in\\mathcal{H}} \\mathbb{E}_{S' \\sim \\mathcal{D}}[\\hat{R}'(h)] -\\hat{R}(h)\\right]\\\\\n",
    "&\\leq\\mathbb{E}_{S \\sim \\mathcal{D}}\\left[ \\mathbb{E}_{S' \\sim \\mathcal{D}}\\left[\\sup_{h\\in\\mathcal{H}}\\hat{R}'(h) -\\hat{R}(h)\\right]\\right]\\\\\n",
    "&=\\mathbb{E}_{S \\sim \\mathcal{D}}\\left[ \\mathbb{E}_{S' \\sim \\mathcal{D}}\\left[\\sup_{h\\in\\mathcal{H}}\\frac{1}{n}\\sum_{i}\\ell((x_i', y_i'), h) - \\ell((x_i, y_i), h)\\right]\\right]\\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "が成り立ちます．\n",
    "\n",
    "ここで，$\\ell((x_i', y_i'), h) - \\ell((x_i, y_i), h)$は期待値の計算に対称性があるので，その正負の符号は$S\\sim \\mathcal{D}$と$S'\\sim \\mathcal{D}$によってランダムに決まります．\n",
    "よって，\n",
    "$\\ell' - \\ell$と$\\sigma\\left(\\ell' - \\ell\\right)$は同じ分布です．\n",
    "以上から，上の式はさらに\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&=\\mathbb{E}_{S \\sim \\mathcal{D}}\\left[ \\mathbb{E}_{S' \\sim \\mathcal{D}}\\mathbb{E}_\\sigma\\left[\\sup_{h\\in\\mathcal{H}}\\frac{1}{n}\\sum_{i}\\sigma_i\\cdot\\left(\\ell((x_i', y_i'), h) - \\ell((x_i, y_i), h)\\right)\\right]\\right]\\\\\n",
    "&\\leq\\mathbb{E}_{S \\sim \\mathcal{D}, \\sigma}\\left[\\sup_{h\\in\\mathcal{H}}\\frac{1}{n}\\sum_{i}\\sigma_i \\cdot \\ell((x_i, y_i), h)\\right]\n",
    "+ \\mathbb{E}_{S' \\sim \\mathcal{D}, \\sigma}\\left[\\sup_{h\\in\\mathcal{H}}\\frac{1}{n}\\sum_{i}(-\\sigma_i) \\cdot \\ell((x_i', y_i'), h)\\right]\\\\\n",
    "&=2 \\mathcal{R}_n(\\mathcal{L})\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "## 4. 汎化誤差バウンドと合体しよう\n",
    "\n",
    "あとは[MATH_finite_hypothesis_bound.ipynb](MATH_finite_hypothesis_bound.ipynb)でやった\n",
    "$$\n",
    "R(h_S) - R(h_\\mathcal{H})\n",
    "\\leq \n",
    "2 \\sup_{h \\in \\mathcal{H}} |\\hat{R}(h) - R(h)|\n",
    "$$\n",
    "と合体して終わりです．\n",
    "最終的に，少なくとも$1-\\delta$以上の確率で\n",
    "\n",
    "$$\n",
    "R(h_S) - R(h^*) \\leq 4\\mathcal{R}_n(\\mathcal{L}) + (b-a) \\sqrt{\\frac{2\\log \\frac{2}{\\delta}}{n}}\n",
    "$$\n",
    "です．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 仮説集合に対してのラデマッハ複雑度\n",
    "\n",
    "上で出したバウンドは$\\mathcal{R}_n(\\mathcal{L})$についてでした．\n",
    "これは損失関数の集合に対しての複雑度であり，仮説集合$\\mathcal{H}$についての複雑度ではありません．\n",
    "\n",
    "そこで，損失関数についての複雑度を仮説集合についての複雑度に変形しましょう．\n",
    "\n",
    "### バイナリ仮説のとき\n",
    "\n",
    "* 仮説関数$h: \\mathcal{X} \\rightarrow\\{-1,+1\\}$の集合を$\\mathcal{H}$\n",
    "* 損失関数$\\ell((x, y), h)=\\mathbb{I}(y \\neq h(x))$の集合を$\\mathcal{L}_{0-1}$とします．\n",
    "\n",
    "このとき，$\\mathbb{I}(y \\neq h(x))=\\frac{1}{2}(1-y h(x))$であることを使えば，\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathcal{R}_n(\\mathcal{L}_{0-1})=\n",
    "& \\mathbb{E}_{\\mathcal{D}}\\left[\\mathbb{E}_\\sigma\\left[\\sup _{\\ell \\in \\mathcal{L}} \\frac{1}{n} \\sum_{i=1}^n \\underbrace{\\frac{\\sigma_i}{2}\\left(1-y_i h\\left(x_i\\right)\\right)}_{=\\sigma_i \\ell\\left(\\left(x_i, y_i\\right), h\\right)}\\right]\\right] \\\\\n",
    "& \\left.=\\frac{1}{2} \\mathbb{E}_{\\mathcal{D}}\\left[\\mathbb{E}_\\sigma\\left[\\sup _{h \\in \\mathcal{H}}\\frac{1}{n} \\sum_{i=1}^n \\sigma_i+\\frac{1}{n} \\sum_{i=1}^n-\\sigma_i y_i h\\left(x_i\\right)\\right)\\right]\\right] \\\\\n",
    "& =\\frac{1}{2} \\mathbb{E}_{\\mathcal{D}}\\left[\\mathbb{E}_\\sigma\\left[\\sup _{h \\in \\mathcal{H}} \\frac{1}{n} \\sum_{i=1}^n \\underbrace{\\left(-\\sigma_i y_i\\right)}_{\\text {ランダムラベル}} h\\left(x_i\\right))\\right]\\right] \\\\\n",
    "& =\\frac{1}{2} \\mathcal{R}_n(\\mathcal{H})\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "なので，\n",
    "$$\n",
    "\\mathcal{R}_n(\\mathcal{L}_{0-1})=\n",
    "\\frac{1}{2}\\mathcal{R}_n(\\mathcal{H})\n",
    "$$\n",
    "が示せました．\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 有限集合のラデマッハ複雑度\n",
    "\n",
    "さて，上では損失関数のラデマッハ複雑度を仮説集合のラデマッハ複雑度に変形しました．続いて，有限集合のラデマッハ複雑度をさらに有限集合のサイズでバウンドします．\n",
    "\n",
    "* 仮説関数$h: \\mathcal{X} \\rightarrow\\{-1,+1\\}$の集合を$\\mathcal{H}$\n",
    "* $\\mathcal{H}$を有限集合\n",
    "\n",
    "とします．\n",
    "このとき，\n",
    "\n",
    "$$\n",
    "\\mathcal{R}_n(\\mathcal{H}) \\leq \\sqrt{\\frac{2 \\log |\\mathcal{H}|}{n}}\n",
    "$$\n",
    "が成立します．これを示すために，先に次のMassartの有限仮説の補題を示しましょう．\n",
    "\n",
    "---\n",
    "\n",
    "**Massartの有限仮説の補題**\n",
    "\n",
    "$\\mathcal{A} \\subset \\mathbb{R}^n$を有限集合とし，\n",
    "$$\n",
    "\\sup _{a \\in \\mathcal{A}} \\|a\\|_2^2 =\n",
    "\\sup _{\\left(a_1, \\ldots, a_n\\right) \\in \\mathcal{A}} \\sum_{i=1}^n a_i^2 \\leq M^2\n",
    "$$\n",
    "とする．このとき，\n",
    "$$\n",
    "\\mathbb{E}_\\sigma\\left[\\sup _{\\left(a_1, \\ldots, a_n\\right) \\in \\mathcal{A}} \\frac{1}{n} \\sum_{i=1}^n \\sigma_i a_i\\right] \\leq \\frac{\\sqrt{2 M^2 \\log |\\mathcal{A}|}}{n}\n",
    "$$\n",
    "が成り立つ．\n",
    "\n",
    "**証明**\n",
    "\n",
    "一般に有限集合$\\mathcal{X}$に対して\n",
    "$$f\\left(\\boldsymbol{x}^*\\right)=\\sup _{\\boldsymbol{x} \\in \\mathcal{X}} f(\\boldsymbol{x})$$\n",
    "を考えると，指数関数が単調増加関数なので，\n",
    "$$\n",
    "f\\left(\\boldsymbol{x}^*\\right)=\\log \\left(\\sup _{\\boldsymbol{x} \\in \\mathcal{X}} \\exp (f(\\boldsymbol{x}))\\right)\n",
    "$$\n",
    "が成立します．これを使うと，任意の$\\lambda > 0$に対して\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "& \\frac{\\lambda}{n} \\mathbb{E}_\\sigma\\left[\\sup _{\\left(a_1, \\ldots, a_n\\right) \\in \\mathcal{A}} \\sum_{i=1}^n \\sigma_i a_i\\right] \\\\\n",
    "& =\\frac{1}{n} \\mathbb{E}_\\sigma\\left[\\log \\left(\\sup _{\\left(a_1, \\ldots, a_n\\right) \\in \\mathcal{A}} \\exp \\left(\\lambda \\sum_{i=1}^n \\sigma_i a_i\\right)\\right)\\right] \\\\\n",
    "& \\leq \\frac{1}{n} \\mathbb{E}_\\sigma\\left[\\log \\left(\\sum_{\\left(a_1, \\ldots, a_n\\right) \\in \\mathcal{A}} \\exp \\left(\\lambda \\sum_{i=1}^n \\sigma_i a_i\\right)\\right)\\right] \\\\\n",
    "& \\leq \\frac{1}{n} \\log \\left(\\mathbb{E}_\\sigma\\left[\\sum_{\\left(a_1, \\ldots, a_n\\right) \\in \\mathcal{A}} \\exp \\left(\\lambda \\sum_{i=1}^n \\sigma_i a_i\\right)\\right]\\right] \\\\\n",
    "& (\\because \\text { Jensen's inequality })\\\\\n",
    "& =\\frac{1}{n} \\log \\left(\\sum_{\\left(a_1, \\ldots, a_n\\right) \\in \\mathcal{A}} \\mathbb{E}_\\sigma\\left[\\prod_{i=1}^n \\exp \\left(\\lambda \\sigma_i a_i\\right)\\right]\\right) \\\\\n",
    "& =\\frac{1}{n} \\log \\left(\\sum_{\\left(a_1, \\ldots, a_n\\right) \\in \\mathcal{A}} \\prod_{i=1}^n \\mathbb{E}_{\\sigma_i}\\left[\\exp \\left(\\lambda \\sigma_i a_i\\right)\\right]\\right)\\\\\n",
    "& =\\frac{1}{n} \\log \\left(\\sum_{\\left(a_1, \\ldots, a_n\\right) \\in \\mathcal{A}} \\prod_{i=1}^n\\left[\\frac{1}{2} \\exp \\left(\\lambda a_i\\right)+\\frac{1}{2} \\exp \\left(-\\lambda a_i\\right)\\right]\\right) \\\\\n",
    "& \\leq \\frac{1}{n} \\log \\left(\\sum_{\\left(a_1, \\ldots, a_n\\right) \\in \\mathcal{A}} \\prod_{i=1}^n \\exp \\left(\\frac{\\lambda^2 a_i^2}{2}\\right)\\right)\n",
    "\\end{aligned}\n",
    "$$\n",
    "最後の不等式は，一般に$\\frac{\\exp (x)+\\exp (-x)}{2} \\leq \\exp \\left(\\frac{x^2}{2}\\right)$であることを使ってます．\n",
    "\n",
    "さらに発展させると，\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{\\lambda}{n} \\mathbb{E}_\\sigma\\left[\\sup _{\\left(a_1, \\ldots, a_n\\right) \\in \\mathcal{A}} \\sum_{i=1}^n \\sigma_i a_i\\right] & \\leq \\frac{1}{n} \\log \\left(\\sum_{\\left(a_1, \\ldots, a_n\\right) \\in \\mathcal{A}} \\prod_{i=1}^n \\exp \\left(\\frac{\\lambda^2 a_i^2}{2}\\right)\\right) \\\\\n",
    "& =\\frac{1}{n} \\log \\left(\\sum_{\\left(a_1, \\ldots, a_n\\right) \\in \\mathcal{A}} \\exp \\left(\\lambda^2 \\sum_{i=1}^n \\frac{a_i^2}{2}\\right)\\right) \\\\\n",
    "& \\leq \\frac{1}{n} \\log \\left(\\sum_{\\left(a_1, \\ldots, a_n\\right) \\in \\mathcal{A}} \\exp \\left(\\frac{\\lambda^2 M^2}{2}\\right)\\right) \\\\\n",
    "& =\\frac{1}{n} \\log \\left(|\\mathcal{A}| \\exp \\left(\\frac{\\lambda^2 M^2}{2}\\right)\\right) \\\\\n",
    "& =\\frac{1}{n} \\log |\\mathcal{A}|+\\frac{1}{n} \\frac{\\lambda^2 M^2}{2} .\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "あとは\n",
    "$$\n",
    "\\lambda=\\sqrt{2 \\frac{\\log |\\mathcal{A}|}{M^2}}\n",
    "$$\n",
    "とおけば終わりです．\n",
    "\n",
    "**補足：なぜ$\\lambda$をいれるのか？**\n",
    "\n",
    "$\\lambda=1$のときを考えてみましょう．このとき，\n",
    "$$\\frac{1}{n} \\frac{M^2}{2}$$\n",
    "が出てきてしまいます．ここで，\n",
    "$$\n",
    "\\sup _{\\left(a_1, \\ldots, a_n\\right) \\in \\mathcal{A}} \\sum_{i=1}^n a_i^2 \\leq M^2\n",
    "$$\n",
    "なので，$M^2$はだいたい$n$くらいのオーダーなわけですね．すると，$\\frac{1}{n} \\frac{M^2}{2}$の部分がせっかく$n$で割ってるのに定数が残ってしまいます．これは嬉しくないので，$\\log |\\mathcal{A}|$の部分を犠牲にして$\\sqrt{n}$のオーダーを出しています．\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 補足：ラデマッハ複雑度によるバウンドの別解\n",
    "\n",
    "TODO: 後で書く．授業のLec 14."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 補足：経験誤差と経験ラデマッハ複雑度\n",
    "\n",
    "上での解析は$R(h_S) - R(h_\\mathcal{H})$をバウンドしました．つまり，最も良い仮説とアルゴリズムが出した仮説の期待誤差を評価していたわけですね．\n",
    "\n",
    "これも大事ですが，経験誤差$\\hat{R}(h_S)$と期待誤差$R(h_S)$の差を評価するのも大事な解析です．\n",
    "\n",
    "これは\n",
    "$$\n",
    "\\begin{aligned}\n",
    "R(\\hat{h}) & =\\widehat{R}(\\hat{h})+R(\\hat{h})-\\widehat{R}(\\hat{h}) \\\\\n",
    "& \\leq \\widehat{R}(\\hat{h})+\\sup _{h \\in \\mathcal{H}}\\left\\{R(h)-\\widehat{R}(h)\\right\\} \\\\\n",
    "& \\leq \\widehat{R}(\\hat{h})+2 \\mathcal{R}(\\mathcal{L})+(b-a) \\sqrt{\\frac{\\log \\frac{1}{\\delta}}{2 n}}\n",
    "\\end{aligned}\n",
    "$$\n",
    "とすればラデマッハ複雑度で抑えることができます．\n",
    "\n",
    "これは結局ラデマッハ複雑度で抑えており，ラデマッハ複雑度はデータについての期待値をとっています．上と似たような議論を使えば，ラデマッハ複雑度を経験ラデマッハ複雑度で抑えることができます．\n",
    "\n",
    "TODO: 残りを書く．授業のLec 15．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ラデマッハ複雑度の合成\n",
    "\n",
    "上で見たように，ラデマッハ複雑度は損失関数の集合に対しての指標でした．\n",
    "これまでは特に$0-1$損失しか見てこなかったので，損失関数（や仮説関数）が変わると使えません．つまり，まだ具体的な推定モデル（L2正則化線形モデルなど）を考えると，今までの理論じゃ不十分なわけですね．\n",
    "\n",
    "次に示すTalagrandの補題を使うと合成関数に対してのラデマッハ複雑度を計算できます．ニューラルネットワークなどは合成関数なのでTalagrandの補題が活躍します．\n",
    "\n",
    "---\n",
    "\n",
    "**補題：Ledoux-Talagrand contraction lemma**\n",
    "\n",
    "$\\phi: \\mathbb{R}\\to \\mathbb{R}$を$L_\\phi$-Lipschitzな連続関数とします．つまり$|\\phi(x)-\\phi(y)| \\leq L_\\phi|x-y|$です．\n",
    "$\\mathcal{F} \\subset \\mathbb{R}^n$のとき，\n",
    "$$\n",
    "\\mathbb{E}\\left[\\sup _{f \\in \\mathcal{F}} \\frac{1}{n} \\sum_{i=1}^n \\sigma_i \\phi\\left(f_i\\right)\\right] \\leq L_\\phi \\mathbb{E}\\left[\\sup _{f \\in \\mathcal{F}} \\frac{1}{n} \\sum_{i=1}^n \\sigma_i f_i\\right]\n",
    "$$\n",
    "が成り立ちます．つまり，$R(\\phi(\\mathcal{F})) \\leq L_\\phi R(\\mathcal{F})$です．\n",
    "\n",
    "---\n",
    "\n",
    "これはつまり，損失や仮説の集合$\\mathcal{F}$を$\\phi$で変形したとき，そのラデマッハ複雑度がリプシッツ定数でスケールすることを表しています．\n",
    "\n",
    "証明は後でやります．先に使用例を見てみましょう．\n",
    "\n",
    "* 二乗誤差（厳密に言えばこれはリプシッツ連続ではないですが，打ち切れば良いです）：\n",
    "$\\ell((x, y), h)=\\phi(f((x, y), h))=\\|y-h(x)\\|_2^2$を考えましょう．このとき\n",
    "$$\\phi(f)=\\|f\\|_2^2, f((x, y), h)=y-h(x)$$\n",
    "* ヒンジ損失：$\\ell((x, y), h)=\\phi(f((x, y), h))=\\max \\{0,1-y h(x)\\}$を考えましょう．このとき，\n",
    "$$\\phi(f)=\\max \\{0, f\\}, f((x, y), h)=1-y h(x)$$\n",
    "\n",
    "ヒンジ損失についてのラデマッハ複雑度を出してみましょう．\n",
    "\n",
    "$f((x, y), h)=1-y h(x)$の集合を$\\mathcal{F}$とすると，\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "R_n(\\mathcal{F}) & =\\mathbb{E}_{\\mathcal{D}}\\left[\\mathbb{E}_\\sigma\\left[\\sup _{f \\in \\mathcal{F}} \\frac{1}{n} \\sum_{i=1}^n \\sigma_i\\left(1-y_i h\\left(x_i\\right)\\right)\\right]\\right] \\\\\n",
    "& \\left.=\\mathbb{E}_{\\mathcal{D}}\\left[\\mathbb{E}_\\sigma\\left[\\sup _{h \\in \\mathcal{H}} \\frac{1}{n} \\sum_{i=1}^n \\sigma_i+\\frac{1}{n} \\sum_{i=1}^n-\\sigma_i y_i h\\left(x_i\\right)\\right)\\right]\\right] \\\\\n",
    "& =\\mathbb{E}_{\\mathcal{D}}[\\mathbb{E}_\\sigma[\\sup _{h \\in \\mathcal{H}} \\frac{1}{n} \\sum_{i=1}^n \\underbrace{\\left(-\\sigma_i y_i\\right)}_{\\text {ランダムラベル }} h\\left(x_i\\right))]]=R_n(\\mathcal{H})\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "より，$f((x, y), h)=1-y h(x)$の集合のラデマッハ複雑度は仮説集合のラデマッハ複雑度と同じです．\n",
    "\n",
    "ヒンジ損失のリプシッツ定数は１なので，Talagrandの補題から\n",
    "$$\n",
    "R_n(\\mathcal{L}) \\leq R_n(\\mathcal{F})=R_n(\\mathcal{H})\n",
    "$$\n",
    "が成り立ち，ヒンジ損失のラデマッハ複雑度を仮説集合のラデマッハ複雑度で抑えることができました．\n",
    "（今回は上の変形で$\\mathcal{R}_n(\\mathcal{F}) = \\mathcal{R}_n(\\mathcal{H})$を出しましたが，これもTalagrandの補題で$\\mathcal{R}_n(\\mathcal{F}) \\leq \\mathcal{R}_n(\\mathcal{H})$として抑えることができます．）\n",
    "\n",
    "Talagrandの補題を証明しましょう．\n",
    "\n",
    "**証明**\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "& \\mathbb{E}\\left[\\sup _{f \\in \\mathcal{F}} \\frac{1}{n} \\sum_{i=1}^n \\sigma_i \\phi\\left(f_i\\right)\\right] \\\\\n",
    "& =\\frac{1}{n} \\mathbb{E}_{\\sigma_1, \\sigma_2, \\ldots, \\sigma_n}\\left[\\sup _{f \\in \\mathcal{F}} \\sigma_1 \\phi\\left(f_1\\right)+\\sum_{i=2}^n \\sigma_i \\phi\\left(f_i\\right)\\right] \\\\\n",
    "& =\\frac{1}{n} \\mathbb{E}_{\\sigma_2, \\ldots, \\sigma_n}\\left[\\frac{1}{2} \\sup _{f \\in \\mathcal{F}}\\left((+1) \\phi\\left(f_1\\right)+\\sum_{i=2}^n \\sigma_i \\phi\\left(f_i\\right)\\right)\\right. \\\\\n",
    "& \\left.\\quad+\\frac{1}{2} \\sup _{f \\in \\mathcal{F}}\\left((-1) \\phi\\left(f_1\\right)+\\sum_{i=2}^n \\sigma_i \\phi\\left(f_i\\right)\\right)\\right] \\\\\n",
    "& =\\frac{1}{n} \\mathbb{E}_{\\sigma_2, \\ldots, \\sigma_n}\\left[\\frac{1}{2} \\sup _{f \\in \\mathcal{F}, f^{\\prime} \\in \\mathcal{F}}\\left(\\phi\\left(f_1\\right)-\\phi\\left(f_1^{\\prime}\\right)\\right)+\\sum_{i=2}^n \\sigma_i \\phi\\left(f_i\\right)+\\sum_{i=2}^n \\sigma_i \\phi\\left(f_i^{\\prime}\\right)\\right]\n",
    "& \\leq \\frac{1}{n} \\mathbb{E}_{\\sigma_2, \\ldots, \\sigma_n}\\left[\\frac{1}{2} \\sup _{f \\in \\mathcal{F}, f^{\\prime} \\in \\mathcal{F}} L_\\phi\\left|f_1-f_1^{\\prime}\\right|+\\sum_{i=2}^n \\sigma_i \\phi\\left(f_i\\right)+\\sum_{i=2}^n \\sigma_i \\phi\\left(f_i^{\\prime}\\right)\\right] \\\\\n",
    "& \\leq\\frac{1}{n} \\mathbb{E}_{\\sigma_2, \\ldots, \\sigma_n}\\left[\\frac{1}{2} \\sup _{f \\in \\mathcal{F}, f^{\\prime} \\in \\mathcal{F}} L_\\phi|f_1-f_1^{\\prime}|+\\sum_{i=2}^n \\sigma_i \\phi\\left(f_i\\right)+\\sum_{i=2}^n \\sigma_i \\phi\\left(f_i^{\\prime}\\right)\\right]\\\\\n",
    "& =\\frac{1}{n} \\mathbb{E}_{\\sigma_2, \\ldots, \\sigma_n}\\left[\\frac{1}{2} \\sup _{f \\in \\mathcal{F}, f^{\\prime} \\in \\mathcal{F}} L_\\phi\\left(f_1-f_1^{\\prime}\\right)+\\sum_{i=2}^n \\sigma_i \\phi\\left(f_i\\right)+\\sum_{i=2}^n \\sigma_i \\phi\\left(f_i^{\\prime}\\right)\\right]\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "あとはこれを$1, \\dots, n$まで繰り返せば終わりです．"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
