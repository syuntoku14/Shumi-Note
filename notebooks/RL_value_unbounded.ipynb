{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 有界ではない報酬＆可算無限状態空間での価値反復について\n",
    "\n",
    "参考：\n",
    "* [Markov Decision Processes: Discrete Stochastic Dynamic Programming](https://onlinelibrary.wiley.com/doi/book/10.1002/9780470316887)の6.10章．表記は本と同様です．\n",
    "\n",
    "価値反復法の証明には基本的に報酬が有界であることを使います．\n",
    "例えば$L_d v = r_d \\lambda P_d v$なるベルマン作用素を考えたときに，報酬が有界であることを使えば，これは$\\lambda$-contractionになり，方策$d$の価値$v_d$に収束することが言えます．\n",
    "\n",
    "一方で，報酬が有界ではない場合はどうすれば良いでしょうか？\n",
    "これは例えば状態空間が（可算）無限のような場合に発生します．\n",
    "（詳しい例はMDP本の３章のInventory controlの例などを参考にしてみてください．）\n",
    "\n",
    "## 適切な仮定を考えよう\n",
    "\n",
    "有界でない場合には通常のContractionが使えないので，より一般的なContractionの概念を導入します．\n",
    "また，有界でないMDPが何でも扱えるわけではないので（多分），報酬と遷移に対して適切な仮定をおきます．\n",
    "\n",
    "準備：\n",
    "* $w: S \\to \\mathbb{R}$を$\\inf _{s \\in S} w(s)>0$を満たす関数とします．\n",
    "  * 例えば$w(s)=\\max (s, 1)$ or $w(s)=\\log (s+\\delta)$, with $\\delta>1$がこれを満たします．\n",
    "* 次の重み付きsupremumノルムを導入します：\n",
    "$$\n",
    "\\|v\\|_w=\\sup _{s \\in S}\\frac{|v(s)|}{w(s)}\n",
    "$$\n",
    "* $V_w$を$\\{v \\in V : \\|v\\|_w<\\infty\\}$とします．例えば$w(s)=1$なら，$V_w = V$です．\n",
    "\n",
    "以降，この$V_w$内で何らかの系列$\\{v_0, v_1, \\dots \\in V_w\\}$の収束について考えていきます．ちなみに$V_w$内で$\\|\\cdot\\|_w$についての収束は各点収束であることに注意しましょう．実際，\n",
    "\n",
    "$$\n",
    "\\left\\|v^n-v\\right\\|_\\omega<\\varepsilon \\text { for some } \\varepsilon>0\n",
    "$$\n",
    "\n",
    "なら，各$s$について\n",
    "\n",
    "$$\n",
    "\\left|v_n(s)-v(s)\\right|<\\varepsilon w(s)\n",
    "$$\n",
    "\n",
    "です（$w(s)=定数$なら一様収束が言えます）．また，$V_w$内の任意のコーシー列は$V_w$内に収束するので，$V_w$はバナッハ空間です．\n",
    "\n",
    "ここで，$H$を$|S| \\times|S|$の行列として，$(s, j)$番目の要素を$h(j|s)$とします．$H : V_w \\to V_w$について，\n",
    "$$\n",
    "\\|H\\|_w=\\sup _{s \\in S} \\frac{\\sum_{j \\in S}|h(j \\mid s)| w(j)}{w(s)}\n",
    "$$\n",
    "を作用素ノルムとします（作用素ノルムの定義と同じです）．\n",
    "\n",
    "さて，ここから報酬と遷移について以下を仮定します（教科書Proposition 6.10.5も参考になるので見ておきましょう．）：\n",
    "\n",
    "---\n",
    "\n",
    "**報酬の仮定**\n",
    "\n",
    "次を満たす$\\mu < \\infty$が存在する．\n",
    "$$\\left\\|r_d\\right\\|_w \\leq \\mu$$\n",
    "\n",
    "* つまり，**「状態$s$での報酬は$w(s)$のレートでしか増えない」**ことを仮定してます．\n",
    "* 例えば$w(s)=\\max \\left\\{\\sup _{a \\in A_s}|r(s, a)|, 1\\right\\}$などは条件を満たす．ここで$\\mu=1$です．\n",
    "\n",
    "---\n",
    "\n",
    "**遷移についての仮定**\n",
    "\n",
    "次を満たす$0 \\leq \\kappa < \\infty$が存在する．\n",
    "$$P_d w \\leq \\kappa w$$\n",
    "\n",
    "* ちなみにこれは$\\left\\|P_d\\right\\|_w \\leq \\kappa$と等価\n",
    "\n",
    "さらに，次を満たす$0 \\leq \\alpha < 1$と$J \\in \\mathbb{N}$が，任意の$\\pi=\\left(d_1, \\ldots, d_J\\right)$ where $d_k \\in D^{\\mathrm{MD}} ; 1 \\leq k \\leq J$について存在する．\n",
    "\n",
    "$$\\lambda^J P_\\pi^J w \\leq \\alpha w$$\n",
    "\n",
    "* ちなみにこれは$\\left\\|\\lambda^J P_\\pi^J\\right\\|_w \\leq \\alpha$と等価\n",
    "\n",
    "つまり，任意の$\\pi$について，\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&E^\\pi\\left\\{w\\left(X_{n+1}\\right) \\mid X_n=s, Y_n=a\\right\\} \\leq \\kappa w(s)\\\\\n",
    "&E^\\pi\\left\\{w\\left(X_{n+J}\\right) \\mid X_n=s\\right\\} \\leq \\alpha \\lambda^{-J} w(s)\n",
    "\\end{aligned}\n",
    "$$\n",
    "であることを仮定してます．つまり， **「$w(s)$から$w(s')$に遷移したとき，その期待値は線形にしか変化しない．」** また， **「十分な回数遷移すると，その期待値が$\\lambda^{-J}$のスケールで抑えられる」**ことを仮定しています．\n",
    "\n",
    "---\n",
    "\n",
    "**具体例**\n",
    "\n",
    "一旦具体的な例を見てみましょう．\n",
    "次のMDPを考えます：\n",
    "\n",
    "* 状態集合：$S = \\{0, 1, 2, 3, \\dots\\}$\n",
    "* 行動集合：$A = \\{0, 1, \\dots, M\\}$\n",
    "* 報酬：$r(s, a)=s$\n",
    "* 遷移：$P(s+a | s, a)=1$\n",
    "\n",
    "このとき，$w(s)=\\max\\{s, 1\\}$とします．すると，明らかに報酬の仮定は満たされてますね．また，任意の方策について\n",
    "\n",
    "$$\n",
    "\\sum_{j \\in S} P_d(j \\mid s) w(j)=s+a \\leq s+M \\leq(1+M) w(s)\n",
    "$$\n",
    "なので，$\\kappa=(1+M)$で１つ目の遷移の仮定が成立してます．\n",
    "\n",
    "さらに，任意の$\\pi$について\n",
    "$$\n",
    "\\lambda^{\\prime} \\sum_{j \\in S} P_\\pi^J(j \\mid s) w(j) \\leq \\lambda^J(s+M J) \\leq \\lambda^J(1+M J) w(s) .\n",
    "$$\n",
    "なので，$\\lambda^J\\left(1+M^J\\right)<1$を満たす十分大きな$J$についてなら，２つ目の遷移の仮定も成り立ってます．\n",
    "\n",
    "---\n",
    "\n",
    "さて，上の仮定が成り立つMDPでは，任意の方策$\\pi=\\left(d_1, d_2, \\ldots\\right) \\in \\Pi^{\\mathrm{MD}}$の価値関数に対して次のバウンドが成立します（証明は略）：\n",
    "\n",
    "$$\n",
    "\\begin{gathered}\n",
    "\\left|v_\\lambda^\\pi(s)\\right| \\leq \\frac{\\mu}{1-\\alpha}\\left[1+\\lambda \\kappa+\\cdots+(\\lambda \\kappa)^{J-1}\\right] w(s) \\\\\n",
    "\\left\\|v_\\lambda^\\pi\\right\\|_w \\leq \\frac{\\mu}{1-\\alpha}\\left[1+\\lambda \\kappa+\\cdots+\\left(\\lambda_\\kappa\\right)^{J-1}\\right] .\n",
    "\\end{gathered}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## J-stage contraction\n",
    "\n",
    "ここまでで見たように，$\\kappa > 1$であれば，$L$は$V_w$についてcontractionではありません．\n",
    "しかし，上の仮定が成立しているとき，$L$は$V_w$について$J$-state contractionになります．\n",
    "\n",
    "---\n",
    "\n",
    "バナッハ空間$J$上の作用素$T$は次を満たすときに$J$-state contractionという．任意の$v, u \\in U$について，次を満たす$J \\in \\mathbb{N}$と$0 \\leq \\lambda' < 1$が存在する：\n",
    "\n",
    "$$\n",
    "\\left\\|T^J u-T^J v\\right\\| \\leq \\lambda^{\\prime}\\|u-v\\| .\n",
    "$$\n",
    "\n",
    "つまり，作用素$T$を$J$回繰り返すとcontractionが成立するわけですね．\n",
    "また，\n",
    "* $Tv^*=v^*$を満たす唯一の解$v^*\\in U$が存在し，\n",
    "* 任意の$v^0 \\in U$について，$v^{n+1}=T v^n$は$v^*$に収束します．\n",
    "\n",
    "証明略．\n",
    "\n",
    "---\n",
    "\n",
    "上で見た報酬と遷移の仮定が成立しているとき，ベルマン作用素$L$が$J$-stage contractionになります．\n",
    "\n",
    "**証明**\n",
    "\n",
    "適当な$v \\in V_w$について，$L v=r_d+\\lambda P_d v$を満たす$d \\in D^{MD}$を考えます．\n",
    "このとき，三角不等式と仮定より\n",
    "$$\n",
    "\\|L v\\|_w \\leq \\|r_d\\|_w + \\lambda \\|P_d\\|_w \\|v\\|_w\n",
    "\\leq \\mu + \\lambda \\kappa \\|v\\|_w\n",
    "$$\n",
    "です．よって$Lv \\in V_w$です．\n",
    "\n",
    "$u, v \\in V_w$とし，$L^J v(s) \\geq L^J u(s)$としましょう．\n",
    "$\\pi = (d_1, d_2, \\dots, d_j)$を$L v, L(L v), \\ldots, L\\left(L^{J-1}\\right) v$の中でgreedyを実現する意思決定ルールとします．すると，\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "0 & \\leq L^J v(s)-L^J u(s) \\leq L_{d_J} \\cdots L_{d_2} L_{d_1} v(s)-L_{d_J} \\cdots L_{d_2} L_{d_1} u(s) \\\\\n",
    "& =\\lambda^J P_{d_J} \\cdots P_{d_2} P_{d_1}(v-u)(s) \\leq \\lambda^J P_\\pi^J w(s)\\|v-u\\|_w \\leq \\alpha\\left\\|_v-u\\right\\|_w .\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "です．同様にして，$L^J v(s) \\leq L^J u(s)$のときも成立します．よって$L$は$J$-stage contractionです．\n",
    "\n",
    "---\n",
    "\n",
    "無事$L$が$J$-stage contractionであることが言えました！\n",
    "あとはちょっと証明すれば，報酬と遷移の仮定のもと，$L$の反復によって最適価値関数に収束することが言えます（Modified policy iterationでも大丈夫です）．\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 可算無限状態空間を有限状態で近似しよう\n",
    "\n",
    "上では報酬が有界ではない場合について学び，ベルマン最適作用素で最適価値関数に収束することがわかりました．\n",
    "しかし，上の例は状態空間が有限ではない場合は使えません（$L$を計算するのに無限の時間がかかってしまいます）．\n",
    "\n",
    "そこで，無限の状態を有限の状態で近似することを考えましょう．\n",
    "\n",
    "準備：\n",
    "\n",
    "可算無限の状態空間に対して，\n",
    "$$\n",
    "S_N=\\{0, 1, \\dots, N\\}\n",
    "$$\n",
    "を，その$N+1$個の状態による近似とします．\n",
    "\n",
    "適当な$u \\in V_w$（例えば$u=0$など）によって，$v \\in V_w$に対して\n",
    "$$\n",
    "v^{N, u}(s)= \\begin{cases}v(s) & s \\leq N \\\\ u(s) & s>N\\end{cases}\n",
    "$$\n",
    "なる関数を定めましょう．つまり，$[N]$以外の部分では$v(s)$ではなく$u(s)$を取ります．\n",
    "\n",
    "$d\\in D$について，次の作用素$L_d^{N, u}: V_w \\rightarrow V_w$を定めます：\n",
    "\n",
    "$$\n",
    "L_d^{N, u} v(s)=\\left\\{\\begin{array}{cc}\n",
    "r_d(s)+\\lambda \\sum_{j \\leq N} p_d(j \\mid s) v(j)+\\lambda \\sum_{j>N} p_d(j \\mid s) u(j) & s \\leq N \\\\\n",
    "u(s) & s>N\n",
    "\\end{array}\\right.\n",
    "$$\n",
    "\n",
    "つまり，$[N]$以外の状態は$u(s)$を当てはめているわけですね．\n",
    "一番簡単なケースは$u=0$のときです：\n",
    "$$\n",
    "L_d^{N, 0} v(s)=r(s, d(s))+\\lambda \\sum_{j \\leq N} p(j \\mid s, d(s)) v(j) \\quad s \\leq N\n",
    "$$\n",
    "\n",
    "実は固定された$N, d\\in D, u \\in V_w$について，$L_d^{N, u}$は$N$-stage contractionになります．任意の$\\pi$について，\n",
    "\n",
    "$$\n",
    "\\sum_{j \\in S_N} P_\\pi^J(j \\mid s) w(j)\n",
    "\\leq \n",
    "\\sum_{j \\in S_N} w(j)\n",
    "$$\n",
    "\n",
    "<!-- \n",
    "**証明**\n",
    "\n",
    "面倒なので$L'_d$を$L^{N, u}_d$として扱います．\n",
    "\n",
    "上の$J$-contractionの証明と同様にすれば，$L' v \\in V_w$はすぐわかります（多分）．\n",
    "\n",
    "$u, v \\in V_w$とし，$(L'_d)^N v(s) \\geq (L'_d)^N u(s)$としましょう．\n",
    "すると，\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "0 & \\leq (L'_d)^N v(s)-(L'_d)^N u(s) \n",
    "=\\lambda^N (P_{d})^N (v-u)(s) \\\\\n",
    "&\\leq \\lambda^J P_\\pi^J w(s)\\|v-u\\|_w \\leq \\alpha\\left\\|_v-u\\right\\|_w .\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "です．同様にして，$L^J v(s) \\leq L^J u(s)$のときも成立します．よって$L$は$J$-stage contractionです．\n",
    "\n",
    " -->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
