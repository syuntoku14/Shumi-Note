{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 有界ではない報酬＆可算無限状態空間での価値反復について\n",
    "\n",
    "参考：\n",
    "* [Markov Decision Processes: Discrete Stochastic Dynamic Programming](https://onlinelibrary.wiley.com/doi/book/10.1002/9780470316887)の6.10章．表記は本と同様です．\n",
    "\n",
    "価値反復法の証明には基本的に報酬が有界であることを使います．\n",
    "例えば$L_d v = r_d \\lambda P_d v$なるベルマン作用素を考えたときに，報酬が有界であることを使えば，これは$\\lambda$-contractionになり，方策$d$の価値$v_d$に収束することが言えます．\n",
    "\n",
    "一方で，報酬が有界ではない場合はどうすれば良いでしょうか？\n",
    "これは例えば状態空間が（可算）無限のような場合に発生します．\n",
    "（詳しい例はMDP本の３章のInventory controlの例などを参考にしてみてください．）\n",
    "\n",
    "## 適切な仮定を考えよう\n",
    "\n",
    "有界でない場合には通常のContractionが使えないので，より一般的なContractionの概念を導入します．\n",
    "また，有界でないMDPが何でも扱えるわけではないので（多分），報酬と遷移に対して適切な仮定をおきます．\n",
    "\n",
    "準備：\n",
    "* $w: S \\to \\mathbb{R}$を$\\inf _{s \\in S} w(s)>0$を満たす関数とします．\n",
    "  * 例えば$w(s)=\\max (s, 1)$ or $w(s)=\\log (s+\\delta)$, with $\\delta>1$がこれを満たします．\n",
    "* 次の重み付きsupremumノルムを導入します（つまり，各$v(s)$の値を$w(s)$で割ってるだけです．$w(s)$が$v(s)$くらいのスケールで大きくなるのであれば，$\\|v\\|_\\infty$が大きくても$\\|v\\|_w$は小さく抑えられます）：\n",
    "$$\n",
    "\\|v\\|_w=\\sup _{s \\in S}\\frac{|v(s)|}{w(s)}\n",
    "$$\n",
    "* $V_w$を$\\{v \\in V : \\|v\\|_w<\\infty\\}$とします．例えば$w(s)=1$なら，$V_w = V$です．\n",
    "\n",
    "以降，この$V_w$内で何らかの系列$\\{v_0, v_1, \\dots \\in V_w\\}$の収束について考えていきます．ちなみに$V_w$内で$\\|\\cdot\\|_w$についての収束は各点収束であることに注意しましょう．実際，\n",
    "\n",
    "$$\n",
    "\\left\\|v^n-v\\right\\|_\\omega<\\varepsilon \\text { for some } \\varepsilon>0\n",
    "$$\n",
    "\n",
    "なら，各$s$について\n",
    "\n",
    "$$\n",
    "\\left|v_n(s)-v(s)\\right|<\\varepsilon w(s)\n",
    "$$\n",
    "\n",
    "しか言えません（$w(s)=定数$なら一様収束が言えます）．また，$V_w$内の任意のコーシー列は$V_w$内に収束するので，$V_w$はバナッハ空間です．\n",
    "\n",
    "ここで，$H$を$|S| \\times|S|$の行列として，$(s, j)$番目の要素を$h(j|s)$とします．$H : V_w \\to V_w$について，\n",
    "$$\n",
    "\\|H\\|_w=\\sup _{s \\in S} \\frac{\\sum_{j \\in S}|h(j \\mid s)| w(j)}{w(s)}\n",
    "$$\n",
    "を作用素ノルムとします（作用素ノルムの定義と同じです）．\n",
    "\n",
    "さて，ここから報酬と遷移について以下を仮定します（教科書Proposition 6.10.5も参考になるので見ておきましょう．）：\n",
    "\n",
    "---\n",
    "\n",
    "**報酬の仮定**\n",
    "\n",
    "次を満たす$\\mu < \\infty$が存在する．\n",
    "$$\\left\\|r_d\\right\\|_w \\leq \\mu\n",
    "\\Longleftrightarrow\n",
    "\\sup _{a \\in A_s}|r(s, a)| \\leq \\mu w(s)\n",
    "$$\n",
    "\n",
    "* つまり， **「状態$s$での報酬は$w(s)$のレートでしか増えない」** ことを仮定してます．\n",
    "* 例えば$w(s)=\\max \\left\\{\\sup _{a \\in A_s}|r(s, a)|, 1\\right\\}$などは条件を満たします．ここで$\\mu=1$です．\n",
    "\n",
    "---\n",
    "\n",
    "**遷移についての仮定**\n",
    "\n",
    "次を満たす$0 \\leq \\kappa < \\infty$が存在する．\n",
    "$$P_d w \\leq \\kappa w$$\n",
    "\n",
    "* ちなみにこれは$\\left\\|P_d\\right\\|_w \\leq \\kappa$と等価\n",
    "\n",
    "さらに，次を満たす$0 \\leq \\alpha < 1$と$J \\in \\mathbb{N}$が，任意の$\\pi=\\left(d_1, \\ldots, d_J\\right)$ where $d_k \\in D^{\\mathrm{MD}} ; 1 \\leq k \\leq J$について存在する．\n",
    "\n",
    "$$\\lambda^J P_\\pi^J w \\leq \\alpha w$$\n",
    "\n",
    "* ちなみにこれは$\\left\\|\\lambda^J P_\\pi^J\\right\\|_w \\leq \\alpha$と等価\n",
    "\n",
    "つまり，任意の$\\pi$について，\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&E^\\pi\\left\\{w\\left(X_{n+1}\\right) \\mid X_n=s, Y_n=a\\right\\} \\leq \\kappa w(s)\\\\\n",
    "&E^\\pi\\left\\{w\\left(X_{n+J}\\right) \\mid X_n=s\\right\\} \\leq \\alpha \\lambda^{-J} w(s)\n",
    "\\end{aligned}\n",
    "$$\n",
    "であることを仮定してます．つまり， **「$w(s)$から$w(s')$に遷移したとき，その期待値は線形にしか変化しない．」** また， **「十分な回数遷移すると，その期待値が$\\alpha\\lambda^{-J}$のスケールで抑えられる」** ことを仮定しています．$\\alpha$と$\\lambda$は１より小さいので，$J$回遷移すればcontractionが成立するわけですね．\n",
    "\n",
    "---\n",
    "\n",
    "**具体例**\n",
    "\n",
    "一旦具体的な例を見てみましょう．\n",
    "次のMDPを考えます：\n",
    "\n",
    "* 状態集合：$S = \\{0, 1, 2, 3, \\dots\\}$\n",
    "* 行動集合：$A = \\{0, 1, \\dots, M\\}$\n",
    "* 報酬：$r(s, a)=s$\n",
    "* 遷移：$P(s+a | s, a)=1$\n",
    "\n",
    "このとき，$w(s)=\\max\\{s, 1\\}$とします．すると，明らかに報酬の仮定は満たされてますね．また，任意の方策について\n",
    "\n",
    "$$\n",
    "\\sum_{j \\in S} P_d(j \\mid s) w(j)=s+a \\leq s+M \\leq(1+M) w(s)\n",
    "$$\n",
    "なので，$\\kappa=(1+M)$で１つ目の遷移の仮定が成立してます．\n",
    "\n",
    "さらに，任意の$\\pi$について\n",
    "$$\n",
    "\\lambda^{\\prime} \\sum_{j \\in S} P_\\pi^J(j \\mid s) w(j) \\leq \\lambda^J(s+M J) \\leq \\lambda^J(1+M J) w(s) .\n",
    "$$\n",
    "なので，$\\lambda^J\\left(1+M^J\\right)<1$を満たす十分大きな$J$についてなら，２つ目の遷移の仮定も成り立ってます．\n",
    "\n",
    "---\n",
    "\n",
    "さて，上の仮定が成り立つMDPでは，任意の方策$\\pi=\\left(d_1, d_2, \\ldots\\right) \\in \\Pi^{\\mathrm{MD}}$の価値関数に対して次のバウンドが成立します（証明は略）：\n",
    "\n",
    "$$\n",
    "\\begin{gathered}\n",
    "\\left|v_\\lambda^\\pi(s)\\right| \\leq \\frac{\\mu}{1-\\alpha}\\left[1+\\lambda \\kappa+\\cdots+(\\lambda \\kappa)^{J-1}\\right] w(s) \\\\\n",
    "\\left\\|v_\\lambda^\\pi\\right\\|_w \\leq \\frac{\\mu}{1-\\alpha}\\left[1+\\lambda \\kappa+\\cdots+\\left(\\lambda_\\kappa\\right)^{J-1}\\right] .\n",
    "\\end{gathered}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## J-stage contraction\n",
    "\n",
    "ここまでで見たように，$\\kappa > 1$であれば，$L$は$V_w$についてcontractionではありません．\n",
    "しかし，上の仮定が成立しているとき，$L$は$V_w$について$J$-state contractionになります．\n",
    "\n",
    "---\n",
    "\n",
    "バナッハ空間$J$上の作用素$T$は次を満たすときに$J$-state contractionという．任意の$v, u \\in U$について，次を満たす$J \\in \\mathbb{N}$と$0 \\leq \\lambda' < 1$が存在する：\n",
    "\n",
    "$$\n",
    "\\left\\|T^J u-T^J v\\right\\| \\leq \\lambda^{\\prime}\\|u-v\\| .\n",
    "$$\n",
    "\n",
    "つまり，作用素$T$を$J$回繰り返すとcontractionが成立するわけですね．\n",
    "また，\n",
    "* $Tv^*=v^*$を満たす唯一の解$v^*\\in U$が存在し，\n",
    "* 任意の$v^0 \\in U$について，$v^{n+1}=T v^n$は$v^*$に収束します．\n",
    "\n",
    "証明略．\n",
    "\n",
    "---\n",
    "\n",
    "上で見た報酬と遷移の仮定が成立しているとき，ベルマン作用素$L$が$J$-stage contractionになります．\n",
    "\n",
    "**証明**\n",
    "\n",
    "適当な$v \\in V_w$について，$L v=r_d+\\lambda P_d v$を満たす$d \\in D^{MD}$を考えます．\n",
    "このとき，三角不等式と仮定より\n",
    "$$\n",
    "\\|L v\\|_w \\leq \\|r_d\\|_w + \\lambda \\|P_d\\|_w \\|v\\|_w\n",
    "\\leq \\mu + \\lambda \\kappa \\|v\\|_w\n",
    "$$\n",
    "です．よって$Lv \\in V_w$です．\n",
    "\n",
    "$u, v \\in V_w$とし，$L^J v(s) \\geq L^J u(s)$としましょう．\n",
    "$\\pi = (d_1, d_2, \\dots, d_j)$を$L v, L(L v), \\ldots, L\\left(L^{J-1}\\right) v$の中でgreedyを実現する意思決定ルールとします．すると，\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "0 & \\leq L^J v(s)-L^J u(s) \\leq L_{d_J} \\cdots L_{d_2} L_{d_1} v(s)-L_{d_J} \\cdots L_{d_2} L_{d_1} u(s) \\\\\n",
    "& =\\lambda^J P_{d_J} \\cdots P_{d_2} P_{d_1}(v-u)(s) \\leq \\lambda^J P_\\pi^J w(s)\\|v-u\\|_w \\leq \\alpha\\left\\|v-u\\right\\|_w .\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "です．同様にして，$L^J v(s) \\leq L^J u(s)$のときも成立します．よって$L$は$J$-stage contractionです．\n",
    "\n",
    "---\n",
    "\n",
    "無事$L$が$J$-stage contractionであることが言えました！\n",
    "あとはちょっと証明すれば，報酬と遷移の仮定のもと，$L$の反復によって最適価値関数に収束することが言えます（Modified policy iterationでも大丈夫です）．\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 可算無限状態空間を有限状態で近似しよう\n",
    "\n",
    "上では報酬が有界ではない場合について学び，ベルマン最適作用素で最適価値関数に収束することがわかりました．\n",
    "しかし，上の例は状態空間が有限ではない場合は使えません（$L$を計算するのに無限の時間がかかってしまいます）．\n",
    "\n",
    "そこで，無限の状態を有限の状態で近似することを考えましょう．\n",
    "\n",
    "準備：\n",
    "\n",
    "可算無限の状態空間に対して，\n",
    "$$\n",
    "S_N=\\{0, 1, \\dots, N\\}\n",
    "$$\n",
    "を，その$N+1$個の状態による近似とします．\n",
    "\n",
    "適当な$u \\in V_w$（例えば$u=0$など）によって，$v \\in V_w$に対して\n",
    "$$\n",
    "v^{N, u}(s)= \\begin{cases}v(s) & s \\leq N \\\\ u(s) & s>N\\end{cases}\n",
    "$$\n",
    "なる関数を定めましょう．つまり，$[N]$以外の部分では$v(s)$ではなく$u(s)$を取ります．\n",
    "\n",
    "$d\\in D$について，次の作用素$L_d^{N, u}: V_w \\rightarrow V_w$を定めます：\n",
    "\n",
    "$$\n",
    "L_d^{N, u} v(s)=\\left\\{\\begin{array}{cc}\n",
    "r_d(s)+\\lambda \\sum_{j \\leq N} p_d(j \\mid s) v(j)+\\lambda \\sum_{j>N} p_d(j \\mid s) u(j) & s \\leq N \\\\\n",
    "u(s) & s>N\n",
    "\\end{array}\\right.\n",
    "$$\n",
    "\n",
    "ここで$j$を取っているのは遷移先であることに注意しましょう．$[N]$以外の遷移先と，$[N]$以外の遷移元には$u(s)$を当てはめているわけですね．\n",
    "一番簡単なケースは$u=0$のときです：\n",
    "$$\n",
    "L_d^{N, 0} v(s)=r(s, d(s))+\\lambda \\sum_{j \\leq N} p(j \\mid s, d(s)) v(j) \\quad s \\leq N\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "実は固定された$N, d\\in D, u \\in V_w$について，$L_d^{N, u}$は$J$-stage contractionになります（教科書には$N$-stage contractionって書いてありますが，全然わからん... 少なくとも$J$-stage contractionにはなりそう．）．後でまた戻ってみよう．\n",
    "\n",
    "---\n",
    "\n",
    "**証明(TODO:)**\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$L_d^{N, u}$が$V_w$上でcontractionなので，不動点を持ちます．\n",
    "この不動点を$v^{N, u}_d$としましょう．これをv_\\lambda^{d^\\infty}$の$N$-state approximationと呼ぶことにします．\n",
    "\n",
    "また，$D_N \\equiv \\times_{s \\leq N} A_s$を$S_N$上の決定的なマルコフ意思決定の集合とします．$v_*^{N, u}=\\sup _{d \\in D_N} v_d^{N, u}$としましょう．また，\n",
    "$$\n",
    "L^{N, u} v=\\max _{d \\in D_N} L_d^{N, u} v\n",
    "$$\n",
    "なる作用素を定義します．上と同様にすると，これも$...$-stage contractionになってることがわかります．よってこれは不動点$v_*^{N, u}$を持ちます．\n",
    "\n",
    "さて，これから$N$-state approximationが$v_\\lambda^\\infty$に収束する条件について見ていきます．\n",
    "次の補題で$N$と$N-1$を関連付けることができます．\n",
    "\n",
    "---\n",
    "\n",
    "**補題**\n",
    "\n",
    "適当な$u \\in V_w$について，$L_d u\\geq (\\leq) u$とします．このとき，任意の$k$と$N$について，\n",
    "$$\n",
    "\\left(L_d^{N, u}\\right)^k u \\geq(\\leq)\\left(L_d^{N-1, u}\\right)^k u\n",
    "$$\n",
    "が成り立ちます．\n",
    "\n",
    "**証明**\n",
    "\n",
    "$\\geq$のときだけ示しましょう．帰納法で示します．まず$k=1$のとき，$\\left(L_d^{N, u}\\right) u$と$\\left(L_d^{N-1, u}\\right)u$は引数に$u$を取っていることから\n",
    "\n",
    "$$\n",
    "L_d^{N, u} u(s)=\\left\\{\\begin{array}{cc}\n",
    "r_d(s)+\\lambda \\sum_{j \\in S} p_d(j \\mid s) u(j) & s \\leq N \\\\\n",
    "u(s) & s>N\n",
    "\\end{array}\\right.\n",
    "$$\n",
    "\n",
    "なので，$\\left(L_d^{N, u}\\right) u$と$\\left(L_d^{N-1, u}\\right)u$の違いは状態$N$だけです．よって，\n",
    "$$\n",
    "L_d^{N, u} u(N)=r_d(N)+\\lambda \\sum_{j=0}^{\\infty} p_d(j \\mid N) u(j)=L_d u(N) \\geq u(N)=L_d^{N-1, u} u(N),\n",
    "$$\n",
    "なので，$k=1$のときは成立します．\n",
    "\n",
    "$\\left(L_d^{N, u}\\right)^k u \\geq\\left(L_d^{N-1, u}\\right)^k u \\geq u$ が$k<K$で成立しているとします. $s>N$で，\n",
    "\n",
    "$$\\left(L_d^{N, u}\\right)^K u(s)=\\left(L_d^{N-1, u}\\right)^K u(s)=u(s)$$\n",
    "であり，$s \\leq N$では\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\left(L_d^{N, u}\\right)^K u(s) & =r_d(s)+\\lambda \\sum_{j \\leq N} p_d(j \\mid s)\\left(L_d^{N, u}\\right)^{K-1} u(j)+\\lambda \\sum_{j>N} p_d(j \\mid s) u(j) \\\\\n",
    "& \\geq r_d(s)+\\lambda \\sum_{j \\leq N-1} p_d(j \\mid s)\\left(L_d^{N-1, u}\\right)^{K-1} u(j)+\\lambda \\sum_{j>N-1} p_d(j \\mid s) u(j) \\\\\n",
    "& =\\left(L_d^{N-1, u}\\right)^K u(s),\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "よって，$s>N$でも$s\\leq N$でも$\\left(L_d^{N, u}\\right)^K u \\geq \\left(L_d^{N-1, u}\\right)^K u$なので，証明終わりです．\n",
    "\n",
    "---\n",
    "\n",
    "以上の結果を使うと，次が言えます：\n",
    "\n",
    "報酬と遷移についての仮定が成立しているとします．また，何らかの$u \\in V_w$について，$L_d u \\geq u$もしくは$L_d u\\leq u$とします．このとき，それぞれの$s \\in S$について，$U_d^{N, u}(s)$は$v_\\lambda^{d^\\phi}(s)$に収束します．\n",
    "\n",
    "**証明**\n",
    "\n",
    "$s \\in S$を固定します．$L_d u\\geq u$とします．$L_du \\geq u$なので，$u(s) \\leq v_\\lambda^{d^{\\infty}}(s)$でもあります．\n",
    "\n",
    "まず，それぞれの$N$について，$\\left(L_d^{N, u}\\right)^k u(s)$は$v_d^{N, u}(s)$に収束します（J-stage contractionのせい）．\n",
    "$u(s) \\leq v_\\lambda^{d^{\\infty}}(s)$なので，$L_d^{N, u}$の定義を考えると，$v_d^{N, u}(s) \\leq v_\\lambda^{d^{\\infty}}(s)$でもあります（これは確認すればすぐわかると思う）．\n",
    "\n",
    "$v_d^{N, u}(s)$は$N$について単調増加であり，さらに上界が存在するので，何らかの収束先を持ちます．これを$v'(s)$としましょう．\n",
    "$\\varepsilon > 0$とします．任意の$n$について，\n",
    "$$\n",
    "\\begin{aligned}\n",
    "0 & \\leq L_d v^{\\prime}(s)-L_d v_d^{N, u} \\\\\n",
    "& =\\lambda \\sum_{j \\leq n} p_d(j \\mid s)\\left[v^{\\prime}(j)-v_d^{N, u}(j)\\right]+\\lambda \\sum_{j>n} p_d(j \\mid s)\\left[v^{\\prime}(j)-v_d^{N, u}(j)\\right]\n",
    "\\end{aligned}\n",
    "$$\n",
    "です．２つ目の部分は\n",
    "$$\n",
    "\\lambda \\sum_{j>n} p_d(j \\mid s) w(j)\\left\\|v^{\\prime}-v_d^N \\cdot u\\right\\|_w \\leq \\lambda \\sum_{j>n} p_d(j \\mid s) w(j)\\left\\|u-v_\\lambda^*\\right\\|_w\n",
    "$$\n",
    "でバウンドできます．ここで不等式は$L_d^{N, u}$が大小関係を保存することとと，$v_d^{N, u}(s) \\leq v_\\lambda^{d^{\\infty}}(s)$を使っています．\n",
    "\n",
    "さて，遷移に対しておいた仮定から，$\\sum_{n=0}^{\\infty} p_d(j \\mid s) w(j) \\leq \\kappa w(s)$です．\n",
    "よって，$\\sum_{j>n} p_d(j \\mid s) w(j)<\\varepsilon$ for all $n \\geq n^{\\prime}$が成り立つような$n'$が存在します（そうでないならば吹っ飛ぶので）．\n",
    "\n",
    "$n \\geq n'$となるように$n$を選びましょう．このとき（$N$を大きくしていくと？），$v_d^{N, u}$は特に$\\{0, 1, \\dots, n\\}$では$\\varepsilon$のおかげで$v'$に一様に収束します．\n",
    "すなわち$N$を十分大きくすれば，上の不等式の１項目は$\\varepsilon$より小さくできるはずです．\n",
    "よって，$L_d v_d^{N, u}(s)$は$L_d v'(s)$に一様に収束します．\n",
    "あとは簡単なので省略．\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$L_d u \\geq u$ならば$v_d^{N, u} \\leq v_\\lambda^{d^{\\infty}}$が任意の$N$で成立します．\n",
    "これを$v_\\lambda^{d^\\infty}$のlower approximationと呼ぶことにしましょう． \n",
    "\n",
    "TODO: 最適価値への収束について書く．\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
