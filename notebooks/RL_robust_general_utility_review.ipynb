{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a21390af",
   "metadata": {},
   "source": [
    "# ロバストMDPと凸MDPの論文のチェック\n",
    "\n",
    "参考：\n",
    "* [Robust Reinforcement Learning with General Utility](https://openreview.net/pdf?id=8Uyfr5TcNR)\n",
    "\n",
    "この論文結構怪しいので，検証します．\n",
    "* まず第一に，Proposition 1の部分でConstrained MDPも扱える，みたいな話を書いてますが，CMDPではAssumption 2が明らかに破壊されるので間違ってる．\n",
    "* Section 4.2で1/Kで収束するみたいな話が書いてますが，これも怪しいので確かめます．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30ffc97",
   "metadata": {},
   "source": [
    "**準備**\n",
    "\n",
    "次の最適化を考えます．\n",
    "\n",
    "$$\n",
    "\\min _{\\pi \\in \\Pi} \\max _{P \\in U} f\\left(\\lambda_{\\pi, P}\\right)\n",
    "$$\n",
    "\n",
    "* ここで，$\\lambda_{\\pi, P}$はOccupancy Measureです．\n",
    "* 今回は簡単のためにDirect parameterizationを使います．論文中では一般のパラメータを扱ってます．（22）式付近で言ってますが，もしかしたらSoftmax policyじゃないと無理かも．\n",
    "* 論文では$s$-rectangularなUncertainty set を仮定してますが，別にいらない気がするので今回は無視します．\n",
    "\n",
    "次の最適化を考えます．\n",
    "\n",
    "$$\n",
    "\\pi_{k+1} = \\pi_k - \\beta_k d_k\n",
    "$$\n",
    "\n",
    "ここで，$U_k = \\{P \\in \\arg\\max_{P \\in U}f(\\lambda_{\\pi_k, P})\\}$とします．つまりMaximumを取るような$P$の集合です．\n",
    "また，与えられた$d$について，勾配方向に減る量を次の用に定義します．\n",
    "\n",
    "$$\n",
    "A_k(d):=\\max _{P \\in U_k}\\left[\\nabla_\\pi f\\left(\\lambda_{\\pi_k, P}\\right)^{\\top} d\\right], d \\in B_1:=\\left\\{d^{\\prime} \\in \\mathbb{R}^{d_{\\Theta}}:\\left\\|d^{\\prime}\\right\\| \\leq 1\\right\\}\n",
    "$$\n",
    "\n",
    "* $P$で$\\max$取ってるので，一番勾配が減らない方向ですね．\n",
    "* これ無理やり論文の表記に合わせてますが，実際は$d$は$\\Pi$から出ないように設定しないとダメです．まあ細かいところは一旦無視\n",
    "\n",
    "そして，$d_k$を\n",
    "$$d_k \\in \\arg\\min_{d \\in B_1} A_k(d)$$\n",
    "としてます．つまり，Worst caseについて一番勾配が減るような方向を取ってます．\n",
    "(28)式で，このMinimizationは\n",
    "\n",
    "$$\n",
    "d_{k, t+1} \\leftarrow \\operatorname{proj}_{B_1}\\left[d_{k, t}-\\alpha \\nabla_\\pi f\\left(\\lambda_{\\pi_k, P_{k, t}}\\right)\\right], \\text { where } P_{k, t} \\in \\arg \\max _{P \\in U_k} \\nabla_\\pi f\\left(\\lambda_{\\pi_k, P}\\right)^{\\top} d_{k, t}\n",
    "$$\n",
    "\n",
    "* **コメント** そもそもこの$P_{k, t}$を計算する方法が特に記されてないな… 一応目的関数自体は線形なので，多分劣勾配法で収束するとは思う．試しに$f$が期待収益の時を考えてみよう．このとき，\n",
    "\n",
    "$$\n",
    "\\sum_{s, a}\\nabla_\\pi f\\left(\\lambda_{\\pi_k, P}\\right)(s, a)d_{k, t}(s, a) = \\sum_{s, a}\\lambda_{\\pi_k, P}(s) Q^{\\pi_k}_{P}(s, a)d_{k, t}(s, a)\n",
    "$$\n",
    "\n",
    "になる．これはrectangularでもいつ最大になるのかよくわからないんじゃないかな？Occupancy measureとQの両方に$P$がかかっているけど，これを最大にする$P$はわかんないと思う．\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937e03b9",
   "metadata": {},
   "source": [
    "## 収束の確認\n",
    "\n",
    "細かいところに目をつむって，収束解析してみます．$\\Gamma$を$\\max_P f(...)$とします．\n",
    "このとき，式163付近で，\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\Gamma\\left(\\pi_{k+1}\\right)-\\Gamma\\left(\\pi_k\\right) & \\stackrel{(i)}{\\leq} f\\left(\\lambda_{\\pi_{k+1}, P_{k+1}^*}\\right)-f\\left(\\lambda_{\\pi_k, P_{k+1}^*}\\right) \\\\\n",
    "& \\stackrel{(i i)}{\\leq} \\nabla_\\pi f\\left(\\lambda_{\\pi_k, P_{k+1}^*}\\right)^{\\top}\\left(\\pi_{k+1}-\\pi_k\\right)+\\frac{L_{\\pi, \\pi}}{2}\\left\\|\\pi_{k+1}-\\pi_k\\right\\|^2 \\\\\n",
    "& \\stackrel{(i i i)}{=} \\beta_k \\nabla_\\pi f\\left(\\lambda_{\\pi_k, P_{k+1}^*}\\right)^{\\top} d_k+\\frac{L_{\\pi, \\pi}}{2} \\beta_k^2 \\\\\n",
    "& \\stackrel{(i v)}{\\leq} \\beta_k A_k\\left(d_k\\right)+\\frac{L_{\\pi, \\pi}}{2} \\beta_k^2 \\\\\n",
    "&\\leq \\text{上からGradient dominanceで抑える}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "みたいなことをしていますが，途中で$A_k\\left(d_k\\right)$を使って抑えています．これは正しいですが，現実的じゃなさそう．\n",
    "* 途中過程で$P_{k+1}^*$がでるので，なんとかしてこれを更新中の勾配に出さないといけないわけですね．\n",
    "* もちろん$P_{k+1}^*$は$\\pi_{k+1}$に依存してるので，計算できません．そこで，論文ではそれを更に上から抑える量で抑えていますが，上で見たように，$d_k$の計算ができるかは怪しいです．\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f08e788",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
