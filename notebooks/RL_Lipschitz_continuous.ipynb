{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 強化学習におけるリプシッツ連続性\n",
    "\n",
    "参考：\n",
    "* [Lipschitz Continuity in Model-based Reinforcement Learning](https://arxiv.org/abs/1804.07193)\n",
    "\n",
    "今回は状態空間が連続である場合の話について学びます．\n",
    "状態空間が離散の場合は価値反復法が使えますが，連続の場合には使えません．\n",
    "\n",
    "しかし，MDPの中にリプシッツ連続性のようなものが導入されてる場合は解くことができます．見てみましょう．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## リプシッツ連続性とWasserstein距離\n",
    "\n",
    "数学的な準備をします．\n",
    "\n",
    "---\n",
    "\n",
    "**リプシッツ連続性**\n",
    "\n",
    "２つの距離空間$\\left(M_1, d_1\\right)$と$\\left(M_2, d_2\\right)$を考えます．\n",
    "関数$f: M_1 \\mapsto M_2$は次で定義されるリプシッツ定数が有限である時にリプシッツ連続である，といいます．\n",
    "\n",
    "$$\n",
    "K_{d_1, d_2}(f):=\\sup _{s_1 \\in M_1, s_2 \\in M_1} \\frac{d_2\\left(f\\left(s_1\\right), f\\left(s_2\\right)\\right)}{d_1\\left(s_1, s_2\\right)}\n",
    "$$\n",
    "\n",
    "これは次と等価です：\n",
    "\n",
    "$$\n",
    "\\forall s_1, \\forall s_2 \\quad d_2\\left(f\\left(s_1\\right), f\\left(s_2\\right)\\right) \\leq K_{d_1, d_2}(f) d_1\\left(s_1, s_2\\right)\n",
    "$$\n",
    "\n",
    "$f$は$K_{d_1, d_2}(f)=1$のときにnon-expansionと呼び，$K_{d_1, d_2}(f)<1$のときにcontractionと呼ばれます．\n",
    "\n",
    "---\n",
    "\n",
    "**一様リプシッツ連続**\n",
    "\n",
    "関数$f: M_1 \\times \\mathcal{A} \\mapsto M_2$は次の定数が有限であるときに$\\mathcal{A}$について一様リプシッツ連続であるといいます．\n",
    "\n",
    "$$\n",
    "K_{d_1, d_2}^{\\mathcal{A}}(f):=\\sup _{a \\in \\mathcal{A}} \\sup _{s_1, s_2} \\frac{d_2\\left(f\\left(s_1, a\\right), f\\left(s_2, a\\right)\\right)}{d_1\\left(s_1, s_2\\right)}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "**Wasserstein距離**\n",
    "\n",
    "距離空間$(M, d)$と，$M$上の全ての確率測度$\\mathbb{P}(M)$について，確率分布$\\mu_1 \\in \\mathbb{P}(M)$と$\\mu_2 \\in \\mathbb{P}$のWasserstein距離は，\n",
    "\n",
    "$$\n",
    "W\\left(\\mu_1, \\mu_2\\right):=\\inf _{j \\in \\Lambda} \\iint j\\left(s_1, s_2\\right) d\\left(s_1, s_2\\right) d s_2 d s_1\n",
    "$$\n",
    "\n",
    "で定義さます．\n",
    "ここで，$j$は$M\\times M$上の分布であり，$\\mu_1(s_1)=\\sum_{s_2} j(s_1, s_2)$および$\\mu_2(s_2)=\\sum_{s_1} j(s_1, s_2)$を満たします．\n",
    "$\\Lambda$はそのような$j$の全ての集合です．\n",
    "\n",
    "**解釈**\n",
    "\n",
    "距離$d(s_1, s_2)$は$s_1$を$s_2$に輸送するコストとみなすことができます．\n",
    "よって，積分$\\iint j\\left(s_1, s_2\\right) d\\left(s_1, s_2\\right) d s_2 d s_1$は測度$\\mu_1$を$\\mu_2$に動かすコストとみなせます．\n",
    "\n",
    "このため，Wasserstein距離はEarth-Mover's Distanceとも呼ばれます．\n",
    "\n",
    "**双対性**\n",
    "\n",
    "Wasserstein距離は双対性を使うと，次のようなリプシッツ連続性を使った形式に変形できます．\n",
    "\n",
    "$$\n",
    "W\\left(\\mu_1, \\mu_2\\right)=\\sup _{f: K_{d, d_{\\mathbb{R}}}(f) \\leq 1} \\int\\left(f(s) \\mu_1(s)-f(s) \\mu_2(s)\\right) d s .\n",
    "$$\n",
    "\n",
    "これはKantorovich-Rubinstein双対性と呼ばれます．\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## リプシッツ連続性を使ったMDPの定義\n",
    "\n",
    "次の定義を導入します：\n",
    "\n",
    "---\n",
    "\n",
    "距離が導入されている状態空間$\\left(\\mathcal{S}, d_{\\mathcal{S}}\\right)$と，行動空間$\\mathcal{A}$を考えます．\n",
    "$F_g=\\{f: \\mathcal{S} \\mapsto \\mathcal{S}\\}$を状態から状態へmapする関数の集合とします．\n",
    "また，$a \\in \\mathcal{A}$について，この上の分布$g(f\\mid a)$を考えます．\n",
    "\n",
    "このとき，次の定数が有限のとき，$F_g$はLipschitz model classであるといいます．\n",
    "\n",
    "$$\n",
    "K_F:=\\sup _{f \\in F_g} K_{d_{\\mathcal{S}}, d_{\\mathcal{S}}}(f)\n",
    "$$\n",
    "\n",
    "つまり，$F_g$の中の関数全てがリプシッツ連続である場合です．\n",
    "\n",
    "---\n",
    "\n",
    "**一般的な遷移関数**\n",
    "\n",
    "ここで定義した$F_g$を使えば，遷移関数を定義することができます：\n",
    "\n",
    "$$\n",
    "\\widehat{T}\\left(s^{\\prime} \\mid s, a\\right)=\\sum_{f\\in F_g} \\mathbb{1}\\left(f(s)=s^{\\prime}\\right) g(f \\mid a) .\n",
    "$$\n",
    "\n",
    "さらに，遷移元を状態ではなく，分布$\\mu(s)$を考えた場合の一般的な遷移関数も定義しておきます：\n",
    "\n",
    "$$\n",
    "\\widehat{T}_{\\mathcal{G}}\\left(s^{\\prime} \\mid \\mu, a\\right)=\\int_s \\underbrace{\\sum_f \\mathbb{1}\\left(f(s)=s^{\\prime}\\right) g(f \\mid a)}_{\\widehat{T}\\left(s^{\\prime} \\mid s, a\\right)} \\mu(s) d s .\n",
    "$$\n",
    "\n",
    "実はこのような形式を使うと，有限MDPの遷移関数は全て表現できます．（つまり，この定義自体では$\\mathcal{S}$が距離空間である必要はありません．距離の導入は後で使います．）\n",
    "\n",
    "**証明**\n",
    "\n",
    "$\\operatorname{Pr}\\left(s, a, s^{\\prime}\\right)$を有限MDPの遷移関数とします．\n",
    "状態に次のような順番を導入しましょう：$s_1, \\ldots, s_n$．また，$s_0$を到達不可能な状態とします．\n",
    "これを使って，次の累積分布を導入します．\n",
    "\n",
    "$$\n",
    "C\\left(s, a, s_i\\right):=\\sum_{j=0}^i \\operatorname{Pr}\\left(s, a, s_j\\right)\n",
    "$$\n",
    "\n",
    "次の$L$を定義します（$C$がとり得る値の集合です）：\n",
    "\n",
    "$$\n",
    "L:=\\left\\{C\\left(s, a, s_i\\right) \\mid \\quad s \\in \\mathcal{S}, i \\in[0, n]\\right\\}\n",
    "$$\n",
    "\n",
    "MDPは有限なので，$|L|$は有限です．\n",
    "$c_i$を$L$のうち，$i$番目に小さい値とします．このとき$c_0=0$かつ$c_{|L|}=1$です．\n",
    "\n",
    "これを使って，$f_1, \\ldots, f_{|L|}$を次のように定義します．\n",
    "\n",
    "任意の$\\forall i \\in [|L|]$と$\\forall j \\in n$について，\n",
    "$$\n",
    "C\\left(s, a, s_{j-1}\\right)<c_i \\leq C\\left(s, a, s_j\\right)\n",
    "$$\n",
    "のとき，またそのときに限り，$f_i(s)=s_j$とします．\n",
    "\n",
    "また，$f$上の分布を\n",
    "\n",
    "$$\n",
    "g\\left(f_i \\mid a\\right):=c_i-c_{i-1} .\n",
    "$$\n",
    "\n",
    "とします．こうすると，\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "& \\sum_i \\mathbb{1}\\left(f_i(s)=s_j\\right) g\\left(f_i \\mid a\\right) \\\\\n",
    "& =\\sum_i \\mathbb{1}\\left(C\\left(s, a, s_{j-1}\\right)<c_i \\leq C\\left(s, a, s_j\\right)\\right)\\left(c_i-c_{i-1}\\right) \\\\\n",
    "& =C\\left(s, a, s_j\\right)-C\\left(s, a, s_{j-1}\\right) \\\\\n",
    "& =\\operatorname{Pr}\\left(s, a, s_j\\right)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "なので，結局遷移関数が復元できます．\n",
    "\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wasserstein距離を使った遷移関数の評価\n",
    "\n",
    "強化学習ではしばしば，遷移関数$T$と推定した遷移関数$\\hat{T}$の差が重要になることがあります（モデルベースRLなど）．\n",
    "よく使われるのは全変動距離やKLダイバージェンスですが，状態空間に距離が定義されている場合はWasserstein距離を使ったほうが自然に差が測定できます．\n",
    "\n",
    "（これは面倒なので論文の４章参照）\n",
    "\n",
    "続いて，Wasserstein距離が離れた遷移関数同士で誤差がどのようになるか見てみましょう．まず，次の定義を導入します：\n",
    "\n",
    "$$\n",
    "\\forall s \\forall a \\quad W(\\widehat{T}(\\cdot \\mid s, a), T(\\cdot \\mid s, a)) \\leq \\Delta\n",
    "$$\n",
    "\n",
    "を満たすような$\\hat{T}$が$F_g$によって誘導されるとき，$F_g$は$\\Delta$-accurateであるといいます．\n",
    "さて，行動の系列$a_0, \\ldots, a_{n-1}$について，$\\widehat{T}_{\\mathcal{G}}^n(\\cdot \\mid \\mu):=\\underbrace{\\widehat{T}_{\\mathcal{G}}\\left(\\cdot \\mid \\widehat{T}_{\\mathcal{G}}\\left(\\cdot \\mid \\ldots \\widehat{T}_{\\mathcal{G}}\\left(\\cdot \\mid \\mu, a_0\\right) \\ldots, a_{n-2}\\right), a_{n-1}\\right)}_{n \\text { recursive calls }}$として，遷移の誤差\n",
    "\n",
    "$$\n",
    "\\delta(n):=W\\left(\\widehat{T}_{\\mathcal{G}}^n(\\cdot \\mid \\mu), T_{\\mathcal{G}}^n(\\cdot \\mid \\mu)\\right)\n",
    "$$\n",
    "\n",
    "について考えましょう．\n",
    "\n",
    "\n",
    "このとき，$\\Delta$-accurate かつリプシッツ定数が$K_F$の$\\widehat{T}_{\\mathcal{G}}$と，リプシッツ定数が$K_T$の真の遷移関数$T_\\mathcal{G}$について，\n",
    "\n",
    "$$\n",
    "\\delta(n):=W\\left(\\widehat{T}_{\\mathcal{G}}^n(\\cdot \\mid \\mu), T_{\\mathcal{G}}^n(\\cdot \\mid \\mu)\\right) \\leq \\Delta \\sum_{i=0}^{n-1}(\\bar{K})^i\n",
    "$$\n",
    "\n",
    "が成立します．ここで，$\\bar{K}=\\min\\{K_F, K_T\\}$です．\n",
    "\n",
    "つまり，真の遷移との誤差を小さくするためには，遷移がリプシッツ連続であることと，１ステップの誤差が小さいことが重要になります．\n",
    "\n",
    "<!-- また，次が成立します． -->\n",
    "<!-- \n",
    "$\\hat{T}_\\mathcal{G}$がLipschitz model class $F_g$によって誘導されるとき，$\\hat{T}_\\mathcal{G}$は次の定数について一様リプシッツ連続です．\n",
    "\n",
    "$$\n",
    "K_{W, W}^{\\mathcal{A}}\\left(\\widehat{T}_{\\mathcal{G}}\\right):=\\sup _a \\sup _{\\mu_1, \\mu_2} \\frac{W\\left(\\widehat{T}_{\\mathcal{G}}\\left(\\cdot \\mid \\mu_1, a\\right), \\widehat{T}_{\\mathcal{G}}\\left(\\cdot \\mid \\mu_2, a\\right)\\right)}{W\\left(\\mu_1, \\mu_2\\right)} \\leq K_F\n",
    "$$\n",
    "\n",
    " -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lipschitz modelにおける価値の誤差解析\n",
    "\n",
    "行動空間を$\\mathcal{A}=\\{a\\}$とし，\n",
    "$\\langle\\mathcal{S}, \\mathcal{A}, T, R, \\gamma\\rangle$と$\\langle\\mathcal{S}, \\mathcal{A}, T, R, \\gamma\\rangle$なるMDP２つを考えます．\n",
    "これはつまり固定された方策によって遷移が確定したマルコフ連鎖と同じですね．\n",
    "\n",
    "そして，\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&V_T(s):=\\sum_{n=0}^{\\infty} \\gamma^n \\int T_{\\mathcal{G}}^n\\left(s^{\\prime} \\mid \\delta_s\\right) R\\left(s^{\\prime}\\right) d s^{\\prime}\\\\\n",
    "&V_{\\widehat{T}}(s):=\\sum_{n=0}^{\\infty} \\gamma^n \\int \\widehat{T}_{\\mathcal{G}}^n\\left(s^{\\prime} \\mid \\delta_s\\right) R\\left(s^{\\prime}\\right) d s^{\\prime}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "なる状態価値を考えましょう．これもいつもの状態価値そのまんまですね．\n",
    "このとき，次が成立します．\n",
    "\n",
    "$F_g$がLipschitz model classであるとし，$\\hat{T}$は$\\Delta$-accurateとします．また，報酬関数のリプシッツ定数が$K_R=K_{d_{\\mathcal{S}}, \\mathbb{R}}(R)$であるとします．このとき，$\\forall s \\in \\mathcal{S}$ and $\\bar{K} \\in\\left[0, \\frac{1}{\\gamma}\\right)$について，\n",
    "\n",
    "$$\n",
    "\\left|V_T(s)-V_{\\widehat{T}}(s)\\right| \\leq \\frac{\\gamma K_R \\Delta}{(1-\\gamma)(1-\\gamma \\bar{K})}\n",
    "$$\n",
    "\n",
    "が成立します．\n",
    "つまり，異なる遷移によって計算された価値の差をバウンドするには，MDPのリプシッツ性が重要になってきます．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
