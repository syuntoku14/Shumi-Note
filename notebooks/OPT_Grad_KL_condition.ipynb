{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KL条件と一次最適化手法\n",
    "\n",
    "* [Calculus of the exponent of Kurdyka-Lojasiewicz inequality and its applications to linear convergence of first-order methods](https://arxiv.org/abs/1602.02915)\n",
    "\n",
    "１次の最適化手法の収束を特徴づける指標にError boundやPL条件などがあります．今回はKurdyka-Lojasiewicz (KL) 条件についての話です．\n",
    "\n",
    "KL条件を使った１次収束の解析はかなり色々あります．TODO: 全部読んでおこう\n",
    "* [Proximal alternating minimization and projection methods for nonconvex problems: an approach based on the Kurdyka-Lojasiewicz inequality](https://arxiv.org/abs/0801.1780) \n",
    "* [Splitting Methods with Variable Metric for Kurdyka–Łojasiewicz Functions and General Convergence Rates](https://link.springer.com/article/10.1007/s10957-014-0642-3)\n",
    "* [Douglas–Rachford splitting for nonconvex optimization with application to nonconvex feasibility problems](https://link.springer.com/article/10.1007/s10107-015-0963-5)\n",
    "* [A Block Coordinate Descent Method for Regularized Multiconvex Optimization with Applications to Nonnegative Tensor Factorization and Completion](https://epubs.siam.org/doi/abs/10.1137/120887795?casa_token=XfqCNUhm5fgAAAAA:AHuf7JhLJf--ECsK-iIWpBWVSy3uaGn99t1kslLF-ffbQHe4XlfrVM8cMSk6YMZ3V2eZD2jBFg)\n",
    "\n",
    "典型的には，KL指数 $\\alpha \\in [0, 1)$の最適化関数について，１次の勾配法で$\\{x^k\\}$が得られたとき，次の結論が導けます：\n",
    "1. $\\alpha = 0$ならば，$\\{x^k\\}$は有限回で収束する\n",
    "2. $\\alpha \\in (0, 1/2]$ならば，$\\{x^k\\}$は線形に収束する\n",
    "2. $\\alpha \\in (1/2, 1)$ならば，$\\{x^k\\}$は劣線形に収束する\n",
    "\n",
    "KL指数がわかれば収束速度も導けますが，KL指数を推定するのは一般にむずいらしいです（[Mathematical Programs with Equilibrium Constraints](https://www.cambridge.org/core/books/mathematical-programs-with-equilibrium-constraints/03981C32ABDD55A4001BF58BA0C57444)の63ページ参照）．\n",
    "今回はKL指数を推定する話についても触れます．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 表記とKL条件の定義\n",
    "\n",
    "大体の定義はVariational Analysisに則ってます．\n",
    "\n",
    "* フレシェ劣微分：$\\widehat{\\partial} f(x):=\\left\\{v \\in \\mathbb{R}^n: \\liminf _{z \\rightarrow x, z \\neq x} \\frac{f(z)-f(x)-\\langle v, z-x\\rangle}{\\|z-x\\|} \\geq 0\\right\\}$\n",
    "* limiting 劣微分：$\\partial f(x):=\\left\\{v \\in \\mathbb{R}^n: \\exists x^t \\xrightarrow{f} x, v^t \\rightarrow v\\right.$ with $v^t \\in \\widehat{\\partial} f\\left(x^t\\right)$ for each $\\left.t\\right\\}$\n",
    "* フレシェとlimiting劣微分によるNormal cone：$N_S(x)=\\partial \\delta_S(x)$および$\\widehat{N}_S(x)=\\widehat{\\partial} \\delta_S(x)$\n",
    "* proximal mapping：$\\operatorname{prox}_P(z)=\\underset{x \\in \\mathbb{R}^n}{\\arg \\min }\\left\\{P(x)+\\frac{1}{2}\\|x-z\\|^2\\right\\}$\n",
    "    * これはnon-expansionです：$\\left\\|\\operatorname{prox}_P(y)-\\operatorname{prox}_P(z)\\right\\| \\leq\\|y-z\\|$\n",
    "\n",
    "$h$を平滑な関数，$P$を凸関数とします．$f=h+P$について，$\\mathcal{X}$を$f$の停留点の集合とすると，次が成立します\n",
    "$$\n",
    "\\bar{x} \\in \\mathcal{X} \\Longleftrightarrow 0 \\in \\partial(h+P)(\\bar{x}) \\Longleftrightarrow 0 \\in \\nabla h(\\bar{x})+\\partial P(\\bar{x}) \\Longleftrightarrow \\bar{x}-\\nabla h(\\bar{x}) \\in \\bar{x}+\\partial P(\\bar{x}) \\Longleftrightarrow \\bar{x}=\\operatorname{prox}_P(\\bar{x}-\\nabla h(\\bar{x}))\n",
    "$$\n",
    "\n",
    "* **コメント**：これは多分[OPT_Grad_proximal_gradient_method.ipynb](OPT_Grad_proximal_gradient_method.ipynb)でやった話だと思う．\n",
    "\n",
    "---\n",
    "\n",
    "**Luo-TsengのError bound** （First-order error boundとも呼ばれる）\n",
    "\n",
    "$\\mathcal{X}$を$f$の停留点の集合とします．任意の$\\zeta \\geq \\inf f$について，次を満たす$c, \\epsilon > 0$が存在するとき，$f$はLuo-TsengのError boundを満たすといいます：\n",
    "\n",
    "$$\n",
    "\\operatorname{dist}(x, \\mathcal{X}) \\leq c\\left\\|\\operatorname{prox}_P(x-\\nabla h(x))-x\\right\\|\n",
    "$$\n",
    "\n",
    "が$\\left\\|\\operatorname{prox}_P(x-\\nabla h(x))-x\\right\\|<\\epsilon$ および $f(x) \\leq \\zeta$ならば常に成立する．\n",
    "\n",
    "* **コメント**：若干分かりづらくなってるが，$P$がidentity関数なら，これは[OPT_Grad_PL_convergence.ipynb](OPT_Grad_PL_convergence.ipynb)でやったError boundと同じ．\n",
    "\n",
    "---\n",
    "\n",
    "**KL条件とKL関数**\n",
    "\n",
    "Properでclosedな関数$f$は，次を満たすときに$\\bar{x} \\in \\operatorname{dom} \\partial f$ でKL条件を満たすといいます：\n",
    "\n",
    "$\\bar{x}$の近傍$\\mathcal{N}$，$\\nu \\in (0, \\infty]$，および$\\psi(0)=0$を満たす連続な凹関数$\\psi: [0, \\nu) \\to \\mathbb{R}_+$が存在する：\n",
    "1. $\\psi$ が$(0, \\nu)$ で連続微分可能であり， $\\psi^{\\prime}>0$;\n",
    "2. 任意の$f(\\bar{x})<f(x)<f(\\bar{x})+\\nu$を満たす$x \\in \\mathcal{N}$について，\n",
    "\n",
    "$$\n",
    "\\psi^{\\prime}(f(x)-f(\\bar{x})) \\operatorname{dist}(0, \\partial f(x)) \\geq 1\n",
    "$$\n",
    "\n",
    "任意の$\\operatorname{dom} \\partial f$に対して，KL条件を満たす$f$はKL関数と呼ばれます．\n",
    "\n",
    "---\n",
    "\n",
    "**KL指数**\n",
    "\n",
    "$\\psi$が$\\alpha \\in [0, 1)$と$c > 0$に対して$\\psi(s)=cs^{1-\\alpha}$を満たす関数のとき，つまり\n",
    "$$\n",
    "\\operatorname{dist}(0, \\partial f(x)) \\geq c(f(x)-f(\\bar{x}))^\\alpha\n",
    "$$\n",
    "が\n",
    "$\\|x-\\bar{x}\\| \\leq \\epsilon$および$f(\\bar{x})<f(x)<f(\\bar{x})+\\nu$で成り立っているならば，$f$はKL指数が$\\alpha$であると言います．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KL条件とError bound\n",
    "\n",
    "次の関数を考えましょう：\n",
    "\n",
    "$$f(x):=h(x)+P(x)$$\n",
    "\n",
    "* $h$はproperで閉じた関数．domainはopenとする．また，連続微分可能な平滑関数とする\n",
    "* $P$はproperで閉じた凸関数\n",
    "\n",
    "また，$f$の停留点の集合$\\mathcal{X}$について，次を仮定します：\n",
    "* （仮定）：任意の$\\bar{x} \\in \\mathcal{X}$について，次を満たす$\\delta > 0$が存在する：$y \\in \\mathcal{X}$ and $\\|y-\\bar{x}\\| \\leq \\delta$ならば，$f(y) = f(\\bar{x})$．\n",
    "    * つまり，適当な停留点$\\bar{x}$の十分近くの停留点では関数の値が同じってこと？\n",
    "* $h$が凸ならばこれは成立します．\n",
    "\n",
    "上で見た$f$について，次が成立します：\n",
    "\n",
    "* 任意の$x \\in \\operatorname{dom} \\partial f$について，\n",
    "$\\left\\|\\operatorname{prox}_P(x-\\nabla h(x))-x\\right\\| \\leq \\operatorname{dist}(0, \\partial f(x))$.\n",
    "\n",
    "つまり，停留点ではprox-gradient mappingが$0$になります．\n",
    "多分[OPT_Grad_proximal_gradient_method](OPT_Grad_proximal_gradient_method.ipynb)で見た話と同じかも．\n",
    "\n",
    "これを使うと，Error boundとKL条件の関係が出せます．\n",
    "\n",
    "---\n",
    "\n",
    "**Theorem 4.1** \n",
    "\n",
    "$f$について，\n",
    "* $\\mathcal{X} \\neq \\emptyset$\n",
    "* 上の仮定\n",
    "* Error bound\n",
    "\n",
    "が成立しているとします．このとき，$f$はKL指数が$1/2$です．\n",
    "\n",
    "**証明**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
