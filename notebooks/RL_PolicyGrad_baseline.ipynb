{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 確率的な方策勾配法\n",
    "\n",
    "参考：\n",
    "* [Understanding the Effect of Stochasticity in Policy Optimization](https://arxiv.org/abs/2110.15572)\n",
    "* [Beyond variance reduction: Understanding the true impact of baselines on policy optimization](https://arxiv.org/abs/2008.13773)\n",
    "\n",
    "よくある方策勾配法の理論では基本的に「厳密な」勾配がある状況だけ考えてます．しかし，実際のアプリケーションでは確率的な勾配が使われます．\n",
    "確率的な勾配になったときに何が言えるでしょうか？\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 厳密な方策の場合\n",
    "\n",
    "[RL_PolicyGrad_softmax_convergence](RL_PolicyGrad_softmax_convergence.ipynb)と表記はほぼ同じなので省略します．\n",
    "\n",
    "softmaxパラメータを考えます．\n",
    "まずSoftmax PG, NPG, GNPGについてまとめてみましょう．\n",
    "\n",
    "### Softmax PG\n",
    "\n",
    "[RL_PolicyGrad_softmax_convergence](RL_PolicyGrad_softmax_convergence.ipynb)でやったので省略します．Gradient dominanceが成立し，そして適切な学習率のもとでは最適方策に$\\Theta(1/t)$で収束します．\n",
    "\n",
    "### NPG\n",
    "\n",
    "* 更新方法：$\\theta_{t+1} \\leftarrow \\theta_t+\\eta \\cdot r$\n",
    "* 収束レート：$O(e^{-e\\cdot t})$\n",
    "\n",
    "また，次の２種類のGradient dominanceが成立します：\n",
    "\n",
    "---\n",
    "\n",
    "$$\n",
    "\\left\\langle\\frac{d \\pi_\\theta^{\\top} r}{d \\theta}, r\\right\\rangle \\geq \\pi_\\theta\\left(a^*\\right) \\cdot \\Delta \\cdot\\left(\\pi^*-\\pi_\\theta\\right)^{\\top} r .\n",
    "$$\n",
    "\n",
    "また，\n",
    "\n",
    "$$\n",
    "\\left(\\pi^{\\prime}-\\pi\\right)^{\\top} r \\geq\\left[1-\\frac{1}{\\pi\\left(a^*\\right) \\cdot\\left(e^{\\eta \\cdot \\Delta}-1\\right)+1}\\right] \\cdot\\left(\\pi^*-\\pi\\right)^{\\top} r\n",
    "$$\n",
    "\n",
    "ここで，\n",
    "$$\n",
    "\\pi^{\\prime}(a):=\\frac{\\pi(a) \\cdot e^{\\eta \\cdot r(a)}}{\\sum_{a^{\\prime}} \\pi\\left(a^{\\prime}\\right) \\cdot e^{\\eta \\cdot r\\left(a^{\\prime}\\right)}}\n",
    "$$\n",
    "としてます．\n",
    "\n",
    "---\n",
    "\n",
    "**コメント：**：論文にLemma 2と３がどう役に立ってるのかあんまりちゃんと書いてないかも．何がcontinuousで何がdiscreteなんだ？ただ１つ目はSoftmax PGよりマシなバウンドになってる．Softmax PGは$\\left\\|\\frac{d \\pi_{\\theta_t}^{\\top} r}{d \\theta_t}\\right\\|_2^2$が必要だけど，NPGは$\\left\\langle\\frac{d \\pi_{\\theta_t}^{\\top} r}{d \\theta_t}, r\\right\\rangle$でいけてる．\n",
    "\n",
    "２番めのやつを使うと特にExponentialなバウンドが出せます：\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\left(\\pi^*\\right. & \\left.-\\pi_{\\theta_{t+1}}\\right)^{\\top} r=\\left(\\pi^*-\\pi_{\\theta_t}\\right)^{\\top} r-\\left(\\pi_{\\theta_{t+1}}-\\pi_{\\theta_t}\\right)^{\\top} r \\\\\n",
    "& \\leq \\frac{1}{\\pi_{\\theta_t}\\left(a^*\\right) \\cdot\\left(e^{\\eta \\cdot \\Delta}-1\\right)+1} \\cdot\\left(\\pi^*-\\pi_{\\theta_t}\\right)^{\\top} r \\\\\n",
    "& \\leq \\frac{1}{\\pi_{\\theta_1}\\left(a^*\\right) \\cdot\\left(e^{\\eta \\cdot \\Delta}-1\\right)+1} \\cdot\\left(\\pi^*-\\pi_{\\theta_t}\\right)^{\\top} r \\\\\n",
    "& \\leq \\frac{1}{\\left[\\pi_{\\theta_1}\\left(a^*\\right) \\cdot\\left(e^{\\eta \\cdot \\Delta}-1\\right)+1\\right]^t} \\cdot\\left(\\pi^*-\\pi_{\\theta_1}\\right)^{\\top} r \\\\\n",
    "& =\\frac{\\left(\\pi^*-\\pi_{\\theta_1}\\right)^{\\top} r}{e^{c \\cdot t}}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "特に３行目は\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\pi_{\\theta_{t+1}}\\left(a^*\\right) & =\\frac{\\pi_{\\theta_t}\\left(a^*\\right) \\cdot e^{\\eta \\cdot r\\left(a^*\\right)}}{\\sum_a \\pi_{\\theta_t}(a) \\cdot e^{\\eta \\cdot r(a)}} \\\\\n",
    "& =\\frac{\\pi_{\\theta_t}\\left(a^*\\right)}{\\sum_a \\pi_{\\theta_t}(a) \\cdot e^{-\\eta \\cdot \\Delta(a)}} \\\\\n",
    "& \\geq \\pi_{\\theta_t}\\left(a^*\\right) . \\quad(\\Delta(a) \\geq 0)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "を使いました．結局普通のPGより指数的に早いので，**exactな勾配が取れる場合には**NPGを使ったほうが良いです．\n",
    "\n",
    "### Geometry-aware Normalized PG\n",
    "\n",
    "[Leveraging Non-uniformity in First-order Non-convex Optimization](https://proceedings.mlr.press/v139/mei21a.html)をちゃんと読もう．\n",
    "\n",
    "NPGはLSバウンドを良くする方向に進化してますが，Geometry-aware Normalized PGは普通のPGのLSバウンドのnon-uniformnessを利用しています．\n",
    "\n",
    "* 更新方法：$\\theta_{t+1} \\leftarrow \\theta_t+\\eta \\cdot \\frac{d \\pi_{\\theta_t}^{\\top} r}{d \\theta_t} /\\left\\|\\frac{d \\pi_{\\theta_t}^{\\top} r}{d \\theta_t}\\right\\|_2$\n",
    "\n",
    "\n",
    "次が成立します：\n",
    "$$\n",
    "\\left(\\pi^*-\\pi_{\\theta_t}\\right)^{\\top} r \\leq\\left(\\pi^*-\\pi_{\\theta_1}\\right)^{\\top} r \\cdot e^{-\\frac{c \\cdot(t-1)}{12}}\n",
    "$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 確率的更新の場合\n",
    "\n",
    "On-policyな更新を考えましょう．次の重点サンプリング（IS）を使ってUnbiasedな更新をすることを考えます．\n",
    "$a_t \\sim \\pi_{\\theta_t}(\\cdot)$について，\n",
    "$$\n",
    "\\hat{r}_t(a)=\\frac{\\mathbb{I}\\left\\{a_t=a\\right\\}}{\\pi_{\\theta_t}(a)} \\cdot r(a) \\text { for all } a \\in[K]\n",
    "$$\n",
    "とします．\n",
    "\n",
    "さて，このISを使った更新をした場合，\n",
    "* softmax PGは最適方策に確率収束します．\n",
    "* NPGは\n",
    "  * 正の確率で$\\sum_{a \\neq a^*} \\pi_{\\theta_t}(a) \\rightarrow 1$に収束し\n",
    "  * 正の確率で，任意の$a$について，$\\pi_{\\theta_t}(a) \\rightarrow 1$に収束します．\n",
    "* GNPGは正の確率で$\\pi_{\\theta_t}(a) \\rightarrow 1$に収束します．\n",
    "\n",
    "つまり，NPGとGNPGは確率的方策勾配を使った場合に最適方策を得ない場合があります．\n",
    "\n",
    "なぜこんなことが起きるのか？の話はCommittal rateの章を読もう（第３章）．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: baselineについて\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
