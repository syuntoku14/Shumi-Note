{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 逐次意思決定問題における統計的複雑度\n",
    "\n",
    "参考：\n",
    "* [The Statistical Complexity of Interactive Decision Making](https://arxiv.org/abs/2112.13487)\n",
    "\n",
    "教師あり学習ではVC次元やラデマッハ複雑度などの統計的複雑度によって統計的学習問題の難しさを測ることができます．\n",
    "逐次意思決定問題では同じようなことはできないでしょうか？逐次意思決定問題の場合はそんなに単純ではありません（探索があるためです．実際，VC次元を単純に使ってもうまくいきません．[BANDIT_General_Eluder_dimension.ipynb](BANDIT_General_Eluder_dimension.ipynb)参照）\n",
    "\n",
    "\n",
    "また，逐次意思決定問題は問題設定も多種多様です．Bandit，RL, POMDPなど，様々な問題設定が考えられ，それぞれに適切な統計的複雑度が存在しそうです．\n",
    "そこで，今回は多様な逐次意思決定問題を含む，一般的な問題設定と，そこでの統計的複雑度について学びます．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Making with Structured Observations (DMSO)\n",
    "\n",
    "DMSOは一般的な逐次意思決定問題のフレームワークとして提案されました．\n",
    "\n",
    "準備：\n",
    "* $T$ラウンドの学習を考えます．それぞれのラウンドで，\n",
    "* 学習者は意思決定$\\pi^{(t)}\\in \\Pi$を選択します．\n",
    "* 環境は報酬$r^{(t)} \\in \\mathcal{R} \\subseteq \\mathbb{R}$と観測$o^{(t)}\\in \\mathcal{O}$を，意思決定に応じて選択します．報酬と観測は学習者によって観測されます．\n",
    "* また，$r^{(t)}, o^{(t)}$のペアは未知の分布$M^{\\star}\\left(\\pi^{(t)}\\right)$からサンプルされるとします．\n",
    "ここで，$M^{\\star}: \\Pi \\rightarrow \\Delta(\\mathcal{R} \\times \\mathcal{O})$は意思決定を結果にマップする**モデル**です．\n",
    "* 学習と関数近似を有効利用するために，学習者はモデルのクラス$\\mathcal{M}$にアクセスできるとします．また，$M^\\star \\in \\mathcal{M}$を仮定します．$\\mathcal{M}$は例えば線形モデルやニューラルネットワーク，ランダムフォレストなど，なんでもいいです．\n",
    "* $\\mathbb{E}^{M, \\pi}[\\cdot]$ は$(r, o) \\sim M(\\pi)$の期待値を表すとします．\n",
    "    * $f^M(\\pi) := \\mathbb{E}^{M, \\pi}[r]$は期待報酬として，$\\pi_M:= \\arg\\max_{\\pi \\in \\Pi} f^M(\\pi)$は最大の期待報酬を与える意思決定とします．\n",
    "* $\\Pi_{\\mathcal{M}}:=\\left\\{\\pi_M \\mid M \\in \\mathcal{M}\\right\\}$はそれぞれのモデルに対しての最適意思決定の集合とします．\n",
    "* $\\mathcal{F}_{\\mathcal{M}}:=\\left\\{f^M \\mid M \\in \\mathcal{M}\\right\\}$はそれぞれのモデルに対する期待報酬関数の集合とします．\n",
    "* 学習者の性能は次のリグレットで測定するとします：\n",
    "\n",
    "$$\\operatorname{Reg}_{\\mathrm{DM}}:=\\sum_{t=1}^T \\mathbb{E}_{\\pi^{(t)} \\sim p^{(t)}}\\left[f^{\\star}\\left(\\pi^{\\star}\\right)-f^{\\star}\\left(\\pi^{(t)}\\right)\\right]$$\n",
    "\n",
    "ここで，\n",
    "* $f^{\\star}=f^{M^{\\star}}$および$\\pi^{\\star}=\\pi_{M^{\\star}}$としました．また，$p^{(t)} \\in \\Delta(\\Pi)$は学習者の意思決定の分布です．\n",
    "\n",
    "このDMSOはいろいろな逐次意思決定問題を内包する一般的な問題設定です．\n",
    "\n",
    "---\n",
    "\n",
    "**例：構造的バンディット**\n",
    "\n",
    "$\\pi^{(t)}$をアーム，$\\Pi$をアームの空間とすれば，$\\mathcal{O}=\\{\\varnothing\\}$のとき，DMSOは構造的バンディット問題と同じです．\n",
    "\n",
    "さらに次を含みます：\n",
    "* $\\Pi=\\{1,\\dots, A\\}$かつ$\\mathcal{F}_{\\mathcal{M}}=\\mathbb{R}^A$のとき，有限アームバンディットと同じです．\n",
    "* $\\Pi \\in \\mathbb{R}^d$かつ$\\mathcal{F}_{\\mathcal{M}}$が線形関数のクラスのとき，線形バンディットと同じです．\n",
    "* 他にもいろいろ\n",
    "\n",
    "---\n",
    "\n",
    "**例：オンライン強化学習**\n",
    "\n",
    "$M=\\left\\{\\left\\{\\mathcal{S}_h\\right\\}_{h=1}^H, \\mathcal{A},\\left\\{P_h^M\\right\\}_{h=1}^H,\\left\\{R_h^M\\right\\}_{h=1}^H, d_1\\right\\}$を有限MDPとします．\n",
    "\n",
    "エピソードのスタート時に，確率的な非定常方策$\\pi=\\left(\\pi_1, \\ldots, \\pi_H\\right) \\in \\Pi_{\\mathrm{RNS}}$を選択するとします．そして$|pi$の評価は\n",
    "\n",
    "$$f^M(\\pi):=\\mathbb{E}^{M, \\pi}\\left[\\sum_{h=1}^H r_h\\right]$$\n",
    "\n",
    "によって行われるとします．\n",
    "このとき，例えば$M^\\star$をMDP，$\\mathcal{M}$をMDPのクラスとすれば，これはモデルベース強化学習を含みます．また，$M^\\star$を最適Q関数として，$\\mathcal{M}$をQ関数のクラスとすれば，モデルフリー強化学習を含むことになります．\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision-Estimation Coefficient (DEC)\n",
    "\n",
    "上のDSMOフレームワークについて，次のDEC複雑度を導入します．\n",
    "モデルクラス$\\mathcal{M}$とノミナルモデル$\\bar{M}$に対して，\n",
    "\n",
    "$$\n",
    "\\operatorname{dec}_\\gamma(\\mathcal{M}, \\bar{M})=\\inf _{p \\in \\Delta(\\Pi)} \\sup _{M \\in \\mathcal{M}} \\mathbb{E}_{\\pi \\sim p}[\\underbrace{f^M\\left(\\pi_M\\right)-f^M(\\pi)}_{\\text {regret of decision }}-\\gamma \\cdot \\underbrace{D_{\\mathrm{H}}^2(M(\\pi), \\bar{M}(\\pi))}_{\\text {estimation error for obs. }}],\n",
    "$$\n",
    "\n",
    "とします．ここで，$\\gamma > 0$はスケール用のパラメータ，$D_{\\mathrm{H}}^2(\\mathbb{P}, \\mathbb{Q})=\\int(\\sqrt{d \\mathbb{P}}-\\sqrt{d \\mathbb{Q}})^2$はHellinger距離です．\n",
    "\n",
    "また，$\\operatorname{dec}_\\gamma(\\mathcal{M})=\\sup _{\\bar{M} \\in \\mathcal{M}} \\operatorname{dec}_\\gamma(\\mathcal{M}, \\bar{M})$とします．\n",
    "\n",
    "**直感的な説明：**\n",
    "* １項目：１項目は$\\pi$の$M$におけるリグレットです．\n",
    "* ２項目：２項目は$M(\\pi)$と$\\bar{M}(\\pi)$の区別の付きやすさを表してます．\n",
    "\n",
    "つまり，$\\operatorname{dec}_\\gamma(\\mathcal{M})$は次の場合に大きくなります：\n",
    "* 最悪ケースのリグレットが大きい場合：１項目が大きくなる\n",
    "* 非常に見分けづらいMDPがある場合：２項目が大きくなる\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DECと下界\n",
    "\n",
    "DECを使うと，DMSOにおけるどんなアルゴリズムも絶対に取ってしまうリグレットの下界が求まります．\n",
    "\n",
    "まず，$\\varepsilon \\geq 0$とモデル$\\bar{M} \\in \\mathcal{M}$に対して，次の局所モデルクラスを定義します：\n",
    "* $\\mathcal{M}_{\\varepsilon}(\\bar{M})=\\left\\{M \\in \\mathcal{M}: f^{\\bar{M}}\\left(\\pi_{\\bar{M}}\\right) + \\varepsilon\\geq f^M\\left(\\pi_M\\right)\\right\\}$\n",
    "\n",
    "つまり，報酬が$\\bar{M} + \\varepsilon$以上にはならないようなモデルの集合です．\n",
    "ここで，次の略記を導入します：\n",
    "$$\n",
    "\\operatorname{dec}_\\gamma(\\mathcal{M})=\\sup _{\\bar{M} \\in \\mathcal{M}} \\operatorname{dec}_\\gamma(\\mathcal{M}, \\bar{M}) \\quad \\text { and } \\quad \\operatorname{dec}_{\\gamma, \\varepsilon}(\\mathcal{M})=\\sup _{\\bar{M} \\in \\mathcal{M}} \\operatorname{dec}_\\gamma\\left(\\mathcal{M}_{\\varepsilon}(\\bar{M}), \\bar{M}\\right)\n",
    "$$\n",
    "\n",
    "そして，\n",
    "$$\n",
    "V(\\mathcal{M})=\\sup _{M, M^{\\prime} \\in \\mathcal{M}} \\sup _{\\pi \\in \\Pi} \\sup _{A \\in \\mathscr{R} \\otimes \\mathscr{O}}\\left\\{\\frac{M(A \\mid \\pi)}{M^{\\prime}(A \\mid \\pi)}\\right\\} \\vee e\n",
    "$$\n",
    "を導入します．これはモデルによって出る報酬と観測の最大の密度比です．例えば１つのモデルでしか見れない報酬や観測がある場合，これは無限大になります．\n",
    "\n",
    "このとき，次が成立します．\n",
    "\n",
    "---\n",
    "\n",
    "$\\mathcal{F}_{\\mathcal{M}} \\subseteq(\\Pi \\rightarrow[0,1])$なるモデルクラス$\\mathcal{M}$について，$C(T):=2^{15} \\log (2 T \\wedge V(\\mathcal{M}))$および$\\underline{\\varepsilon}_\\gamma:=C(T)^{-1} \\frac{\\gamma}{T}$とする．\n",
    "このとき，どんなアルゴリズムでも，\n",
    "$$\n",
    "\\boldsymbol{R e g}_{\\mathrm{DM}} \\geq(6 C(T))^{-1} \\cdot \\max _{\\gamma>\\sqrt{C(T) T}} \\min \\left\\{\\left(\\operatorname{dec}_{\\gamma, \\underline{\\varepsilon}_\\gamma}(\\mathcal{M})-15 \\delta\\right) \\cdot T, \\gamma\\right\\}\n",
    "$$\n",
    "\n",
    "を確率$\\delta /2$以上で成立するようなモデル$M$が$\\mathcal{M}$に存在する．\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
