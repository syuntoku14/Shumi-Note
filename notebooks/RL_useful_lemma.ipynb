{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RLの証明に便利な定理\n",
    "\n",
    "表記は元論文や雰囲気におまかせします．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation Lemma\n",
    "\n",
    "---\n",
    "\n",
    "**補題: Extended Value Difference**\n",
    "\n",
    "参考：\n",
    "* [Exploration-Exploitation in Constrained MDPs](https://arxiv.org/abs/2003.02189)の補題34など\n",
    "\n",
    "表記：\n",
    "* 方策：$\\pi, \\pi'$\n",
    "* MDP：$\\mathcal{M}=(\\mathcal{S}, \\mathcal{A}, \\{p_h\\}_{h=1}^H, \\{r_h\\}_{h=1}^H)$と$\\mathcal{M}'=(\\mathcal{S}, \\mathcal{A}, \\{p_h'\\}_{h=1}^H, \\{r_h'\\}_{h=1}^H)$\n",
    "* $\\widehat{Q}_h^\\pi(s, a; r, p)$を$\\mathcal{M}$でのQ関数の近似\n",
    "* $\\widehat{V}_h^\\pi(s; r, p)=\\left\\langle \\widehat{Q}_h^\\pi(s, \\cdot; r, p), \\pi_h(\\cdot \\mid s)\\right\\rangle$\n",
    "\n",
    "のとき，\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\widehat{V}_h^\\pi(s; r, p)\n",
    "-\n",
    "{V}_h^{\\pi'}(s; r', p')\n",
    "=\n",
    "&\\sum^{H}_{h=1}\\mathbb{E}\\left[\n",
    "\\left\\langle \\widehat{Q}_h^\\pi(s_h, \\cdot; r, p), \\pi_h'(\\cdot \\mid s_h) - \\pi_h(\\cdot \\mid s_h)\\right\\rangle\n",
    "\\mid s_1, \\pi', p'\n",
    "\\right]\n",
    "+ \\\\\n",
    "&\\sum^{H}_{h=1}\\mathbb{E}\\left[\n",
    "\\widehat{Q}_h^\\pi(s_h, a_h; r, p) - r_h'(s_h, a_h) - p_h'(\\cdot \\mid s_h, a_h)\\widehat{V}_{h+1}^\\pi(\\cdot; r, p) \\mid s_1, \\pi', p'\n",
    "\\right]\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Good Set\n",
    "\n",
    "表記\n",
    "* $w_{tj}(s, a)$：エピソード$j$のステップ$t \\in [H]$で$(s, a)$を訪れる確率\n",
    "* $w_j(s, a):= \\sum_{t=1}^H w_{tj}(s, a)$\n",
    "* $n_j(s, a)$：エピソード$j$までに$(s, a)$を訪れる回数\n",
    "\n",
    "直感的には，次の$L_k$は状態行動空間を「十分訪れたことがある集合」と「そんなに訪れたことがない集合」に分割します．\n",
    "$L_k$の中身の状態行動の訪問回数は，そのoccupancy measureで下から抑えることができます．\n",
    "これはリグレットのバウンドに便利です．\n",
    "\n",
    "---\n",
    "\n",
    "**定義: Good Set**\n",
    "\n",
    "参考：\n",
    "* [Tight Regret Bounds for Model-Based Reinforcement Learning with Greedy Policies](https://arxiv.org/abs/1905.11527)のAppendix F.1\n",
    "* [Tighter Problem-Dependent Regret Bounds in Reinforcement Learning without Domain Knowledge using Value Function Bounds](https://arxiv.org/abs/1901.00210)のAppendix G．こっちのほうがわかりやすいかも．\n",
    "\n",
    "次の集合$L_k$を定義します：\n",
    "\n",
    "$$\n",
    "L_k:= \\left\\{\n",
    "(s, a) \\in \\mathcal{S}\\times \\mathcal{A}: \n",
    "\\frac{1}{4}\n",
    "\\sum_{j<k} w_j(s, a) \\geq H \\ln \\frac{SAH}{\\delta'} + H\n",
    "\\right\\}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "**補題: Failure event**\n",
    "\n",
    "参考：\n",
    "* [Policy Certificates: Towards Accountable Reinforcement Learning](https://arxiv.org/abs/1811.03056)のLemma 6\n",
    "\n",
    "次のFailure Eventを考えます．\n",
    "\n",
    "$$\n",
    "F^N = \\left\\{\\exist k, s, a : n_k(s, a) < \\frac{1}{2}\\sum_{i < k} w_i(s, a) - H \\ln \\frac{SAH}{\\delta'}\\right\\}\n",
    "$$\n",
    "\n",
    "このとき，\n",
    "$$\n",
    "\\mathbb{P}\\left(F^N\\right) \\leq S A H \\delta^{\\prime}\n",
    "$$\n",
    "\n",
    "が成り立ちます．\n",
    "\n",
    "**証明**\n",
    "\n",
    "* $s \\in \\mathcal{S}, a \\in \\mathcal{A}, t \\in [H]$を固定します．\n",
    "* $\\mathcal{F}_k$を，$k$エピソード目の初期状態$s_{k, 1}$と，$k-1$エピソードまでから誘導される$\\sigma$代数とします．\n",
    "* $X_k$を，$s, a$がエピソード$k$の$t$ステップ目に訪問される指示関数とします．\n",
    "\n",
    "このとき，$X_k=1$である確率，つまり\n",
    "\n",
    "$$\n",
    "\\mathbb{P}\\left(s=s_{k, t}, a=a_{k, t} \\mid s_{k, 1}, \\pi_k\\right)\n",
    "$$\n",
    "\n",
    "は，$\\mathcal{F}_k$-measurableです．あとは次の補題に$W=\\ln \\frac{SAH}{\\delta'}$を当てはめて，Union boundを取れば成立します．\n",
    "\n",
    "**補題**\n",
    "\n",
    "* $i=1 \\ldots$について，$\\mathcal{F}_i$をフィルトレーションとする\n",
    "* $X_1, \\dots, X_n$をベルヌーイ確率変数とする\n",
    "    * ここで，$\\mathbb{P}\\left(X_i=1 \\mid \\mathcal{F}_{i-1}\\right)=P_i$であり，$P_i$は$\\mathcal{F}_{i-1}$-measurableかつ$X_i$は$\\mathcal{F}_i$-measurableである．\n",
    "  \n",
    "このとき，\n",
    "\n",
    "$$\n",
    "\\mathbb{P}\\left(\\exists n: \\sum_{t=1}^n X_t<\\sum_{t=1}^n P_t / 2-W\\right) \\leq e^{-W}\n",
    "$$\n",
    "\n",
    "が成り立つ．\n",
    "\n",
    "証明は[Unifying PAC and Regret: Uniform PAC Bounds for Episodic Reinforcement Learning](https://arxiv.org/abs/1703.07710)のLemma F.4参照．\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "**補題: Visitation Ratio**\n",
    "\n",
    "参考：\n",
    "* [Tighter Problem-Dependent Regret Bounds in Reinforcement Learning without Domain Knowledge using Value Function Bounds](https://arxiv.org/abs/1901.00210)のLemma 6\n",
    "\n",
    "$(F^N)^c$が成り立っているとき，$(s, a) \\in L_k$については，\n",
    "\n",
    "$$\n",
    "n_k(s, a) \\geq \\frac{1}{4} \\sum_{j \\leq k} w_j(s, a)\n",
    "$$\n",
    "\n",
    "が成り立つ．\n",
    "\n",
    "**証明**\n",
    "\n",
    "$(F^N)^c$が成り立っているので，次が成立します．\n",
    "$$\n",
    "\\begin{aligned}\n",
    "n_k(s, a) \\geq \\frac{1}{2} \\sum_{j<k} w_j(s, a)-H \\ln \\frac{S A H}{\\delta^{\\prime}}\n",
    "&=\\frac{1}{4} \\sum_{j<k} w_j(s, a)+\\frac{1}{4} \\sum_{j<k} w_j(s, a)-H \\ln \\frac{S A H}{\\delta^{\\prime}} \\\\\n",
    "&\\geq \\frac{1}{4} \\sum_{j<k} w_j(s, a)+H \\\\\n",
    "&\\geq \\frac{1}{4} \\sum_{j<k} w_j(s, a)+w_k(s, a) \\\\\n",
    "&\\geq \\frac{1}{4} \\sum_{j \\leq k} w_j(s, a)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "ここで2つ目の不等式は$(s, a) \\in L_k$を使ってます．\n",
    "\n",
    "---\n",
    "\n",
    "次の補題は，$(s, a) \\notin L_k$であれば，リグレットにはほぼ寄与しないことを示しています．\n",
    "\n",
    "**補題（Minimal Contribution）**\n",
    "\n",
    "参考：\n",
    "* [Tighter Problem-Dependent Regret Bounds in Reinforcement Learning without Domain Knowledge using Value Function Bounds](https://arxiv.org/abs/1901.00210)のLemma 7\n",
    "\n",
    "次が成立します．\n",
    "\n",
    "$$\n",
    "\\sum_{k=1}^K \\sum_{t=1}^H \\sum_{(s, a) \\notin L_k} w_{t k}(s, a) \\leq \\tilde{\\mathcal{O}}(SAH)\n",
    "$$\n",
    "\n",
    "**証明**\n",
    "\n",
    "定義より，$(s, a) \\notin L_k$であれば，\n",
    "\n",
    "$$\n",
    "\\frac{1}{4} \\sum_{j \\leq k} w_j(s, a)<H \\ln \\frac{S A H}{\\delta^{\\prime}}+H\n",
    "$$\n",
    "\n",
    "が成立します．よって，\n",
    "\n",
    "$$\n",
    "\\sum_{k=1}^K \\sum_{t=1}^H \\sum_{(s, a) \\notin L_k} w_{t k}(s, a)=\\sum_{s, a} \\sum_{k=1}^K w_k(s, a) 1\\left\\{(s, a) \\notin L_k\\right\\} \\leq \\sum_{s, a}\\left(4 H \\ln \\frac{S A H}{\\delta^{\\prime}}+4 H\\right) \\leq \\tilde{\\mathcal{O}}(SAH)\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "**補題（Visitation Ratio）**\n",
    "\n",
    "\n",
    "参考：\n",
    "* [Tighter Problem-Dependent Regret Bounds in Reinforcement Learning without Domain Knowledge using Value Function Bounds](https://arxiv.org/abs/1901.00210)のLemma 13\n",
    "\n",
    "$(F^N)^c$が成り立っているとき，次が成立します：\n",
    "\n",
    "$$\n",
    "{\\sum_{k=1}^K \\sum_{t=1}^H \\sum_{(s, a) \\in L_k} \\frac{w_{t k}(s, a)}{n_k(s, a)}} \\leq \\tilde{\\mathcal{O}}(\\sqrt{S A })\n",
    "$$\n",
    "\n",
    "証明は省略\n",
    "\n",
    "---\n",
    "\n",
    "**補題**\n",
    "\n",
    "参考\n",
    "* [Tight Regret Bounds for Model-Based Reinforcement Learning with Greedy Policies](https://arxiv.org/abs/1905.11527)のLemma 38\n",
    "* [Exploration Exploitation in Constrained MDPs](https://arxiv.org/abs/2003.02189)のLemma 36では$H$が$H^2$になってる．なぜ？\n",
    "\n",
    "$(F^N)^c$が成り立っているとき，次が成立します：\n",
    "\n",
    "$$\n",
    "\\sum_{k=1}^K \\sum_{t=1}^H \\mathbb{E}\\left[\\sqrt{\\frac{1}{n_{k-1}\\left(s_t^k, \\pi_k\\left(s_t^k\\right)\\right) \\vee 1}} \\mid \\mathcal{F}_{k-1}\\right] \\leq \\tilde{\\mathcal{O}}(\\sqrt{S A KH}+S A H)\n",
    "$$\n",
    "\n",
    "**証明**\n",
    "\n",
    "次が成立します．\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "& \\sum_{k=1}^K \\sum_{t=1}^H \\mathbb{E}\\left[\\sqrt{\\frac{1}{n_{k-1}\\left(s_t^k, \\pi_k\\left(s_t^k\\right)\\right) \\vee 1}} \\mid \\mathcal{F}_{k-1}\\right] \\\\\n",
    "& =\\sum_{k=1}^K \\sum_{t=1}^H \\sum_{s, a} w_{t k}(s, a) \\sqrt{\\frac{1}{n_{k-1}(s, a) \\vee 1}} \\\\\n",
    "& \\leq \\sum_{k=1}^K \\sum_{t=1}^H \\sum_{s, a \\in L_k} w_{t k}(s, a) \\sqrt{\\frac{1}{n_{k-1}(s, a)}}+\\sum_{k=1}^K \\sum_{t=1}^H \\sum_{s, a \\notin \\in L_k} w_{t k}(s, a) \\\\\n",
    "& \\leq \\sum_{k=1}^K \\sum_{t=1}^H \\sum_{s, a \\in L_k} w_{t k}(s, a) \\sqrt{\\frac{1}{n_{k-1}(s, a)}}+S A H .\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "また，\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "& \\sum_{k=1}^K \\sum_{t=1}^H \\sum_{s, a \\in L_k} w_{t k}(s, a) \\sqrt{\\frac{1}{n_{k-1}(s, a)}} \\\\\n",
    "& \\leq \\sqrt{\\sum_{k=1}^K \\sum_{t=1}^H \\sum_{s, a \\in L_k} w_{t k}(s, a)} \\sqrt{\\sum_{k=1}^K \\sum_{t=1}^H \\sum_{s, a \\in L_k} \\frac{w_{t k}(s, a)}{n_{k-1}(s, a)}} \\\\\n",
    "& \\leq \\sqrt{\\sum_{k=1}^K \\sum_{t=1}^H \\sum_{s, a} w_{t k}(s, a)} \\sqrt{\\sum_{k=1}^K \\sum_{t=1}^H \\sum_{s, a \\in L_k} \\frac{w_{t k}(s, a)}{n_{k-1}(s, a)}} \\\\\n",
    "& =\\sqrt{KH} \\sqrt{\\sum_{k=1}^K \\sum_{t=1}^H \\sum_{s, a} \\frac{w_{t k}(s, a)}{n_{k-1}(s, a)}} \\lesssim \\tilde{\\mathcal{O}}(\\sqrt{S A KH}) .\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "が成立します．ここで，$\\sum_{t=1}^H \\sum_{s, a} w_{t k}(s, a)=H$を使いました．\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regret Bound\n",
    "\n",
    "---\n",
    "\n",
    "**補題：On Policy Errors for Optimistic Model**\n",
    "\n",
    "参考：\n",
    "* [Exploration-Exploitation in Constrained MDPs](https://arxiv.org/abs/2003.02189)の補題29\n",
    "\n",
    "次が成立するとします：\n",
    "\n",
    "$$\n",
    "\\left|\\widetilde{p}_h^k\\left(s^{\\prime} \\mid s, a\\right)-p_h\\left(s^{\\prime} \\mid s, a\\right)\\right| \\lesssim \\sqrt{\\frac{p_h\\left(s^{\\prime} \\mid s, a\\right)}{n_h^{k-1}(s, a) \\vee 1}}+\\frac{1}{n_h^{k-1}(s, a) \\vee 1} .\n",
    "$$\n",
    "\n",
    "および\n",
    "\n",
    "$$\n",
    "n_h^{k-1}(s, a) \\leq \\frac{1}{2} \\sum_{j<k} q_h^{\\pi_k}(s, a \\mid p)-H \\ln \\frac{S A H}{\\delta^{\\prime}}\n",
    "$$\n",
    "\n",
    "また，$\\pi_k$を$k$エピソード目の方策とします．このとき，任意の$K'\\in [K]$について，\n",
    "\n",
    "$$\n",
    "\\sum_{k=1}^{K^{\\prime}}\\left|V_1^{\\pi_k}\\left(s_1 ; l, p\\right)-V_1^{\\pi_k}\\left(s_1 ; \\widetilde{l}_k, \\widetilde{p}_k\\right)\\right| \\leq \\widetilde{\\mathcal{O}}\\left(\\sqrt{S \\mathcal{N} H^4 K}+(\\sqrt{\\mathcal{N}}+H) H^2 S A\\right)\n",
    "$$\n",
    "\n",
    "が成立します．ここで，$\\mathcal{N}:=\\max _{s, a, h}\\left|\\left\\{s^{\\prime}: p_h\\left(s^{\\prime} \\mid s, a\\right)>0\\right\\}\\right|$は次状態への遷移確率が非ゼロになる最大個数です．\n",
    "\n",
    "**証明**\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "& \\sum_{k=1}^{K^{\\prime}}\\left|V_1^{\\pi_k}\\left(s_1 ; p\\right)-V_1^{\\pi_k}\\left(s_1 ; \\widetilde{p}_k\\right)\\right| \\\\\n",
    "& =\\sum_{k=1}^{K^{\\prime}}\\left|\\mathbb{E}\\left[\\sum_{h=1}^H\\left(p_h-\\widetilde{p}_h^k\\right)\\left(\\cdot \\mid s_h, a_h\\right) {V}_{h+1}^{\\pi_k}(\\cdot; \\widetilde{p}_k) \\mid s_1, p, \\pi_k\\right]\\right| \\\\\n",
    "&\\leq \\underbrace{\\sum_{k=1}^{K^{\\prime}} \\mathbb{E}\\left[\\sum_{h=1}^H \\sum_{s^{\\prime}}\\left|\\left(p_h-\\widetilde{p}_h^k\\right)\\left(s^{\\prime} \\mid s_h, a_h\\right)\\right|\\left|{V}_{h+1}^{\\pi_k}\\left(s^{\\prime} ; \\widetilde{p}_k\\right)\\right| \\mid s_1, p, \\pi_k\\right]}_{(i)}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "最後の(i)をバウンドしましょう．\n",
    "$V^\\pi$の部分は$H$以下なので外に出し，仮定を代入すると，\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "(i) & \\lesssim H \\sum_{k=1}^{K^{\\prime}} \\sum_{h=1}^H \\mathbb{E}\\left[\\sqrt{\\frac{1}{n_h^k\\left(s_h, a_h\\right) \\vee 1}} \\sum_{s^{\\prime}} \\sqrt{p_h\\left(s^{\\prime} \\mid s_h, a_h\\right)}+\\frac{S}{n_h^k\\left(s_h, a_h\\right) \\vee 1} \\mid s_1, p, \\pi_k\\right] \\\\\n",
    "& \\leq H \\sum_{k=1}^{K^{\\prime}} \\sum_{h=1}^H \\mathbb{E}\\left[\\sqrt{\\frac{1}{n_h^k\\left(s_h, a_h\\right) \\vee 1}} \\sqrt{\\mathcal{N}}\\sqrt{\\sum_{s^{\\prime}} p_h\\left(s^{\\prime} \\mid s_h, a_h\\right)}+\\frac{S}{n_h^k\\left(s_h, a_h\\right) \\vee 1} \\mid s_1, p, \\pi_k\\right] \\\\\n",
    "& =H \\sum_{k=1}^{K^{\\prime}} \\sum_{h=1}^H \\mathbb{E}\\left[\\sqrt{\\frac{1}{n_h^k\\left(s_h, a_h\\right) \\vee 1}} \\sqrt{\\mathcal{N}}+\\frac{S}{n_h^k\\left(s_h, a_h\\right) \\vee 1} \\mid s_1, p, \\pi_k\\right] \\\\\n",
    "& =H \\sum_{k=1}^{K^{\\prime}} \\sum_{h=1}^H \\mathbb{E}\\left[\\sqrt{\\frac{1}{n_h^k\\left(s_h^k, a_h^k\\right) \\vee 1}} \\sqrt{\\mathcal{N}}+\\frac{S}{n_h^k\\left(s_h^k, a_h^k\\right) \\vee 1} \\mid \\mathcal{F}_{k-1}\\right] \\\\\n",
    "& \\lesssim \\sqrt{S \\mathcal{N} H^4 K}+\\sqrt{\\mathcal{N}} H^2 S A+S H^3 A \\leq \\widetilde{\\mathcal{O}}\\left(\\sqrt{S \\mathcal{N} H^4 K}+(\\sqrt{\\mathcal{N}}+H) H^2 S A\\right) .\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "* １行目は$p$についての仮定を代入してます．\n",
    "* ２行目はJensenの不等式です．\n",
    "* ５行目はGood setの節でやった補題を使っています．\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
