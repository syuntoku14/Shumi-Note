{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 統計的学習理論\n",
    "\n",
    "参考：\n",
    "* [統計的学習理論 (機械学習プロフェッショナルシリーズ)](https://amzn.asia/d/5OudVVi)\n",
    "* [Foundations of Machine Learning](https://cs.nyu.edu/~mohri/mlbook/)\n",
    "\n",
    "入力空間から出力空間への関数のことを仮説と呼びます．\n",
    "統計的学習理論はアルゴリズムが吐き出す仮説の**汎化性能**を評価する理論です．\n",
    "汎化の能力の評価では大きく２つの要素を考えます：\n",
    "1. どんなモデル（関数集合）を規定するか？\n",
    "2. どんな問題（損失関数）を期待するか？\n",
    "\n",
    "つまり，関数集合と損失関数に応じて汎化の理論を構築していくわけですね．\n",
    "\n",
    "## 用語\n",
    "\n",
    "汎化の具体的な理論を与える前に，いくつか用語を定義しておきます．\n",
    "\n",
    "* 仮説$h$の予測損失：$R(h)=\\mathbb{E}_{(X, Y)\\sim D}[\\ell(h(X), Y)]$\n",
    "    * 他にも「Generalization error」，「risk」，「true error」など様々な呼び方があります．\n",
    "* 仮説$h$の経験損失：$\\hat{R}(h)=\\frac{1}{n}\\sum_{i=1}^n\\ell(h(X_i), Y_i)=\\mathbb{E}_{(X, Y)\\sim \\hat{D}}[\\ell(h(X), Y)]$\n",
    "    * ここで，確率$1/n$で$(X_i, Y_i)$に値を取る確率変数を$(X, Y)$とし，その分布を$\\hat{D}$としました．\n",
    "\n",
    "各データ$(X_i, Y_i)$が同一の分布$D$に従うとき、経験損失の期待値は予測損失に一致します。実際、$n$個の観測データの同時分布を$D^n$とすると、期待値の線型性から\n",
    "\n",
    "$$\\mathbb{E}_{D^n}[\\hat{R}(h)]=\\frac{1}{n}\\sum_{i=1}^n\\mathbb{E}_{D^n}\\left[\\ell(h(X_i), Y_i)\\right] = R(h)$$\n",
    "\n",
    "が成り立ちます。また、観測データが独立に同一の分布$D$に従うなら、大数の弱法則から\n",
    "\n",
    "$$\\lim_{n\\to\\infty} \\operatorname{Pr}_{D^n}(|\\hat{R}(h) - R(h)| > \\varepsilon) = 0$$\n",
    "\n",
    "が成り立ちます。\n",
    "\n",
    "---\n",
    "\n",
    "**大数の弱法則**\n",
    "\n",
    "$X_1, \\dots, X_n$を期待値$\\mu$，有限の分散のi.i.d.な確率変数とします．このとき，\n",
    "\n",
    "$$\n",
    "\\lim _{n \\rightarrow \\infty} \\operatorname{Pr}\\left(\\left|\\frac{1}{n}\\sum_{i=1}^n X_i - \\mu\\right| \\geq \\varepsilon\\right)=0 \\quad \\text { for all } \\varepsilon>0\n",
    "$$\n",
    "\n",
    "が成立します（つまり経験平均が期待値$\\mu$に確率収束してます）．\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**ベイズ規則とベイズ誤差**\n",
    "\n",
    "損失関数$\\ell$を定めたとき、任意の可測関数$h: \\mathcal{X} \\to \\mathcal{Y}$のもとでの予測損失の下限\n",
    "\n",
    "$$\\inf_{h:\\text{可測}} R(h)$$\n",
    "\n",
    "を$\\ell$のもとでの**ベイズ誤差**といいます。この下限を達成する仮説が存在する場合、その仮説を **ベイズ規則（ベイズルール）** といいます。\n",
    "さきほどの予測損失を振り返ると、タワールールより\n",
    "\n",
    "$$R(h)=\\mathbb{E}_{(X, Y)\\sim D}[\\ell(h(X), Y)]=\\mathbb{E}_{X}[\\mathbb{E}_Y[\\ell(h(X), Y)|X]]$$\n",
    "が成り立ちます。よって、各入力$X=x$における条件付き期待値\n",
    "\n",
    "$$\\mathbb{E}_Y[\\ell(h(x), Y)|x]=\\int_\\mathcal{Y} \\ell(h(x), y)dP(y|x)$$\n",
    "\n",
    "を最小にする仮説$h$を選ぶと、予測誤差が最小になります。\n",
    "\n",
    "---\n",
    "\n",
    "**例（回帰問題）**\n",
    "\n",
    "例えば損失関数が$\\ell(\\hat{y}, y)=(\\hat{y}-y)^2$であるような回帰問題を考えましょう．\n",
    "このとき，次が成立することに注意しましょう．\n",
    "$$\n",
    "\\mathbb{E}_Y[\\ell(h, Y)] = (h - \\mathbb{E}[Y])^2 + V[Y]\n",
    "$$\n",
    "また，上の話から，ベイズ規則は$h(x) = \\mathbb{E}[Y|x]$によって与えられます。\n",
    "よって、ベイズ誤差は\n",
    "\n",
    "$$\n",
    "R(h) \n",
    "= \\mathbb{E}_X\\left[\\int(y - \\mathbb{E}[Y|X])^2dP(y|X)\\right]\n",
    "= \\mathbb{E}_X[V[Y|X]] \n",
    "$$\n",
    "\n",
    "で表現されます．"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## アルゴリズムの汎化性能\n",
    "\n",
    "データ$S=\\{(X_1, Y_1), \\dots, (X_n, Y_n)\\}$を使ってアルゴリズムが吐き出す仮説を$h_S$としましょう．\n",
    "また，ベイズ誤差を$R^*=\\inf_h R(h)$と省略します．\n",
    "\n",
    "アルゴリズム（仮説$h_S$）の汎化性能の解析では，主に次のような確率不等式を評価します．\n",
    "$$\\operatorname{Pr}_{S\\sim D^n} (R(h_S) - R^* \\geq \\varepsilon) \\leq \\delta$$\n",
    "これを達成する仮説$h_S$はテスト時に$\\varepsilon$以上の期待ミスをする確率が$\\delta$以下になります．\n",
    "さらにこれはマルコフの不等式から以下のように期待値で抑えることもできます．\n",
    "\n",
    "$$\n",
    "\\operatorname{Pr}_{S\\sim D^n} (R(h_S) - R^* \\geq \\varepsilon) \\leq \\frac{\\mathbb{E}_{S\\sim D^n}[R(h_S)] - R^*}{\\varepsilon}\n",
    "$$\n",
    "<!-- このとき，観測データ$S$の分布$D^n$に関する期待予測損失は $\\mathbb{E}_{S\\sim D^n}[R(h_S)]$ となります． -->\n",
    "\n",
    "ベイズ誤差に近い予測損失を達成する仮説を求められるアルゴリズムは、**統計的一致性**をもつといいます．\n",
    "\n",
    "---\n",
    "\n",
    "**統計的一致性**\n",
    "\n",
    "任意の分布$D$と任意の$\\varepsilon > 0$について、\n",
    "\n",
    "$$\n",
    "\\lim_{n\\to \\infty} \\operatorname{Pr}_{S\\sim D^n} (R(h_S) \\leq R^* + \\varepsilon) = 0\n",
    "$$\n",
    "\n",
    "が成り立つとき、学習アルゴリズム$S\\mapsto h_S$は統計的一致性を持つといいます。\n",
    "（つまり，$n$が大きくなると出力の仮説の経験リスクがベイズ誤差に確率収束します．）\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 有限な仮説集合と汎化誤差\n",
    "\n",
    "まずは有限な仮説集合についての汎化誤差の確率不等式を導出してみましょう．\n",
    "\n",
    "---\n",
    "\n",
    "**準備**\n",
    "\n",
    "有限な仮説集合$\\mathcal{H}=\\{h_1, \\cdots, h_T\\}$における二値判別問題を考えてみます。\n",
    "各仮説は入力空間$\\mathcal{X}$から二値ラベル$\\{+1, -1\\}$への関数です。また、データ$S$に対する学習アルゴリズムの出力を，その経験誤差を最小にする仮説として，\n",
    "\n",
    "$$h_S = \\arg \\min_{h\\in \\mathcal{H}} \\hat{R}(h)$$\n",
    "\n",
    "とします。ベイズ規則は$h_0$としましょう．ただし，$h_0$が$\\mathcal{H}$に含まれるとは限りません。\n",
    "さらに、$\\mathcal{H}$の中で予測判別誤差を最小にする仮説を$h_\\mathcal{H}$とします。\n",
    "\n",
    "---\n",
    "\n",
    "さて，上で見たように，次の確率不等式を考えたいわけです．\n",
    "$$\\operatorname{Pr}_{S\\sim D^n} (R(h_S) - R^* \\geq \\varepsilon) \\leq \\delta$$\n",
    "しかし，$R(h_S) - R^* \\geq \\varepsilon$の確率を求めるのは結構難しそうです．\n",
    "そこで，単純に$R(h_S) - R^*$を評価するのではなく，それを評価しやすい量に分解して考えていきます．\n",
    "\n",
    "まず、定義から\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&R(h_0) \\leq R(h_\\mathcal{H}) \\leq R(h_S)\\\\\n",
    "&\\hat{R}(h_S) \\leq R(h_\\mathcal{H})\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "が成り立ちます。これを使って、ベイズ規則との予測判別誤差の差を次のように分解しましょう：\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "R(h_S) - R(h_0) &= \n",
    "R(h_S) - \\hat{R}(h_S)  + \\hat{R}(h_S) - \n",
    "R(h_\\mathcal{H}) + R(h_\\mathcal{H}) - R(h_0) \\\\\n",
    "&\\leq \n",
    "\\underbrace{R(h_S) - \\hat{R}(h_S)}_{(a)}  + \n",
    "\\underbrace{\\hat{R}(h_\\mathcal{H}) - R(h_\\mathcal{H})}_{(b)} \n",
    "+ \\underbrace{R(h_\\mathcal{H}) - R(h_0)}_{(c)} \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "* この(b)は$h_\\mathcal{H}$が固定なので，簡単に解析できます．実際，大数の弱法則では$\\to 0$ですし，中心極限定理を使えば$O(1/\\sqrt{n})$のオーダーで収束することがすぐにわかります．\n",
    "* (c)はベイズ規則と仮説集合限界の性能の差です．この量は **近似誤差(bias)** と呼ばれ，次で定義されます：$\\operatorname{bias}_\\mathcal{H}=R(h_\\mathcal{H}) - R(h_0)$\n",
    "* (a)はそのままでは評価しづらそうです．実際，$h_S$が訓練データに依存するため，$\\hat{R}(h_S)$は独立な$n$個の損失関数の和の評価ではありません．そこで，次のような分解を考えてみましょう．\n",
    "\n",
    "$$\n",
    "(a) = R(h_S) - \\hat{R}(h_S)\n",
    "\\leq \n",
    "\\max_{h\\in \\mathcal{H}} |\\hat{R}(h) - R(h)| \n",
    "$$\n",
    "\n",
    "これは(b)とまとめて良さそうです．つまり，\n",
    "\n",
    "$$\n",
    "(a) + (b) \\leq \n",
    "2\\max_{h\\in \\mathcal{H}} |\\hat{R}(h) - R(h)| \n",
    "$$\n",
    "として問題ありません．\n",
    "この量はHoeffdingの不等式（教科書参照）とUnion Boundによって抑えることができます．\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\operatorname{Pr}\\left(2\\max_{h\\in \\mathcal{H}}|\\hat{R}(h) - R(h)| \\geq \\varepsilon \\right)\n",
    "&\\leq \\sum_{h\\in \\mathcal{H}} \\operatorname{Pr}\\left(2|\\hat{R}(h) - R(h)| \\geq \\varepsilon \\right)\\\\\n",
    "&\\leq \\sum_{h\\in \\mathcal{H}} 2\\exp(-2n(\\varepsilon / 2)^2)\\\\\n",
    "&= 2 |\\mathcal{H}|\\exp(-2n(\\varepsilon / 2)^2)\n",
    "\\end{aligned}\n",
    "$$\n",
    "が成り立ちます。\n",
    "変形すると、確率$1-\\delta$以上で\n",
    "\n",
    "$$\n",
    "2 |\\mathcal{H}|\\exp(-2n(\\varepsilon / 2)^2) \\leq \\sqrt{\\frac{2}{n}\\log{\\frac{2|\\mathcal{H}|}{\\delta}}}\n",
    "$$\n",
    "\n",
    "が成り立ちます。\n",
    "よって、汎化性能は確率$1 - \\delta$以上で\n",
    "\n",
    "$$\n",
    "R(h_S) - R(h_0) \\leq \\sqrt{\\frac{2}{n}\\log{\\frac{2|\\mathcal{H}|}{\\delta}}}+  R(h_\\mathcal{H}) - R(h_0) \n",
    "$$\n",
    "\n",
    "で抑えることができます．もう少し踏み込んで，確率オーダーを導入して評価してみましょう．\n",
    "\n",
    "---\n",
    "\n",
    "**確率オーダー**\n",
    "\n",
    "確率変数列$\\{Z_n\\}_{n\\in \\mathbb{N}}$の確率オーダーが$\\mathcal{O}_P(r_n)$であるとは、\n",
    "\n",
    "$$\n",
    "\\lim_{z\\to \\infty} \\lim \\sup_{n\\to \\infty} \\operatorname{Pr}(|Z_n|/r_n > z) = 0\n",
    "$$\n",
    "\n",
    "であることを意味します。\n",
    "\n",
    "---\n",
    "\n",
    "これを使うと，特に$h_0 \\in \\mathcal{H}$なら、\n",
    "\n",
    "$$\n",
    "R(h_S) = R(h_0) + \\mathcal{O}_P\\left(\\sqrt{\\frac{\\log{|\\mathcal{H}|}}{n}}\\right)\n",
    "$$\n",
    "\n",
    "と評価できます．\n",
    "この２項目は **推定誤差(variance)** と呼ばれ，今回の場合は$\\operatorname{var}_\\mathcal{H}=\\sqrt{\\frac{2}{n}\\log{\\frac{2|\\mathcal{H}|}{\\delta}}}$で与えられます．\n",
    "biasとvarianceを使うと，\n",
    "\n",
    "$$\n",
    "R(h_S) - R(h_0) \\leq \\operatorname{bias}_{\\mathcal{H}} + \\operatorname{var}_{\\mathcal{H}}\n",
    "$$\n",
    "が成立します．定義からbiasとvarianceにはトレードオフがあります．\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 実現可能であるとき\n",
    "\n",
    "上でHoeffdingを使った例ではベイズ規則$h_0$が$\\mathcal{H}$に含まれていませんでした．\n",
    "今回は次の仮定のもとでの学習について考えてみます：\n",
    "\n",
    "* **実現可能性**：$R(h^*)=0$となる仮説$h^*\\in \\mathcal{H}$が存在する\n",
    "\n",
    "今回は損失が常に非負なので，${R}(h)=0$を満たすような任意の$h$について，$\\hat{R}(h)=0$が成り立ちます．\n",
    "よって$\\hat{R}(h^*)=0$です．\n",
    "また，アルゴリズムは経験誤差を最小にする仮説を返すので，$\\hat{R}(h_S)=0$も成立します．\n",
    "\n",
    "目的をあらためて確認しましょう．\n",
    "$$\n",
    "\\mathbb{P}[R(h_S) - R(h_0) \\leq \\epsilon] > 1-\\delta\n",
    "$$\n",
    "を示していきたいわけですね．特に今回は$R(h_0)=0$なので，\n",
    "$$\n",
    "\\mathbb{P}[R(h_S) \\leq \\epsilon] > 1-\\delta\n",
    "$$\n",
    "です．これを抑えるのはちょっと大変なので，$R(h)=0$が満たされるような任意の$h$に対して\n",
    "$\\mathbb{P}[R(h) \\leq \\epsilon] > 1-\\delta$を示していきます．\n",
    "\n",
    "---\n",
    "\n",
    "**$\\mathbb{P}[R(h) \\leq \\epsilon]$を変形しよう** \n",
    "\n",
    "まず，$\\mathcal{H}_{>\\epsilon}=\\{h \\in \\mathcal{H}: R(h)>\\epsilon\\}$とおきます．\n",
    "すると上の目標は$\\mathbb{P}[R({h})>\\epsilon]=\\mathbb{P}\\left[{h} \\in \\mathcal{H}_{>\\epsilon}\\right]$と同じです．\n",
    "\n",
    "---\n",
    "\n",
    "**$\\mathbb{P}[h \\in \\mathcal{H}_{>\\epsilon}]$を上から抑えよう** \n",
    "\n",
    "続いて，適当な仮説$h$について，$R(h)=\\mathbb{E}_{(x, y)\\sim\\mathcal{D}}[1(y\\neq h(x))]=\\mathbb{P}_{(x, y)\\sim\\mathcal{D}}[y\\neq h(x)]$なので，$h$のリスクは仮説$h$について$y\\neq h(x)$となる確率と同じです．\n",
    "よって，リスクが$\\epsilon$以上になるような仮説とは，$1-\\mathbb{P}[y \\neq h(x)] \\leq 1-\\epsilon$を満たします．\n",
    "これを使うと，$\\hat{R}(h)=0$を満たすような任意の$h$に対して，\n",
    "$$\\mathbb{P}\\left[{h} \\in \\mathcal{H}_{>\\epsilon}\\right] \\leq \\mathbb{P}\\left[\\exists h \\in \\mathcal{H}_{>\\epsilon}: \\hat{R}(h)=0\\right]$$\n",
    "で抑えられます．\n",
    "\n",
    "---\n",
    "\n",
    "**$\\mathbb{P}\\left[\\exists h \\in \\mathcal{H}_{>\\epsilon}: \\hat{R}(h)=0\\right]$について考えよう**\n",
    "\n",
    "$R(h) >\\epsilon$を満たすような$h$については，\n",
    "\n",
    "$$\n",
    "\\mathbb{P}[\\hat{R}(h)=0] = (\\mathbb{P}[y=h(x)])^nca\\leq (1-\\epsilon)^n \\leq \\exp(-\\epsilon n)\n",
    "$$\n",
    "\n",
    "が成立します．\n",
    "よって，$\\hat{R}(h)=0$を満たすような任意の$h$に対して，\n",
    "\n",
    "$$\\mathbb{P}\\left[{h} \\in \\mathcal{H}_{>\\epsilon}\\right] \\leq \\mathbb{P}\\left[\\exists h \\in \\mathcal{H}_{>\\epsilon}: \\hat{R}(h)=0\\right]\\leq |\\mathcal{H}|\\exp(-\\epsilon n)$$\n",
    "\n",
    "が成立します．\n",
    "\n",
    "---\n",
    "\n",
    "以上から，\n",
    "$$\n",
    "\\mathbb{P}\\left[R(h_S) \\leq \\frac{1}{n}(\\log|\\mathcal{H}| + \\log (1 / \\delta))\\right] > 1 - \\delta\n",
    "$$\n",
    "が成立します．\n",
    "\n",
    "実現可能性がある場合は$1 / \\sqrt{n}$のオーダーが$1/n$になっていることに注意しましょう．実現可能性のもとでは$h^*$の候補として$\\hat{R}(h)=0$になるような$h$に着目すればよいですが，ない場合は$R(h^*)$がわからないので，分布の裾に関する情報を集めるしかなく，結果として必要なデータ数が増加すると考えられます．"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
