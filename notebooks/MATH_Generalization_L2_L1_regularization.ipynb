{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 仮説集合と正則化\n",
    "\n",
    "トレードオフを調整するためには適切な仮説集合を獲得する必要があります。\n",
    "適切な仮説集合を学習するための枠組みとして、正則化があります。\n",
    "\n",
    "正則化では「大きな仮説集合から仮説を選ぶこと」に対してペナルティを課します。\n",
    "複数の仮説集合$\\mathcal{H}_1 \\subset \\cdots \\subset \\mathcal{H}_M$を用いて学習を行うとします。\n",
    "仮説$h$に対するペナルティを$\\Phi: \\mathcal{H}_M \\to \\mathbb{R}_{\\geq 0}$として、$m_1 < m_2$に対して、\n",
    "\n",
    "$$h \\in \\mathcal{H}_{m_2},\\; h' \\in \\mathcal{H}_{m_2} \\setminus \\mathcal{H}_{m_1} \\Rightarrow\\Phi(h) \\leq \\Phi(h')$$\n",
    "\n",
    "を満たすような関数$\\Phi$を考えると、大きな仮説集合に含まれる仮説に大きなペナルティが課されることになります。具体的な例としては、$\\mathcal{H}_0$を空集合として、\n",
    "\n",
    "$$\\Phi(h) = \\sum^M_{m=1} w_m \\cdot {\\bf 1} [h\\in \\mathcal{H}_m \\setminus \\mathcal{H}_{m-1}]$$\n",
    "\n",
    "ここでさらに$0 < w_1, < w_2, \\cdots$とすれば、大きな仮説集合に入った$h$には大きなペナルティが課されます。\n",
    "これを使って、次のように仮説を学習することを考えます。\n",
    "\n",
    "\n",
    "$$\n",
    "\\min_{h\\in \\mathcal{H}_M} \\hat{R}(h) + \\lambda \\cdot \\Phi (h)\n",
    "$$\n",
    "\n",
    "こうすると、経験判別誤差が同じ仮説が複数ある場合、最も小さい仮説集合に入る仮説が選択されます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 正則化線形モデルの複雑度\n",
    "\n",
    "\n",
    "## L2ノルム正則化線形モデルの複雑度\n",
    "\n",
    "* $\\mathbb{E}_{(x, y) \\sim \\mathcal{D}}\\left[\\|x\\|_2^2\\right]=C_2^2$とする．つまりこれはデータの入出力に関する二乗ノルムの平均値．\n",
    "* $\\mathcal{X}$上の関数を$h_w(x)=\\langle w, x\\rangle$とする．\n",
    "\n",
    "このとき，L2ノルムによって制限された仮説空間\n",
    "\n",
    "$$\n",
    "\\mathcal{H}_2=\\left\\{h_w:\\|w\\|_2 \\leq B_2\\right\\}=\\left\\{x \\mapsto\\langle w, x\\rangle:\\|w\\|_2 \\leq B_2\\right\\}\n",
    "$$\n",
    "\n",
    "のラデマッハ複雑度は\n",
    "\n",
    "$$\n",
    "R_n\\left(\\mathcal{H}_2\\right) \\leq \\frac{B_2 C_2}{\\sqrt{n}}\n",
    "$$\n",
    "で抑えられます．\n",
    "\n",
    "**証明**\n",
    "$$\n",
    "\\begin{aligned}\n",
    "R_n\\left(\\mathcal{H}_2\\right) & =\\mathbb{E}\\left[\\sup _{w:\\|w\\|_2 \\leq B_2} \\frac{1}{n} \\sum_{i=1}^n \\sigma_i\\left\\langle w, x_i\\right\\rangle\\right] \\\\\n",
    "& =\\frac{1}{n} \\mathbb{E}\\left[\\sup _{w:\\|w\\|_2 \\leq B_2}\\left\\langle w, \\sum_{i=1}^n \\sigma_i x_i\\right\\rangle\\right] \\\\\n",
    "& \\leq \\frac{1}{n} \\mathbb{E}\\left[\\sup _{w:\\|w\\|_2 \\leq B_2}\\|w\\|_2\\left\\|\\sum_{i=1}^n \\sigma_i x_i\\right\\|_2\\right]\\\\\n",
    "&\\leq \\frac{B_2}{n} \\mathbb{E}\\left[\\sqrt{\\left\\|\\sum_{i=1}^n \\sigma_i x_i\\right\\|_2^2}\\right] \\leq \\frac{B_2}{n} \\sqrt{\\mathbb{E}\\left[\\left\\|\\sum_{i=1}^n \\sigma_i x_i\\right\\|_2^2\\right]}\n",
    "\\end{aligned}\n",
    "$$\n",
    "最初の不等式はコーシー・シュワルツ，最後の部分はJensenです．\n",
    "\n",
    "これはさらに\n",
    "$$\n",
    "\\begin{aligned}\n",
    "& =\\frac{B_2}{n} \\sqrt{\\mathbb{E}\\left[\\sum_{i=1}^n \\sigma_i^2\\left\\|x_i\\right\\|_2^2\\right]}\\left(\\text { if } i \\neq j, \\mathbb{E}\\left[\\sigma_i \\sigma_j\\right]=0\\right) \\\\\n",
    "& =\\frac{B_2}{n} \\sqrt{\\mathbb{E}\\left[\\sum_{i=1}^n\\left\\|x_i\\right\\|_2^2\\right]}\\left(\\sigma_i^2=1\\right) \\\\\n",
    "& \\leq \\frac{B_2 \\sqrt{n C_2^2}}{n}=\\frac{B_2 C_2}{\\sqrt{n}}\n",
    "\\end{aligned}\n",
    "$$\n",
    "で抑えられます．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L1ノルム正則化線形モデルの複雑度\n",
    "\n",
    "* $x\\in \\mathbb{R}^d$の各要素が有界であるとする．つまり，$\\|x\\|_{\\infty} \\leq C_{\\infty}$です．\n",
    "* $\\mathcal{X}$上の関数を$h_w(x) = \\langle w, x\\rangle$とする\n",
    "\n",
    "このとき，$L_1$ノルムにより制限された仮説空間：\n",
    "\n",
    "$$\n",
    "\\mathcal{H}_1=\\left\\{h_w:\\|w\\|_1 \\leq B_1\\right\\}=\\left\\{x \\mapsto\\langle w, x\\rangle:\\|w\\|_1 \\leq B_1\\right\\}\n",
    "$$\n",
    "\n",
    "のラデマッハ複雑度は\n",
    "$$\n",
    "R_n\\left(\\mathcal{H}_1\\right) \\leq \\frac{B_1 C_{\\infty} \\sqrt{2 \\log (d)}}{\\sqrt{n}}\n",
    "$$\n",
    "で抑えられます．\n",
    "\n",
    "**証明**\n",
    "\n",
    "証明の際に重要なポイントはヘルダーの不等式です．L2ノルムの場合はコーシー・シュワルツでバウンドしたわけですが，今回はそれが使えません．\n",
    "そこで，コーシー・シュワルツの一般系であるヘルダーの不等式を使います．\n",
    "\n",
    "TODO: 双対ノルムを考えると，L1ノルムにおけるバウンドでは$L_\\infty$ノルムが自然に出てくることがわかります．\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "R_n\\left(\\mathcal{H}_1\\right) & =\\frac{1}{n} \\mathbb{E}\\left[\\sup _{w:\\|w\\|_1 \\leq B_1} \\sum_{i=1}^n \\sigma_i\\left\\langle w, x_i\\right\\rangle\\right] \\\\\n",
    "& =\\frac{1}{n} \\mathbb{E}\\left[\\sup _{w:\\|w\\|_1 \\leq B_1}\\left\\langle w, \\sum_{i=1}^n \\sigma_i x_i\\right\\rangle\\right]\\\\\n",
    "& \\leq \\frac{B_1}{n} \\mathbb{E}\\left[\\left\\|\\sum_{i=1}^n \\sigma_i x_i\\right\\|_{\\infty}\\right]=\\frac{B_1}{n} \\mathbb{E}\\left[\\sup _{j \\in\\{1, \\ldots, d\\}}\\left|\\sum_{i=1}^n \\sigma_i\\left[x_i\\right]_j\\right|\\right]\\\\\n",
    "&\\leq \\frac{B_1}{n} \\sqrt{2 n C_{\\infty}^2 \\log 2 d}\n",
    "\\end{aligned}\n",
    "$$\n",
    "ここで１つ目の不等式はヘルダーの不等式，最後の不等式はMassartの補題です．つまり，$\\sum_{i=1}^n\\left[x_i\\right]_j^2 \\leq n C_{\\infty}^2$を使いました．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
