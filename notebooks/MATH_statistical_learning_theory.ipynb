{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 統計的学習理論\n",
    "\n",
    "参考：\n",
    "* [統計的学習理論 (機械学習プロフェッショナルシリーズ)](https://amzn.asia/d/5OudVVi)\n",
    "* [Foundations of Machine Learning](https://cs.nyu.edu/~mohri/mlbook/)\n",
    "\n",
    "入力空間から出力空間への関数のことを仮説と呼びます．\n",
    "統計的学習理論はアルゴリズムが吐き出す仮説の**汎化性能**を評価する理論です．\n",
    "汎化の能力の評価では大きく２つの要素を考えます：\n",
    "1. どんなモデル（関数集合）を規定するか？\n",
    "2. どんな問題（損失関数）を期待するか？\n",
    "\n",
    "つまり，関数集合と損失関数に応じて汎化の理論を構築していくわけですね．\n",
    "\n",
    "## 用語\n",
    "\n",
    "汎化の具体的な理論を与える前に，いくつか用語を定義しておきます．\n",
    "\n",
    "* 仮説$h$の予測損失：$R(h)=\\mathbb{E}_{(X, Y)\\sim D}[\\ell(h(X), Y)]$\n",
    "    * 他にも「Generalization error」，「risk」，「true error」など様々な呼び方があります．\n",
    "* 仮説$h$の経験損失：$\\hat{R}(h)=\\frac{1}{n}\\sum_{i=1}^n\\ell(h(X_i), Y_i)=\\mathbb{E}_{(X, Y)\\sim \\hat{D}}[\\ell(h(X), Y)]$\n",
    "    * ここで，確率$1/n$で$(X_i, Y_i)$に値を取る確率変数を$(X, Y)$とし，その分布を$\\hat{D}$としました．\n",
    "\n",
    "各データ$(X_i, Y_i)$が同一の分布$D$に従うとき、経験損失の期待値は予測損失に一致します。実際、$n$個の観測データの同時分布を$D^n$とすると、期待値の線型性から\n",
    "\n",
    "$$\\mathbb{E}_{D^n}[\\hat{R}(h)]=\\frac{1}{n}\\sum_{i=1}^n\\mathbb{E}_{D^n}\\left[\\ell(h(X_i), Y_i)\\right] = R(h)$$\n",
    "\n",
    "が成り立ちます。また、観測データが独立に同一の分布$D$に従うなら、大数の弱法則から\n",
    "\n",
    "$$\\lim_{n\\to\\infty} \\operatorname{Pr}_{D^n}(|\\hat{R}(h) - R(h)| > \\varepsilon) = 0$$\n",
    "\n",
    "が成り立ちます。\n",
    "\n",
    "---\n",
    "\n",
    "**大数の弱法則**\n",
    "\n",
    "$X_1, \\dots, X_n$を期待値$\\mu$，有限の分散のi.i.d.な確率変数とします．このとき，\n",
    "\n",
    "$$\n",
    "\\lim _{n \\rightarrow \\infty} \\operatorname{Pr}\\left(\\left|\\frac{1}{n}\\sum_{i=1}^n X_i - \\mu\\right| \\geq \\varepsilon\\right)=0 \\quad \\text { for all } \\varepsilon>0\n",
    "$$\n",
    "\n",
    "が成立します（つまり経験平均が期待値$\\mu$に確率収束してます）．\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**ベイズ規則とベイズ誤差**\n",
    "\n",
    "損失関数$\\ell$を定めたとき、任意の可測関数$h: \\mathcal{X} \\to \\mathcal{Y}$のもとでの予測損失の下限\n",
    "\n",
    "$$\\inf_{h:\\text{可測}} R(h)$$\n",
    "\n",
    "を$\\ell$のもとでの**ベイズ誤差**といいます。この下限を達成する仮説が存在する場合、その仮説を **ベイズ規則（ベイズルール）** といいます。\n",
    "さきほどの予測損失を振り返ると、タワールールより\n",
    "\n",
    "$$R(h)=\\mathbb{E}_{(X, Y)\\sim D}[\\ell(h(X), Y)]=\\mathbb{E}_{X}[\\mathbb{E}_Y[\\ell(h(X), Y)|X]]$$\n",
    "が成り立ちます。よって、各入力$X=x$における条件付き期待値\n",
    "\n",
    "$$\\mathbb{E}_Y[\\ell(h(x), Y)|x]=\\int_\\mathcal{Y} \\ell(h(x), y)dP(y|x)$$\n",
    "\n",
    "を最小にする仮説$h$を選ぶと、予測誤差が最小になります。\n",
    "\n",
    "---\n",
    "\n",
    "**例（回帰問題）**\n",
    "\n",
    "例えば損失関数が$\\ell(\\hat{y}, y)=(\\hat{y}-y)^2$であるような回帰問題を考えましょう．\n",
    "このとき，次が成立することに注意しましょう．\n",
    "$$\n",
    "\\mathbb{E}_Y[\\ell(h, Y)] = (h - \\mathbb{E}[Y])^2 + V[Y]\n",
    "$$\n",
    "また，上の話から，ベイズ規則は$h(x) = \\mathbb{E}[Y|x]$によって与えられます。\n",
    "よって、ベイズ誤差は\n",
    "\n",
    "$$\n",
    "R(h) \n",
    "= \\mathbb{E}_X\\left[\\int(y - \\mathbb{E}[Y|X])^2dP(y|X)\\right]\n",
    "= \\mathbb{E}_X[V[Y|X]] \n",
    "$$\n",
    "\n",
    "で表現されます．"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## アルゴリズムの汎化性能\n",
    "\n",
    "データ$S=\\{(X_1, Y_1), \\dots, (X_n, Y_n)\\}$を使ってアルゴリズムが吐き出す仮説を$h_S$としましょう．\n",
    "また，ベイズ誤差を$R^*=\\inf_h R(h)$と省略します．\n",
    "\n",
    "アルゴリズムの汎化性能の解析では，主に次のような確率不等式を評価します．\n",
    "$$\\operatorname{Pr}_{S\\sim D^n} (R(h_S) - R^* \\geq \\varepsilon) \\leq \\delta$$\n",
    "これを達成するアルゴリズムはテスト時に$\\varepsilon$以上の期待ミスをする確率が$\\delta$以下になります．\n",
    "さらにこれはマルコフの不等式から以下のように期待値で抑えることもできます．\n",
    "\n",
    "$$\n",
    "\\operatorname{Pr}_{S\\sim D^n} (R(h_S) - R^* \\geq \\varepsilon) \\leq \\frac{\\mathbb{E}_{S\\sim D^n}[R(h_S)] - R^*}{\\varepsilon}\n",
    "$$\n",
    "<!-- このとき，観測データ$S$の分布$D^n$に関する期待予測損失は $\\mathbb{E}_{S\\sim D^n}[R(h_S)]$ となります． -->\n",
    "\n",
    "ベイズ誤差に近い予測損失を達成する仮説を求められるアルゴリズムは、**統計的一致性**をもつといいます．\n",
    "\n",
    "---\n",
    "\n",
    "**統計的一致性**\n",
    "\n",
    "任意の分布$D$と任意の$\\varepsilon > 0$について、\n",
    "\n",
    "$$\n",
    "\\lim_{n\\to \\infty} \\operatorname{Pr}_{S\\sim D^n} (R(h_S) \\leq R^* + \\varepsilon) = 0\n",
    "$$\n",
    "\n",
    "が成り立つとき、学習アルゴリズム$S\\mapsto h_S$は統計的一致性を持つといいます。\n",
    "（つまり，$n$が大きくなると出力の仮説の経験リスクがベイズ誤差に確率収束します．）\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 有限な仮説集合と汎化誤差\n",
    "\n",
    "まずは有限な仮説集合についての汎化誤差の確率不等式を導出してみましょう．\n",
    "\n",
    "---\n",
    "\n",
    "**準備**\n",
    "\n",
    "有限な仮説集合$\\mathcal{H}=\\{h_1, \\cdots, h_T\\}$における二値判別問題を考えてみます。\n",
    "各仮説は入力空間$\\mathcal{X}$から二値ラベル$\\{+1, -1\\}$への関数です。また、データ$S$に対する学習アルゴリズムの出力を，その経験誤差を最小にする仮説として，\n",
    "\n",
    "$$h_S = \\arg \\min_{h\\in \\mathcal{H}} \\hat{R}(h)$$\n",
    "\n",
    "とします。ベイズ規則は$h_0$としましょう．ただし，$h_0$が$\\mathcal{H}$に含まれるとは限りません。\n",
    "さらに、$\\mathcal{H}$の中で予測判別誤差を最小にする仮説を$h_\\mathcal{H}$とします。\n",
    "\n",
    "---\n",
    "\n",
    "さて，上で見たように，次の確率不等式を考えたいわけです．\n",
    "$$\\operatorname{Pr}_{S\\sim D^n} (R(h_S) - R^* \\geq \\varepsilon) \\leq \\delta$$\n",
    "しかし，$R(h_S) - R^* \\geq \\varepsilon$の確率を求めるのは結構難しそうです．\n",
    "そこで，単純に$R(h_S) - R^*$を評価するのではなく，それを評価しやすい量に分解して考えていきます．\n",
    "\n",
    "まず、定義から\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&R(h_0) \\leq R(h_\\mathcal{H}) \\leq R(h_S)\\\\\n",
    "&\\hat{R}(h_S) \\leq R(h_\\mathcal{H})\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "が成り立ちます。これを使って、ベイズ規則との予測判別誤差の差を次のように分解しましょう：\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "R(h_S) - R(h_0) &= \n",
    "R(h_S) - \\hat{R}(h_S)  + \\hat{R}(h_S) - \n",
    "R(h_\\mathcal{H}) + R(h_\\mathcal{H}) - R(h_0) \\\\\n",
    "&\\leq \n",
    "\\underbrace{R(h_S) - \\hat{R}(h_S)}_{(a)}  + \n",
    "\\underbrace{\\hat{R}(h_\\mathcal{H}) - R(h_\\mathcal{H})}_{(b)} \n",
    "+ \\underbrace{R(h_\\mathcal{H}) - R(h_0)}_{(c)} \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "* この(b)は$h_\\mathcal{H}$が固定なので，簡単に解析できます．実際，大数の弱法則では$\\to 0$ですし，中心極限定理を使えば$O(1/\\sqrt{n})$のオーダーで収束することがすぐにわかります．\n",
    "* (c)はベイズ規則と仮説集合限界の性能の差です．この量は **近似誤差(bias)** と呼ばれ，次で定義されます：$\\operatorname{bias}_\\mathcal{H}=R(h_\\mathcal{H}) - R(h_0)$\n",
    "* (a)はそのままでは評価しづらそうです．実際，$h_S$が訓練データに依存するため，$\\hat{R}(h_S)$は独立な$n$個の損失関数の和の評価ではありません．そこで，次のような分解を考えてみましょう．\n",
    "\n",
    "$$\n",
    "(a) = R(h_S) - \\hat{R}(h_S)\n",
    "\\leq \n",
    "\\max_{h\\in \\mathcal{H}} |\\hat{R}(h) - R(h)| \n",
    "$$\n",
    "\n",
    "これは(b)とまとめて良さそうです．つまり，\n",
    "\n",
    "$$\n",
    "(a) + (b) \\leq \n",
    "2\\max_{h\\in \\mathcal{H}} |\\hat{R}(h) - R(h)| \n",
    "$$\n",
    "として問題ありません．\n",
    "この量はHoeffdingの不等式（教科書参照）とUnion Boundによって抑えることができます．\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\operatorname{Pr}\\left(2\\max_{h\\in \\mathcal{H}}|\\hat{R}(h) - R(h)| \\geq \\varepsilon \\right)\n",
    "&\\leq \\sum_{h\\in \\mathcal{H}} \\operatorname{Pr}\\left(2|\\hat{R}(h) - R(h)| \\geq \\varepsilon \\right)\\\\\n",
    "&\\leq \\sum_{h\\in \\mathcal{H}} 2\\exp(-2n(\\varepsilon / 2)^2)\\\\\n",
    "&= 2 |\\mathcal{H}|\\exp(-2n(\\varepsilon / 2)^2)\n",
    "\\end{aligned}\n",
    "$$\n",
    "が成り立ちます。\n",
    "変形すると、確率$1-\\delta$以上で\n",
    "\n",
    "$$\n",
    "2 |\\mathcal{H}|\\exp(-2n(\\varepsilon / 2)^2) \\leq \\sqrt{\\frac{2}{n}\\log{\\frac{2|\\mathcal{H}|}{\\delta}}}\n",
    "$$\n",
    "\n",
    "が成り立ちます。\n",
    "よって、汎化性能は確率$1 - \\delta$以上で\n",
    "\n",
    "$$\n",
    "R(h_S) - R(h_0) \\leq \\sqrt{\\frac{2}{n}\\log{\\frac{2|\\mathcal{H}|}{\\delta}}}+  R(h_\\mathcal{H}) - R(h_0) \n",
    "$$\n",
    "\n",
    "で抑えることができます．もう少し踏み込んで，確率オーダーを導入して評価してみましょう．\n",
    "\n",
    "---\n",
    "\n",
    "**確率オーダー**\n",
    "\n",
    "確率変数列$\\{Z_n\\}_{n\\in \\mathbb{N}}$の確率オーダーが$\\mathcal{O}_P(r_n)$であるとは、\n",
    "\n",
    "$$\n",
    "\\lim_{z\\to \\infty} \\lim \\sup_{n\\to \\infty} \\operatorname{Pr}(|Z_n|/r_n > z) = 0\n",
    "$$\n",
    "\n",
    "であることを意味します。\n",
    "\n",
    "---\n",
    "\n",
    "これを使うと，特に$h_0 \\in \\mathcal{H}$なら、\n",
    "\n",
    "$$\n",
    "R(h_S) = R(h_0) + \\mathcal{O}_P\\left(\\sqrt{\\frac{\\log{|\\mathcal{H}|}}{n}}\\right)\n",
    "$$\n",
    "\n",
    "と評価できます．\n",
    "この２項目は **推定誤差(variance)** と呼ばれ，$\\operatorname{var}_\\mathcal{H}=\\sqrt{\\frac{2}{n}\\log{\\frac{2|\\mathcal{H}|}{\\delta}}}$で定義されます．\n",
    "biasとvarianceを使うと，\n",
    "\n",
    "$$\n",
    "R(h_S) - R(h_0) \\leq \\operatorname{bias}_{\\mathcal{H}} + \\operatorname{var}_{\\mathcal{H}}\n",
    "$$\n",
    "が成立します．定義からbiasとvarianceにはトレードオフがあります．\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 仮説集合と正則化\n",
    "\n",
    "トレードオフを調整するためには適切な仮説集合を獲得する必要があります。\n",
    "適切な仮説集合を学習するための枠組みとして、正則化があります。\n",
    "\n",
    "正則化では「大きな仮説集合から仮説を選ぶこと」に対してペナルティを課します。\n",
    "複数の仮説集合$\\mathcal{H}_1 \\subset \\cdots \\subset \\mathcal{H}_M$を用いて学習を行うとします。\n",
    "仮説$h$に対するペナルティを$\\Phi: \\mathcal{H}_M \\to \\mathbb{R}_{\\geq 0}$として、$m_1 < m_2$に対して、\n",
    "\n",
    "$$h \\in \\mathcal{H}_{m_2},\\; h' \\in \\mathcal{H}_{m_2} \\setminus \\mathcal{H}_{m_1} \\Rightarrow\\Phi(h) \\leq \\Phi(h')$$\n",
    "\n",
    "を満たすような関数$\\Phi$を考えると、大きな仮説集合に含まれる仮説に大きなペナルティが課されることになります。具体的な例としては、$\\mathcal{H}_0$を空集合として、\n",
    "\n",
    "$$\\Phi(h) = \\sum^M_{m=1} w_m \\cdot {\\bf 1} [h\\in \\mathcal{H}_m \\setminus \\mathcal{H}_{m-1}]$$\n",
    "\n",
    "ここでさらに$0 < w_1, < w_2, \\cdots$とすれば、大きな仮説集合に入った$h$には大きなペナルティが課されます。\n",
    "これを使って、次のように仮説を学習することを考えます。\n",
    "\n",
    "\n",
    "$$\n",
    "\\min_{h\\in \\mathcal{H}_M} \\hat{R}(h) + \\lambda \\cdot \\Phi (h)\n",
    "$$\n",
    "\n",
    "こうすると、経験判別誤差が同じ仮説が複数ある場合、最も小さい仮説集合に入る仮説が選択されます。"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
