{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 統計的学習理論\n",
    "\n",
    "参考：\n",
    "* [統計的学習理論 (機械学習プロフェッショナルシリーズ)](https://amzn.asia/d/5OudVVi)\n",
    "* [Foundations of Machine Learning](https://cs.nyu.edu/~mohri/mlbook/)\n",
    "\n",
    "入力空間から出力空間への関数のことを仮説と呼びます．\n",
    "統計的学習理論はアルゴリズムが吐き出す仮説の**汎化性能**を評価する理論です．\n",
    "汎化の能力の評価では大きく２つの要素を考えます：\n",
    "1. どんなモデル（関数集合）を規定するか？\n",
    "2. どんな問題（損失関数）を期待するか？\n",
    "\n",
    "つまり，関数集合と損失関数に応じて汎化の理論を構築していくわけですね．\n",
    "\n",
    "## 用語\n",
    "\n",
    "汎化の具体的な理論を与える前に，いくつか用語を定義しておきます．\n",
    "\n",
    "* 仮説$h$の予測損失：$R(h)=\\mathbb{E}_{(X, Y)\\sim D}[\\ell(h(X), Y)]$\n",
    "    * 他にも「Generalization error」，「risk」，「true error」など様々な呼び方があります．\n",
    "* 仮説$h$の経験損失：$\\hat{R}(h)=\\frac{1}{n}\\sum_{i=1}^n\\ell(h(X_i), Y_i)=\\mathbb{E}_{(X, Y)\\sim \\hat{D}}[\\ell(h(X), Y)]$\n",
    "    * ここで，確率$1/n$で$(X_i, Y_i)$に値を取る確率変数を$(X, Y)$とし，その分布を$\\hat{D}$としました．\n",
    "\n",
    "各データ$(X_i, Y_i)$が同一の分布$D$に従うとき、経験損失の期待値は予測損失に一致します。実際、$n$個の観測データの同時分布を$D^n$とすると、期待値の線型性から\n",
    "\n",
    "$$\\mathbb{E}_{D^n}[\\hat{R}(h)]=\\frac{1}{n}\\sum_{i=1}^n\\mathbb{E}_{D^n}\\left[\\ell(h(X_i), Y_i)\\right] = R(h)$$\n",
    "\n",
    "が成り立ちます。また、観測データが独立に同一の分布$D$に従うなら、大数の弱法則から\n",
    "\n",
    "$$\\lim_{n\\to\\infty} \\operatorname{Pr}_{D^n}(|\\hat{R}(h) - R(h)| > \\varepsilon) = 0$$\n",
    "\n",
    "が成り立ちます。\n",
    "\n",
    "---\n",
    "\n",
    "**大数の弱法則**\n",
    "\n",
    "$X_1, \\dots, X_n$を期待値$\\mu$，有限の分散のi.i.d.な確率変数とします．このとき，\n",
    "\n",
    "$$\n",
    "\\lim _{n \\rightarrow \\infty} \\operatorname{Pr}\\left(\\left|\\frac{1}{n}\\sum_{i=1}^n X_i - \\mu\\right| \\geq \\varepsilon\\right)=0 \\quad \\text { for all } \\varepsilon>0\n",
    "$$\n",
    "\n",
    "が成立します（つまり経験平均が期待値$\\mu$に確率収束してます）．\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**ベイズ規則とベイズ誤差**\n",
    "\n",
    "損失関数$\\ell$を定めたとき、任意の可測関数$h: \\mathcal{X} \\to \\mathcal{Y}$のもとでの予測損失の下限\n",
    "\n",
    "$$\\inf_{h:\\text{可測}} R(h)$$\n",
    "\n",
    "を$\\ell$のもとでの**ベイズ誤差**といいます。この下限を達成する仮説が存在する場合、その仮説を **ベイズ規則（ベイズルール）** といいます。\n",
    "さきほどの予測損失を振り返ると、タワールールより\n",
    "\n",
    "$$R(h)=\\mathbb{E}_{(X, Y)\\sim D}[\\ell(h(X), Y)]=\\mathbb{E}_{X}[\\mathbb{E}_Y[\\ell(h(X), Y)|X]]$$\n",
    "が成り立ちます。よって、各入力$X=x$における条件付き期待値\n",
    "\n",
    "$$\\mathbb{E}_Y[\\ell(h(x), Y)|x]=\\int_\\mathcal{Y} \\ell(h(x), y)dP(y|x)$$\n",
    "\n",
    "を最小にする仮説$h$を選ぶと、予測誤差が最小になります。\n",
    "\n",
    "---\n",
    "\n",
    "**例（回帰問題）**\n",
    "\n",
    "例えば損失関数が$\\ell(\\hat{y}, y)=(\\hat{y}-y)^2$であるような回帰問題を考えましょう．\n",
    "このとき，次が成立することに注意しましょう．\n",
    "$$\n",
    "\\mathbb{E}_Y[\\ell(h, Y)] = (h - \\mathbb{E}[Y])^2 + V[Y]\n",
    "$$\n",
    "また，上の話から，ベイズ規則は$h(x) = \\mathbb{E}[Y|x]$によって与えられます。\n",
    "よって、ベイズ誤差は\n",
    "\n",
    "$$\n",
    "R(h) \n",
    "= \\mathbb{E}_X\\left[\\int(y - \\mathbb{E}[Y|X])^2dP(y|X)\\right]\n",
    "= \\mathbb{E}_X[V[Y|X]] \n",
    "$$\n",
    "\n",
    "で表現されます．"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## アルゴリズムの汎化性能\n",
    "\n",
    "データ$S=\\{(X_1, Y_1), \\dots, (X_n, Y_n)\\}$を使ってアルゴリズムが吐き出す仮説を$h_S$としましょう．\n",
    "また，ベイズ誤差を$R^*=\\inf_h R(h)$と省略します．\n",
    "\n",
    "アルゴリズムの汎化性能の解析では，主に次のような確率不等式を評価します．\n",
    "$$\\operatorname{Pr}_{S\\sim D^n} (R(h_S) - R^* \\geq \\varepsilon) \\leq \\delta$$\n",
    "これを達成するアルゴリズムはテスト時に$\\varepsilon$以上の期待ミスをする確率が$\\delta$以下になります．\n",
    "さらにこれはマルコフの不等式から以下のように期待値で抑えることもできます．\n",
    "\n",
    "$$\n",
    "\\operatorname{Pr}_{S\\sim D^n} (R(h_S) - R^* \\geq \\varepsilon) \\leq \\frac{\\mathbb{E}_{S\\sim D^n}[R(h_S)] - R^*}{\\varepsilon}\n",
    "$$\n",
    "<!-- このとき，観測データ$S$の分布$D^n$に関する期待予測損失は $\\mathbb{E}_{S\\sim D^n}[R(h_S)]$ となります． -->\n",
    "\n",
    "ベイズ誤差に近い予測損失を達成する仮説を求められるアルゴリズムは、**統計的一致性**をもつといいます．\n",
    "\n",
    "---\n",
    "\n",
    "**統計的一致性**\n",
    "\n",
    "任意の分布$D$と任意の$\\varepsilon > 0$について、\n",
    "\n",
    "$$\n",
    "\\lim_{n\\to \\infty} \\operatorname{Pr}_{S\\sim D^n} (R(h_S) \\leq R^* + \\varepsilon) = 0\n",
    "$$\n",
    "\n",
    "が成り立つとき、学習アルゴリズム$S\\mapsto h_S$は統計的一致性を持つといいます。\n",
    "（つまり，$n$が大きくなると出力の仮説の経験リスクがベイズ誤差に確率収束します．）\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 有限な仮説集合と汎化誤差\n",
    "\n",
    "まずは有限な仮説集合についての汎化誤差の確率不等式を導出してみましょう．\n",
    "\n",
    "---\n",
    "\n",
    "**準備**\n",
    "\n",
    "有限な仮説集合$\\mathcal{H}=\\{h_1, \\cdots, h_T\\}$における二値判別問題を考えてみます。\n",
    "各仮説は入力空間$\\mathcal{X}$から二値ラベル$\\{+1, -1\\}$への関数です。また、データ$S$に対する学習アルゴリズムの出力を，その経験誤差を最小にする仮説として，\n",
    "\n",
    "$$h_S = \\arg \\min_{h\\in \\mathcal{H}} \\hat{R}(h)$$\n",
    "\n",
    "とします。ベイズ規則は$h_0$としましょう．ただし，$h_0$が$\\mathcal{H}$に含まれるとは限りません。\n",
    "さらに、$\\mathcal{H}$の中で予測判別誤差を最小にする仮説を$h_\\mathcal{H}$とします。\n",
    "\n",
    "---\n",
    "\n",
    "さて，上で見たように，次の確率不等式を考えたいわけです．\n",
    "$$\\operatorname{Pr}_{S\\sim D^n} (R(h_S) - R^* \\geq \\varepsilon) \\leq \\delta$$\n",
    "しかし，$R(h_S) - R^* \\geq \\varepsilon$の確率を求めるのは結構難しそうです．\n",
    "そこで，単純に$R(h_S) - R^*$を評価するのではなく，それを評価しやすい量に分解して考えていきます．\n",
    "\n",
    "まず、定義から\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&R(h_0) \\leq R(h_\\mathcal{H}) \\leq R(h_S)\\\\\n",
    "&\\hat{R}(h_S) \\leq R(h_\\mathcal{H})\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "が成り立ちます。これを使って、ベイズ規則との予測判別誤差の差を次のように分解しましょう：\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "R(h_S) - R(h_0) &= \n",
    "R(h_S) - \\hat{R}(h_S)  + \\hat{R}(h_S) - \n",
    "R(h_\\mathcal{H}) + R(h_\\mathcal{H}) - R(h_0) \\\\\n",
    "&\\leq \n",
    "\\underbrace{R(h_S) - \\hat{R}(h_S)}_{(a)}  + \n",
    "\\underbrace{\\hat{R}(h_\\mathcal{H}) - R(h_\\mathcal{H})}_{(b)} \n",
    "+ \\underbrace{R(h_\\mathcal{H}) - R(h_0)}_{(c)} \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "* この(b)は$h_\\mathcal{H}$が固定なので，簡単に解析できます．実際，大数の弱法則では$\\to 0$ですし，中心極限定理を使えば$O(1/\\sqrt{n})$のオーダーで収束することがすぐにわかります．\n",
    "* (c)はベイズ規則と仮説集合限界の性能の差です．この量は **近似誤差(bias)** と呼ばれ，次で定義されます：$\\operatorname{bias}_\\mathcal{H}=R(h_\\mathcal{H}) - R(h_0)$\n",
    "* (a)はそのままでは評価しづらそうです．実際，$h_S$が訓練データに依存するため，$\\hat{R}(h_S)$は独立な$n$個の損失関数の和の評価ではありません．そこで，次のような分解を考えてみましょう．\n",
    "\n",
    "$$\n",
    "(a) = R(h_S) - \\hat{R}(h_S)\n",
    "\\leq \n",
    "\\max_{h\\in \\mathcal{H}} |\\hat{R}(h) - R(h)| \n",
    "$$\n",
    "\n",
    "これは(b)とまとめて良さそうです．つまり，\n",
    "\n",
    "$$\n",
    "(a) + (b) \\leq \n",
    "2\\max_{h\\in \\mathcal{H}} |\\hat{R}(h) - R(h)| \n",
    "$$\n",
    "として問題ありません．\n",
    "この量はHoeffdingの不等式（教科書参照）とUnion Boundによって抑えることができます．\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\operatorname{Pr}\\left(2\\max_{h\\in \\mathcal{H}}|\\hat{R}(h) - R(h)| \\geq \\varepsilon \\right)\n",
    "&\\leq \\sum_{h\\in \\mathcal{H}} \\operatorname{Pr}\\left(2|\\hat{R}(h) - R(h)| \\geq \\varepsilon \\right)\\\\\n",
    "&\\leq \\sum_{h\\in \\mathcal{H}} 2\\exp(-2n(\\varepsilon / 2)^2)\\\\\n",
    "&= 2 |\\mathcal{H}|\\exp(-2n(\\varepsilon / 2)^2)\n",
    "\\end{aligned}\n",
    "$$\n",
    "が成り立ちます。\n",
    "変形すると、確率$1-\\delta$以上で\n",
    "\n",
    "$$\n",
    "2 |\\mathcal{H}|\\exp(-2n(\\varepsilon / 2)^2) \\leq \\sqrt{\\frac{2}{n}\\log{\\frac{2|\\mathcal{H}|}{\\delta}}}\n",
    "$$\n",
    "\n",
    "が成り立ちます。\n",
    "よって、汎化性能は確率$1 - \\delta$以上で\n",
    "\n",
    "$$\n",
    "R(h_S) - R(h_0) \\leq \\sqrt{\\frac{2}{n}\\log{\\frac{2|\\mathcal{H}|}{\\delta}}}+  R(h_\\mathcal{H}) - R(h_0) \n",
    "$$\n",
    "\n",
    "で抑えることができます．もう少し踏み込んで，確率オーダーを導入して評価してみましょう．\n",
    "\n",
    "---\n",
    "\n",
    "**確率オーダー**\n",
    "\n",
    "確率変数列$\\{Z_n\\}_{n\\in \\mathbb{N}}$の確率オーダーが$\\mathcal{O}_P(r_n)$であるとは、\n",
    "\n",
    "$$\n",
    "\\lim_{z\\to \\infty} \\lim \\sup_{n\\to \\infty} \\operatorname{Pr}(|Z_n|/r_n > z) = 0\n",
    "$$\n",
    "\n",
    "であることを意味します。\n",
    "\n",
    "---\n",
    "\n",
    "これを使うと，特に$h_0 \\in \\mathcal{H}$なら、\n",
    "\n",
    "$$\n",
    "R(h_S) = R(h_0) + \\mathcal{O}_P\\left(\\sqrt{\\frac{\\log{|\\mathcal{H}|}}{n}}\\right)\n",
    "$$\n",
    "\n",
    "と評価できます．\n",
    "この２項目は **推定誤差(variance)** と呼ばれ，今回の場合は$\\operatorname{var}_\\mathcal{H}=\\sqrt{\\frac{2}{n}\\log{\\frac{2|\\mathcal{H}|}{\\delta}}}$で与えられます．\n",
    "biasとvarianceを使うと，\n",
    "\n",
    "$$\n",
    "R(h_S) - R(h_0) \\leq \\operatorname{bias}_{\\mathcal{H}} + \\operatorname{var}_{\\mathcal{H}}\n",
    "$$\n",
    "が成立します．定義からbiasとvarianceにはトレードオフがあります．\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 実現可能であるとき\n",
    "\n",
    "上でHoeffdingを使った例ではベイズ規則$h_0$が$\\mathcal{H}$に含まれていませんでした．\n",
    "今回は次の仮定のもとでの学習について考えてみます：\n",
    "\n",
    "* **実現可能性**：$R(h^*)=0$となる仮説$h^*\\in \\mathcal{H}$が存在する\n",
    "\n",
    "今回は損失が常に非負なので，${R}(h)=0$を満たすような任意の$h$について，$\\hat{R}(h)=0$が成り立ちます．\n",
    "よって$\\hat{R}(h^*)=0$です．\n",
    "また，アルゴリズムは経験誤差を最小にする仮説を返すので，$\\hat{R}(h_S)=0$も成立します．\n",
    "\n",
    "目的をあらためて確認しましょう．\n",
    "$$\n",
    "\\mathbb{P}[R(h_S) - R(h_0) \\leq \\epsilon] > 1-\\delta\n",
    "$$\n",
    "を示していきたいわけですね．特に今回は$R(h_0)=0$なので，\n",
    "$$\n",
    "\\mathbb{P}[R(h_S) \\leq \\epsilon] > 1-\\delta\n",
    "$$\n",
    "です．これを抑えるのはちょっと大変なので，$R(h)=0$が満たされるような任意の$h$に対して\n",
    "$\\mathbb{P}[R(h) \\leq \\epsilon] > 1-\\delta$を示していきます．\n",
    "\n",
    "---\n",
    "\n",
    "**$\\mathbb{P}[R(h) \\leq \\epsilon]$を変形しよう** \n",
    "\n",
    "まず，$\\mathcal{H}_{>\\epsilon}=\\{h \\in \\mathcal{H}: R(h)>\\epsilon\\}$とおきます．\n",
    "すると上の目標は$\\mathbb{P}[R({h})>\\epsilon]=\\mathbb{P}\\left[{h} \\in \\mathcal{H}_{>\\epsilon}\\right]$と同じです．\n",
    "\n",
    "---\n",
    "\n",
    "**$\\mathbb{P}[h \\in \\mathcal{H}_{>\\epsilon}]$を上から抑えよう** \n",
    "\n",
    "続いて，適当な仮説$h$について，$R(h)=\\mathbb{E}_{(x, y)\\sim\\mathcal{D}}[1(y\\neq h(x))]=\\mathbb{P}_{(x, y)\\sim\\mathcal{D}}[y\\neq h(x)]$なので，$h$のリスクは仮説$h$について$y\\neq h(x)$となる確率と同じです．\n",
    "よって，リスクが$\\epsilon$以上になるような仮説とは，$1-\\mathbb{P}[y \\neq h(x)] \\leq 1-\\epsilon$を満たします．\n",
    "これを使うと，$\\hat{R}(h)=0$を満たすような任意の$h$に対して，\n",
    "$$\\mathbb{P}\\left[{h} \\in \\mathcal{H}_{>\\epsilon}\\right] \\leq \\mathbb{P}\\left[\\exists h \\in \\mathcal{H}_{>\\epsilon}: \\hat{R}(h)=0\\right]$$\n",
    "で抑えられます．\n",
    "\n",
    "---\n",
    "\n",
    "**$\\mathbb{P}\\left[\\exists h \\in \\mathcal{H}_{>\\epsilon}: \\hat{R}(h)=0\\right]$について考えよう**\n",
    "\n",
    "$R(h) >\\epsilon$を満たすような$h$については，\n",
    "\n",
    "$$\n",
    "\\mathbb{P}[\\hat{R}(h)=0] = (\\mathbb{P}[y=h(x)])^nca\\leq (1-\\epsilon)^n \\leq \\exp(-\\epsilon n)\n",
    "$$\n",
    "\n",
    "が成立します．\n",
    "よって，$\\hat{R}(h)=0$を満たすような任意の$h$に対して，\n",
    "\n",
    "$$\\mathbb{P}\\left[{h} \\in \\mathcal{H}_{>\\epsilon}\\right] \\leq \\mathbb{P}\\left[\\exists h \\in \\mathcal{H}_{>\\epsilon}: \\hat{R}(h)=0\\right]\\leq |\\mathcal{H}|\\exp(-\\epsilon n)$$\n",
    "\n",
    "が成立します．\n",
    "\n",
    "---\n",
    "\n",
    "以上から，\n",
    "$$\n",
    "\\mathbb{P}\\left[R(h_S) \\leq \\frac{1}{n}(\\log|\\mathcal{H}| + \\log (1 / \\delta))\\right] > 1 - \\delta\n",
    "$$\n",
    "が成立します．\n",
    "\n",
    "実現可能性がある場合は$1 / \\sqrt{n}$のオーダーが$1/n$になっていることに注意しましょう．実現可能性のもとでは$h^*$の候補として$\\hat{R}(h)=0$になるような$h$に着目すればよいですが，ない場合は$R(h^*)$がわからないので，分布の裾に関する情報を集めるしかなく，結果として必要なデータ数が増加すると考えられます．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 仮説集合が無限のとき\n",
    "\n",
    "ちょっとおさらいしてみましょう．\n",
    "\n",
    "* 実現可能なとき：$\\hat{R}(h)=0$を満たす任意の$h$について，\n",
    "$$\n",
    "\\mathbb{P}[R(\\hat{h})>\\epsilon] =\\mathbb{P}\\left[{h} \\in \\mathcal{H}_{>\\epsilon}\\right] \n",
    "\\leq \\sum_{h \\in \\mathcal{H}_{>\\epsilon}} \\mathbb{P}\\left[\\widehat{R}(h)=0\\right]\n",
    "\\leq \\left|\\mathcal{H}\\right| \\exp (-\\epsilon n)\n",
    "$$\n",
    "* 実現不可能なとき：\n",
    "$R(h_S) - R(h_0) \\leq {R(h_S) - \\hat{R}(h_S)}  + {\\hat{R}(h_\\mathcal{H}) - R(h_\\mathcal{H})} + {R(h_\\mathcal{H}) - R(h_0)}$を使い，最初の２項をHoeffdingでバウンド．\n",
    "\n",
    "さて，無限のときはUnion boundを取ってバウンドするやり方が通用しません．\n",
    "\n",
    "無限の場合は次のMcDiarmidの不等式を使ってtail boundを期待値計算へ変換し，その後ラデマッハ複雑度で無限集合のサイズを抑えます．\n",
    "\n",
    "---\n",
    "\n",
    "**McDiarmidの不等式**\n",
    "\n",
    "関数$f$が，任意の$x_1, \\dots, x_n, x_i'$において以下を満たすとします．\n",
    "\n",
    "$$\n",
    "\\left|f\\left(x_1, \\ldots, x_i, \\ldots, x_n\\right)-f\\left(x_1, \\ldots, x_i^{\\prime}, \\ldots, x_n\\right)\\right| \\leq c_i\n",
    "$$\n",
    "\n",
    "また，$X_1, \\dots, X_n$を独立な確率変数とします．このとき，\n",
    "$$\n",
    "\\mathbb{P}\\left[f\\left(X_1, \\ldots, X_n\\right)-\\mathbb{E}\\left[f\\left(X_1, \\ldots, X_n\\right)\\right]>\\epsilon\\right] \\\\\n",
    "\\leq \\exp \\left(-\\frac{2 \\epsilon^2}{\\sum_{i=1}^n c_i^2}\\right) .\n",
    "$$\n",
    "が成立します．\n",
    "\n",
    "これはつまり$X_1, \\dots, X_n$の関数についての確率不等式です．\n",
    "この不等式はHoeffdingを一般化しています．$f(X_1,\\dots, X_n)=\\frac{1}{n}\\sum_i X_i$としましょう．$|X|\\leq A$なら，\n",
    "\n",
    "$$\n",
    "\\left|f\\left(x_1, \\ldots, x_i, \\ldots, x_n\\right)-f\\left(x_1, \\ldots, x_i^{\\prime}, \\ldots, x_n\\right)\\right| \n",
    "=\\left|\\frac{x_i - x_i'}{n}\\right| \\leq \\frac{2A}{n}\n",
    "$$\n",
    "\n",
    "が成り立ちます．あとは$c_i$に上の式を代入すると，McDiarmidはHoeffdingを一般化していることがわかります．\n",
    "\n",
    "また，$f$の取る値を$[a, b]$とすると，少なくとも$1-\\delta$の確率で\n",
    "$$\n",
    "\\left|f\\left(X_1, \\ldots, X_n\\right)-\\mathbb{E}\\left[f\\left(X_1, \\ldots, X_n\\right)\\right]\\right| \\leq(b-a) \\sqrt{\\frac{n \\log \\frac{2}{\\delta}}{2}}\n",
    "$$\n",
    "が成り立ちます．これは後で使います．\n",
    "\n",
    "---\n",
    "\n",
    "さて，汎化誤差のバウンドに戻りましょう．\n",
    "少し一般化した話を考えます．損失関数$\\ell((x, y), h)$は$[a, b]$上の値を取る関数とします．また，\n",
    "$\\mathcal{H}$上の関数で計算される$\\ell((\\cdot, \\cdot), h)$の集合を$\\mathcal{L}$とします．つまり，$\\mathcal{L}=\\{((x, y), h) \\mapsto \\ell((x, y), h) \\mid(x, y) \\in \\mathcal{X} \\times \\mathcal{Y}, h \\in \\mathcal{H}\\}$とします．\n",
    "\n",
    "次の手順で進みます（簡単のために$h_0 \\in \\mathcal{H}$とします）：\n",
    "\n",
    "1. 有限な仮説集合のところでやったように，次が成り立ちます．\n",
    "$$\\mathbb{P}\\left[R(h)-R(h_0) > \\epsilon\\right] \\leq \\mathbb{P}\\left[\\sup_{h \\in \\mathcal{H}}|\\hat{R}(h) - R(h)| > \\epsilon / 2\\right]$$\n",
    "2. データに依存した確率変数：$\\hat{G}=\\sup_{h \\in \\mathcal{H}} R(h) - \\hat{R}(h)$\n",
    "を定義します．$\\hat{G}$を使うと，$\\mathbb{P}\\left[\\widehat{G}>\\frac{\\epsilon}{2}\\right] \\leq \\frac{\\delta}{2}, \\mathbb{P}\\left[-\\widehat{G}>\\frac{\\epsilon}{2}\\right] \\leq \\frac{\\delta}{2}$ならば次が成立します．\n",
    "$$\\mathbb{P}\\left[\\sup_{h \\in \\mathcal{H}}|\\hat{R}(h) - R(h)| > \\epsilon / 2\\right] \\leq \n",
    "\\mathbb{P}\\left[\\widehat{G}>\\frac{\\epsilon}{2}\\right] + \\mathbb{P}\\left[-\\widehat{G}>\\frac{\\epsilon}{2}\\right] \\leq \\delta$$\n",
    "3. McDiarmidの不等式より，$\\widehat{G} \\leq \\mathbb{E}\\left[\\widehat{G}\\right]+(b-a) \\sqrt{\\frac{\\log \\frac{1}{\\delta}}{2 n}}$が成立します．\n",
    "4. $\\mathbb{E}[\\hat{G}]$をラデマッハ複雑度で上から抑えます．\n",
    "\n",
    "ラデマッハ複雑度は次で定義されます：\n",
    "\n",
    "---\n",
    "\n",
    "**経験ラデマッハ複雑度**\n",
    "\n",
    "実数値関数の集合$\\mathcal{F}\\subset\\{f: \\mathcal{X}\\to \\mathbb{R}\\}$を考えます。\n",
    "入力点の集合$S=\\{x_1, x_2, \\dots, x_n\\}\\subset \\mathcal{X}$を考えます。\n",
    "また、$+1$と$-1$を等確率で取る独立な確率変数を$\\sigma_1, \\dots, \\sigma_n$とします。\n",
    "このとき、$\\mathcal{F}$の経験ラデマッハ複雑度は\n",
    "\n",
    "$$\n",
    "\\widehat{\\mathcal{R}}_S(\\mathcal{F}) = \\mathbb{E}_\\sigma \\left[\\sup_{f\\in \\mathcal{F}} \\frac{1}{n} \\sum^n_{i=1}\\sigma_i f(x_i)\\right]\n",
    "$$\n",
    "で定義されます。\n",
    "\n",
    "経験ラデマッハ複雑度は、$S$上のランダムなラベル付けに対して関数集合$\\mathcal{G}$のデータへの適合度を平均的に図っていることになります。\n",
    "つまり，$\\mathcal{F}$が複雑な関数を表現できるほど$\\widehat{R}_S(\\mathcal{F})$の値は大きくなります．\n",
    "\n",
    "**ラデマッハ複雑度**\n",
    "\n",
    "経験ラデマッハ複雑度をデータについて期待値を取ったものをラデマッハ複雑度と呼びます．\n",
    "\n",
    "$$\\mathcal{R}_n(\\mathcal{F})=\\mathbb{E}_{S\\sim \\mathcal{D}}[\\widehat{\\mathcal{R}}_S(\\mathcal{F})]$$\n",
    "\n",
    "---\n",
    "\n",
    "手順３から考えましょう．$\\hat{G}'$をデータの一つを変化させたものとします．$\\hat{G} - \\hat{G}' \\leq \\frac{b-a}{n}$が成り立つのはすぐにわかります．\n",
    "すると，McDiarmidの不等式から，少なくとも$1-\\delta / 2$の確率で\n",
    "\n",
    "$$\\widehat{G} \\leq \\mathbb{E}\\left[\\widehat{G}\\right]+(b-a) \\sqrt{\\frac{\\log \\frac{2}{\\delta}}{2 n}}$$\n",
    "\n",
    "が成り立ちます．\n",
    "最後に\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathbb{E}[\\hat{G}]\n",
    "&=\\mathbb{E}_{S \\sim \\mathcal{D}}\\left[\\sup_{h\\in\\mathcal{H}} \\mathbb{E}_{S' \\sim \\mathcal{D}}[\\hat{R}'(h)] -\\hat{R}(h)\\right]\\\\\n",
    "&\\leq\\mathbb{E}_{S \\sim \\mathcal{D}}\\left[ \\mathbb{E}_{S' \\sim \\mathcal{D}}\\left[\\sup_{h\\in\\mathcal{H}}\\hat{R}'(h) -\\hat{R}(h)\\right]\\right]\\\\\n",
    "&=\\mathbb{E}_{S \\sim \\mathcal{D}}\\left[ \\mathbb{E}_{S' \\sim \\mathcal{D}}\\left[\\sup_{h\\in\\mathcal{H}}\\frac{1}{n}\\sum_{i}\\ell((x_i', y_i'), h) - \\ell((x_i, y_i), h)\\right]\\right]\\\\\n",
    "&=\\mathbb{E}_{S \\sim \\mathcal{D}}\\left[ \\mathbb{E}_{S' \\sim \\mathcal{D}}\\mathbb{E}_\\sigma\\left[\\sup_{h\\in\\mathcal{H}}\\frac{1}{n}\\sum_{i}\\sigma_i\\left(\\ell((x_i', y_i'), h) - \\ell((x_i, y_i), h)\\right)\\right]\\right]\\\\\n",
    "&\\leq 2 \\mathcal{R}_n(\\mathcal{L})\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "あとは汎化誤差の式と合体させれば終了です．"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 仮説集合と正則化\n",
    "\n",
    "トレードオフを調整するためには適切な仮説集合を獲得する必要があります。\n",
    "適切な仮説集合を学習するための枠組みとして、正則化があります。\n",
    "\n",
    "正則化では「大きな仮説集合から仮説を選ぶこと」に対してペナルティを課します。\n",
    "複数の仮説集合$\\mathcal{H}_1 \\subset \\cdots \\subset \\mathcal{H}_M$を用いて学習を行うとします。\n",
    "仮説$h$に対するペナルティを$\\Phi: \\mathcal{H}_M \\to \\mathbb{R}_{\\geq 0}$として、$m_1 < m_2$に対して、\n",
    "\n",
    "$$h \\in \\mathcal{H}_{m_2},\\; h' \\in \\mathcal{H}_{m_2} \\setminus \\mathcal{H}_{m_1} \\Rightarrow\\Phi(h) \\leq \\Phi(h')$$\n",
    "\n",
    "を満たすような関数$\\Phi$を考えると、大きな仮説集合に含まれる仮説に大きなペナルティが課されることになります。具体的な例としては、$\\mathcal{H}_0$を空集合として、\n",
    "\n",
    "$$\\Phi(h) = \\sum^M_{m=1} w_m \\cdot {\\bf 1} [h\\in \\mathcal{H}_m \\setminus \\mathcal{H}_{m-1}]$$\n",
    "\n",
    "ここでさらに$0 < w_1, < w_2, \\cdots$とすれば、大きな仮説集合に入った$h$には大きなペナルティが課されます。\n",
    "これを使って、次のように仮説を学習することを考えます。\n",
    "\n",
    "\n",
    "$$\n",
    "\\min_{h\\in \\mathcal{H}_M} \\hat{R}(h) + \\lambda \\cdot \\Phi (h)\n",
    "$$\n",
    "\n",
    "こうすると、経験判別誤差が同じ仮説が複数ある場合、最も小さい仮説集合に入る仮説が選択されます。"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
